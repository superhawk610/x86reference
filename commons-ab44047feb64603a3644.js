(self.webpackChunkx86reference=self.webpackChunkx86reference||[]).push([[351],{523:function(e){var t="undefined"!=typeof Element,i="function"==typeof Map,n="function"==typeof Set,o="function"==typeof ArrayBuffer&&!!ArrayBuffer.isView;function s(e,r){if(e===r)return!0;if(e&&r&&"object"==typeof e&&"object"==typeof r){if(e.constructor!==r.constructor)return!1;var a,m,d,p;if(Array.isArray(e)){if((a=e.length)!=r.length)return!1;for(m=a;0!=m--;)if(!s(e[m],r[m]))return!1;return!0}if(i&&e instanceof Map&&r instanceof Map){if(e.size!==r.size)return!1;for(p=e.entries();!(m=p.next()).done;)if(!r.has(m.value[0]))return!1;for(p=e.entries();!(m=p.next()).done;)if(!s(m.value[1],r.get(m.value[0])))return!1;return!0}if(n&&e instanceof Set&&r instanceof Set){if(e.size!==r.size)return!1;for(p=e.entries();!(m=p.next()).done;)if(!r.has(m.value[0]))return!1;return!0}if(o&&ArrayBuffer.isView(e)&&ArrayBuffer.isView(r)){if((a=e.length)!=r.length)return!1;for(m=a;0!=m--;)if(e[m]!==r[m])return!1;return!0}if(e.constructor===RegExp)return e.source===r.source&&e.flags===r.flags;if(e.valueOf!==Object.prototype.valueOf)return e.valueOf()===r.valueOf();if(e.toString!==Object.prototype.toString)return e.toString()===r.toString();if((a=(d=Object.keys(e)).length)!==Object.keys(r).length)return!1;for(m=a;0!=m--;)if(!Object.prototype.hasOwnProperty.call(r,d[m]))return!1;if(t&&e instanceof Element)return!1;for(m=a;0!=m--;)if(("_owner"!==d[m]&&"__v"!==d[m]&&"__o"!==d[m]||!e.$$typeof)&&!s(e[d[m]],r[d[m]]))return!1;return!0}return e!=e&&r!=r}e.exports=function(e,t){try{return s(e,t)}catch(i){if((i.message||"").match(/stack|recursion/i))return console.warn("react-fast-compare cannot handle circular refs"),!1;throw i}}},6124:function(e,t,i){"use strict";var n,o=i(7294),s=(n=o)&&"object"==typeof n&&"default"in n?n.default:n;function r(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}var a=!("undefined"==typeof window||!window.document||!window.document.createElement);e.exports=function(e,t,i){if("function"!=typeof e)throw new Error("Expected reducePropsToState to be a function.");if("function"!=typeof t)throw new Error("Expected handleStateChangeOnClient to be a function.");if(void 0!==i&&"function"!=typeof i)throw new Error("Expected mapStateOnServer to either be undefined or a function.");return function(n){if("function"!=typeof n)throw new Error("Expected WrappedComponent to be a React component.");var m,d=[];function p(){m=e(d.map((function(e){return e.props}))),l.canUseDOM?t(m):i&&(m=i(m))}var l=function(e){var t,i;function o(){return e.apply(this,arguments)||this}i=e,(t=o).prototype=Object.create(i.prototype),t.prototype.constructor=t,t.__proto__=i,o.peek=function(){return m},o.rewind=function(){if(o.canUseDOM)throw new Error("You may only call rewind() on the server. Call peek() to read the current state.");var e=m;return m=void 0,d=[],e};var r=o.prototype;return r.UNSAFE_componentWillMount=function(){d.push(this),p()},r.componentDidUpdate=function(){p()},r.componentWillUnmount=function(){var e=d.indexOf(this);d.splice(e,1),p()},r.render=function(){return s.createElement(n,this.props)},o}(o.PureComponent);return r(l,"displayName","SideEffect("+function(e){return e.displayName||e.name||"Component"}(n)+")"),r(l,"canUseDOM",a),l}}},1914:function(e){function t(e,t){if((e=e.replace(/\s+/g,""))===(t=t.replace(/\s+/g,"")))return 1;if(e.length<2||t.length<2)return 0;for(var i=new Map,n=0;n<e.length-1;n++){var o=e.substring(n,n+2),s=i.has(o)?i.get(o)+1:1;i.set(o,s)}for(var r=0,a=0;a<t.length-1;a++){var m=t.substring(a,a+2),d=i.has(m)?i.get(m):0;d>0&&(i.set(m,d-1),r++)}return 2*r/(e.length+t.length-2)}e.exports={compareTwoStrings:t,findBestMatch:function(e,i){if(!function(e,t){return"string"==typeof e&&(!!Array.isArray(t)&&(!!t.length&&!t.find((function(e){return"string"!=typeof e}))))}(e,i))throw new Error("Bad arguments: First argument should be a string, second should be an array of strings");for(var n=[],o=0,s=0;s<i.length;s++){var r=i[s],a=t(e,r);n.push({target:r,rating:a}),a>n[o].rating&&(o=s)}var m=n[o];return{ratings:n,bestMatch:m,bestMatchIndex:o}}}},3347:function(e,t,i){"use strict";i.d(t,{Z:function(){return c}});var n=i(7294),o=i(5444),s=i(1914);function r(e,t){var i="undefined"!=typeof Symbol&&e[Symbol.iterator]||e["@@iterator"];if(i)return(i=i.call(e)).next.bind(i);if(Array.isArray(e)||(i=function(e,t){if(!e)return;if("string"==typeof e)return a(e,t);var i=Object.prototype.toString.call(e).slice(8,-1);"Object"===i&&e.constructor&&(i=e.constructor.name);if("Map"===i||"Set"===i)return Array.from(e);if("Arguments"===i||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(i))return a(e,t)}(e))||t&&e&&"number"==typeof e.length){i&&(e=i);var n=0;return function(){return n>=e.length?{done:!0}:{done:!1,value:e[n++]}}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}function a(e,t){(null==t||t>e.length)&&(t=e.length);for(var i=0,n=new Array(t);i<t;i++)n[i]=e[i];return n}var m=JSON.parse('{"AAA":{"_":"aaa","*":"ASCII adjust AL after addition."},"AAD":{"_":"aad","*":"Adjust AX before division to number base imm8."},"AAM":{"_":"aam","*":"Adjust AX after multiply to number base imm8."},"AAS":{"_":"aas","*":"ASCII adjust AL after subtraction."},"ADC":{"_":"adc","*":"Add with CF r/m64 to r64."},"ADCX":{"_":"adcx","*":"Unsigned addition of r64 with CF, r/m64 to r64, writes CF."},"ADD":{"_":"add","*":"Add r/m64 to r64."},"ADDPD":{"_":"addpd","*":"Add packed double-precision floating-point values from xmm2/mem to xmm1 and store result in xmm1."},"VADDPD":{"_":"addpd","*":"Add packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1."},"ADDPS":{"_":"addps","*":"Add packed single-precision floating-point values from xmm2/m128 to xmm1 and store result in xmm1."},"VADDPS":{"_":"addps","*":"Add packed single-precision floating-point values from zmm3/m512/m32bcst to zmm2 and store result in zmm1 with writemask k1."},"ADDSD":{"_":"addsd","*":"Add the low double-precision floating-point value from xmm2/mem to xmm1 and store the result in xmm1."},"VADDSD":{"_":"addsd","*":"Add the low double-precision floating-point value from xmm3/m64 to xmm2 and store the result in xmm1 with writemask k1."},"ADDSS":{"_":"addss","*":"Add the low single-precision floating-point value from xmm2/mem to xmm1 and store the result in xmm1."},"VADDSS":{"_":"addss","*":"Add the low single-precision floating-point value from xmm3/m32 to xmm2 and store the result in xmm1with writemask k1."},"ADDSUBPD":{"_":"addsubpd","*":"Add/subtract double-precision floating-point values from xmm2/m128 to xmm1."},"VADDSUBPD":{"_":"addsubpd","*":"Add / subtract packed double-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1."},"ADDSUBPS":{"_":"addsubps","*":"Add/subtract single-precision floating-point values from xmm2/m128 to xmm1."},"VADDSUBPS":{"_":"addsubps","*":"Add / subtract single-precision floating-point values from ymm3/mem to ymm2 and stores result in ymm1."},"ADOX":{"_":"adox","*":"Unsigned addition of r64 with OF, r/m64 to r64, writes OF."},"AESDEC":{"_":"aesdec","*":"Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128."},"VAESDEC":{"_":"aesdec","*":"Perform one round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1."},"AESDECLAST":{"_":"aesdeclast","*":"Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128."},"VAESDECLAST":{"_":"aesdeclast","*":"Perform the last round of an AES decryption flow, using the Equivalent Inverse Cipher, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from xmm3/m128; store the result in xmm1."},"AESENC":{"_":"aesenc","*":"Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128."},"VAESENC":{"_":"aesenc","*":"Perform one round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128-bit round key from the xmm3/m128; store the result in xmm1."},"AESENCLAST":{"_":"aesenclast","*":"Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm1 with a 128-bit round key from xmm2/m128."},"VAESENCLAST":{"_":"aesenclast","*":"Perform the last round of an AES encryption flow, operating on a 128-bit data (state) from xmm2 with a 128 bit round key from xmm3/m128; store the result in xmm1."},"AESIMC":{"_":"aesimc","*":"Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1."},"VAESIMC":{"_":"aesimc","*":"Perform the InvMixColumn transformation on a 128-bit round key from xmm2/m128 and store the result in xmm1."},"AESKEYGENASSIST":{"_":"aeskeygenassist","*":"Assist in AES round key generation using an 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1."},"VAESKEYGENASSIST":{"_":"aeskeygenassist","*":"Assist in AES round key generation using 8 bits Round Constant (RCON) specified in the immediate byte, operating on 128 bits of data specified in xmm2/m128 and stores the result in xmm1."},"AND":{"_":"and","*":"r64 AND r/m64."},"ANDN":{"_":"andn","*":"Bitwise AND of inverted r32b with r/m32, store result in r32a."},"ANDNPD":{"_":"andnpd","*":"Return the bitwise logical AND NOT of packed double-precision floating-point values in xmm1 and xmm2/mem."},"VANDNPD":{"_":"andnpd","*":"Return the bitwise logical AND NOT of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1."},"ANDNPS":{"_":"andnps","*":"Return the bitwise logical AND NOT of packed single-precision floating-point values in xmm1 and xmm2/mem."},"VANDNPS":{"_":"andnps","*":"Return the bitwise logical AND of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1."},"ANDPD":{"_":"andpd","*":"Return the bitwise logical AND of packed double-precision floating-point values in xmm1 and xmm2/mem."},"VANDPD":{"_":"andpd","*":"Return the bitwise logical AND of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1."},"ANDPS":{"_":"andps","*":"Return the bitwise logical AND of packed single-precision floating-point values in xmm1 and xmm2/mem."},"VANDPS":{"_":"andps","*":"Return the bitwise logical AND of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1."},"ARPL":{"_":"arpl","*":"Adjust RPL of r/m16 to not less than RPL of r16."},"BEXTR":{"_":"bextr","*":"Contiguous bitwise extract from r/m64 using r64b as control; store result in r64a"},"BLENDPD":{"_":"blendpd","*":"Select packed DP-FP values from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1."},"VBLENDPD":{"_":"blendpd","*":"Select packed double-precision floating-point Values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1."},"BLENDPS":{"_":"blendps","*":"Select packed single precision floating-point values from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1."},"VBLENDPS":{"_":"blendps","*":"Select packed single-precision floating-point values from ymm2 and ymm3/m256 from mask in imm8 and store the values in ymm1."},"BLENDVPD":{"_":"blendvpd","*":"Select packed DP FP values from xmm1 and xmm2 from mask specified in XMM0 and store the values in xmm1."},"VBLENDVPD":{"_":"blendvpd","*":"Conditionally copy double-precision floating-point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the mask operand, ymm4."},"BLENDVPS":{"_":"blendvps","*":"Select packed single precision floating-point values from xmm1 and xmm2/m128 from mask specified in XMM0 and store the values into xmm1."},"VBLENDVPS":{"_":"blendvps","*":"Conditionally copy single-precision floating-point values from ymm2 or ymm3/m256 to ymm1, based on mask bits in the specified mask register, ymm4."},"BLSI":{"_":"blsi","*":"Extract lowest set bit from r/m64, and set that bit in r64."},"BLSMSK":{"_":"blsmsk","*":"Set all lower bits in r64 to “1” starting from bit 0 to lowest set bit in r/m64."},"BLSR":{"_":"blsr","*":"Reset lowest set bit of r/m64, keep all other bits of r/m64 and write result to r64."},"BNDCL":{"_":"bndcl","*":"Generate a #BR if the address in r/m64 is lower than the lower bound in bnd.LB."},"BNDCU:BNDCN":{"_":"bndcu:bndcn","*":"Compare the address in the second operand with the upper bound in bnd. The second operand can be either a register or a memory operand. If the address is higher than the upper bound in bnd.UB, it will set BNDSTATUS to 01H and signal a #BR exception."},"BNDCU":{"_":"bndcu:bndcn","*":"Generate a #BR if the address in r/m64 is higher than the upper bound in bnd.UB (bnb.UB in 1\'s complement form)."},"BNDCN":{"_":"bndcu:bndcn","*":"Generate a #BR if the address in r/m64 is higher than the upper bound in bnd.UB (bnb.UB not in 1\'s complement form)."},"BNDLDX":{"_":"bndldx","*":"Load the bounds stored in a bound table entry (BTE) into bnd with address translation using the base of mib and conditional on the index of mib matching the pointer value in the BTE."},"BNDMK":{"_":"bndmk","*":"Make lower and upper bounds from m64 and store them in bnd."},"BNDMOV":{"_":"bndmov","*":"Move lower and upper bound from bnd2 to bound register bnd1/m128."},"BNDSTX":{"_":"bndstx","*":"Store the bounds in bnd and the pointer value in the index register of mib to a bound table entry (BTE) with address translation using the base of mib."},"BOUND":{"_":"bound","*":"Check if r32 (array index) is within bounds specified by m32&32."},"BSF":{"_":"bsf","*":"Bit scan forward on r/m64."},"BSR":{"_":"bsr","*":"Bit scan reverse on r/m64."},"BSWAP":{"_":"bswap","*":"Reverses the byte order of a 64-bit register."},"BT":{"_":"bt","*":"Store selected bit in CF flag."},"BTC":{"_":"btc","*":"Store selected bit in CF flag and complement."},"BTR":{"_":"btr","*":"Store selected bit in CF flag and clear."},"BTS":{"_":"bts","*":"Store selected bit in CF flag and set."},"BZHI":{"_":"bzhi","*":"Zero bits in r/m64 starting with the position in r64b, write result to r64a."},"CALL":{"_":"call","*":"In 64-bit mode: If selector points to a gate, then RIP = 64-bit displacement taken from gate; else RIP = 64-bit offset from far pointer referenced in the instruction."},"CBW:CWDE:CDQE":{"_":"cbw:cwde:cdqe","*":"Double the size of the source operand by means of sign extension. The CBW (convert byte to word) instruction copies the sign (bit 7) in the source operand into every bit in the AH register. The CWDE (convert word to double-word) instruction copies the sign (bit 15) of the word in the AX register into the high 16 bits of the EAX register."},"CDQE":{"_":"cbw:cwde:cdqe","*":"RAX ← sign-extend of EAX."},"CWDE":{"_":"cbw:cwde:cdqe","*":"EAX ← sign-extend of AX."},"CBW":{"_":"cbw:cwde:cdqe","*":"AX ← sign-extend of AL."},"CLAC":{"_":"clac","*":"Clear the AC flag in the EFLAGS register."},"CLC":{"_":"clc","*":"Clear CF flag."},"CLD":{"_":"cld","*":"Clear DF flag."},"CLDEMOTE":{"_":"cldemote","*":"Hint to hardware to move the cache line containing m8 to a more distant level of the cache without writing back to memory."},"CLFLUSH":{"_":"clflush","*":"Flushes cache line containing m8."},"CLI":{"_":"cli","*":"Clear interrupt flag; interrupts disabled when interrupt flag cleared."},"CLTS":{"_":"clts","*":"Clears TS flag in CR0."},"CLWB":{"_":"clwb","*":"Writes back modified cache line containing m8, and may retain the line in cache hierarchy in non-modified state."},"CMC":{"_":"cmc","*":"Complement CF flag."},"CMOVCC":{"_":"cmovcc","*":"The CMOVcc instructions check the state of one or more of the status flags in the EFLAGS register (CF, OF, PF, SF, and ZF) and perform a move operation if the flags are in a specified state (or condition). A condition code (cc) is associated with each instruction to indicate the condition being tested for. If the condition is not satisfied, a move is not performed and execution continues with the instruction following the CMOVcc instruction."},"CMOVPO":{"_":"cmovcc","*":"Move if parity odd (PF=0)."},"CMOVNZ":{"_":"cmovcc","*":"Move if not zero (ZF=0)."},"CMOVP":{"_":"cmovcc","*":"Move if parity (PF=1)."},"CMOVAE":{"_":"cmovcc","*":"Move if above or equal (CF=0)."},"CMOVPE":{"_":"cmovcc","*":"Move if parity even (PF=1)."},"CMOVB":{"_":"cmovcc","*":"Move if below (CF=1)."},"CMOVNS":{"_":"cmovcc","*":"Move if not sign (SF=0)."},"CMOVC":{"_":"cmovcc","*":"Move if carry (CF=1)."},"CMOVBE":{"_":"cmovcc","*":"Move if below or equal (CF=1 or ZF=1)."},"CMOVNC":{"_":"cmovcc","*":"Move if not carry (CF=0)."},"CMOVNO":{"_":"cmovcc","*":"Move if not overflow (OF=0)."},"CMOVE":{"_":"cmovcc","*":"Move if equal (ZF=1)."},"CMOVLE":{"_":"cmovcc","*":"Move if less or equal (ZF=1 or SF≠ OF)."},"CMOVNL":{"_":"cmovcc","*":"Move if not less (SF=OF)."},"CMOVNLE":{"_":"cmovcc","*":"Move if not less or equal (ZF=0 and SF=OF)."},"CMOVNAE":{"_":"cmovcc","*":"Move if not above or equal (CF=1)."},"CMOVNG":{"_":"cmovcc","*":"Move if not greater (ZF=1 or SF≠ OF)."},"CMOVNBE":{"_":"cmovcc","*":"Move if not below or equal (CF=0 and ZF=0)."},"CMOVNA":{"_":"cmovcc","*":"Move if not above (CF=1 or ZF=1)."},"CMOVGE":{"_":"cmovcc","*":"Move if greater or equal (SF=OF)."},"CMOVNE":{"_":"cmovcc","*":"Move if not equal (ZF=0)."},"CMOVL":{"_":"cmovcc","*":"Move if less (SF≠ OF)."},"CMOVA":{"_":"cmovcc","*":"Move if above (CF=0 and ZF=0)."},"CMOVZ":{"_":"cmovcc","*":"Move if zero (ZF=1)."},"CMOVNP":{"_":"cmovcc","*":"Move if not parity (PF=0)."},"CMOVG":{"_":"cmovcc","*":"Move if greater (ZF=0 and SF=OF)."},"CMOVO":{"_":"cmovcc","*":"Move if overflow (OF=1)."},"CMOVS":{"_":"cmovcc","*":"Move if sign (SF=1)."},"CMOVNGE":{"_":"cmovcc","*":"Move if not greater or equal (SF≠ OF)."},"CMOVNB":{"_":"cmovcc","*":"Move if not below (CF=0)."},"CMP":{"_":"cmp","*":"Compare r/m64 with r64."},"CMPPD":{"_":"cmppd","*":"Compare packed double-precision floating-point values in xmm2/m128 and xmm1 using bits 2:0 of imm8 as a comparison predicate."},"VCMPPD":{"_":"cmppd","*":"Compare packed double-precision floating-point values in zmm3/m512/m64bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1."},"CMPPS":{"_":"cmpps","*":"Compare packed single-precision floating-point values in xmm2/m128 and xmm1 using bits 2:0 of imm8 as a comparison predicate."},"VCMPPS":{"_":"cmpps","*":"Compare packed single-precision floating-point values in zmm3/m512/m32bcst and zmm2 using bits 4:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1."},"CMPS:CMPSB:CMPSW:CMPSD:CMPSQ":{"_":"cmps:cmpsb:cmpsw:cmpsd:cmpsq","*":"Compares the byte, word, doubleword, or quadword specified with the first source operand with the byte, word, doubleword, or quadword specified with the second source operand and sets the status flags in the EFLAGS register according to the results."},"CMPSW":{"_":"cmps:cmpsb:cmpsw:cmpsd:cmpsq","*":"For legacy mode, compare word at address DS:(E)SI with word at address ES:(E)DI; For 64-bit mode compare word at address (R|E)SI with word at address (R|E)DI. The status flags are set accordingly."},"CMPSB":{"_":"cmps:cmpsb:cmpsw:cmpsd:cmpsq","*":"For legacy mode, compare byte at address DS:(E)SI with byte at address ES:(E)DI; For 64-bit mode compare byte at address (R|E)SI with byte at address (R|E)DI. The status flags are set accordingly."},"CMPSQ":{"_":"cmps:cmpsb:cmpsw:cmpsd:cmpsq","*":"Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly."},"CMPS":{"_":"cmps:cmpsb:cmpsw:cmpsd:cmpsq","*":"Compares quadword at address (R|E)SI with quadword at address (R|E)DI and sets the status flags accordingly."},"CMPSD":{"_":"cmps:cmpsb:cmpsw:cmpsd:cmpsq","*":"For legacy mode, compare dword at address DS:(E)SI with dword at address ES:(E)DI; For 64-bit mode compare dword at address (R|E)SI with dword at address (R|E)DI. The status flags are set accordingly."},"CMPSS":{"_":"cmpss","*":"Compare low single-precision floating-point value in xmm2/m32 and xmm1 using bits 2:0 of imm8 as comparison predicate."},"VCMPSS":{"_":"cmpss","*":"Compare low single-precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1."},"CMPXCHG":{"_":"cmpxchg","*":"Compare EAX with r/m32. If equal, ZF is set and r32 is loaded into r/m32. Else, clear ZF and load r/m32 into EAX."},"CMPXCHG8B:CMPXCHG16B":{"_":"cmpxchg8b:cmpxchg16b","*":"Compares the 64-bit value in EDX:EAX (or 128-bit value in RDX:RAX if operand size is 128 bits) with the operand (destination operand). If the values are equal, the 64-bit value in ECX:EBX (or 128-bit value in RCX:RBX) is stored in the destination operand. Otherwise, the value in the destination operand is loaded into EDX:EAX (or RDX:RAX). The destination operand is an 8-byte memory location (or 16-byte memory location if operand size is 128 bits). For the EDX:EAX and ECX:EBX register pairs, EDX and ECX contain the high-order 32 bits and EAX and EBX contain the low-order 32 bits of a 64-bit value. For the RDX:RAX and RCX:RBX register pairs, RDX and RCX contain the high-order 64 bits and RAX and RBX contain the low-order 64bits of a 128-bit value."},"CMPXCHG8B":{"_":"cmpxchg8b:cmpxchg16b","*":"Compare EDX:EAX with m64. If equal, set ZF and load ECX:EBX into m64. Else, clear ZF and load m64 into EDX:EAX."},"COMISD":{"_":"comisd","*":"Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly."},"VCOMISD":{"_":"comisd","*":"Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly."},"COMISS":{"_":"comiss","*":"Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly."},"VCOMISS":{"_":"comiss","*":"Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly."},"CPUID":{"_":"cpuid","*":"Returns processor identification and feature information to the EAX, EBX, ECX, and EDX registers, as determined by input entered in EAX (in some cases, ECX as well)."},"CRC32":{"_":"crc32","*":"Accumulate CRC32 on r/m64."},"CVTDQ2PD":{"_":"cvtdq2pd","*":"Convert two packed signed doubleword integers from xmm2/mem to two packed double-precision floating-point values in xmm1."},"VCVTDQ2PD":{"_":"cvtdq2pd","*":"Convert eight packed signed doubleword integers from ymm2/m256/m32bcst to eight packed double-precision floating-point values in zmm1 with writemask k1."},"CVTDQ2PS":{"_":"cvtdq2ps","*":"Convert four packed signed doubleword integers from xmm2/mem to four packed single-precision floating-point values in xmm1."},"VCVTDQ2PS":{"_":"cvtdq2ps","*":"Convert sixteen packed signed doubleword integers from zmm2/m512/m32bcst to sixteen packed single-precision floating-point values in zmm1with writemask k1."},"CVTPD2DQ":{"_":"cvtpd2dq","*":"Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1."},"VCVTPD2DQ":{"_":"cvtpd2dq","*":"Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight signed doubleword integers in ymm1 subject to writemask k1."},"CVTPD2PI":{"_":"cvtpd2pi","*":"Convert two packed double-precision floating-point values from xmm/m128 to two packed signed doubleword integers in mm."},"CVTPD2PS":{"_":"cvtpd2ps","*":"Convert two packed double-precision floating-point values in xmm2/mem to two single-precision floating-point values in xmm1."},"VCVTPD2PS":{"_":"cvtpd2ps","*":"Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight single-precision floating-point values in ymm1with writemask k1."},"CVTPI2PD":{"_":"cvtpi2pd","*":"Convert two packed signed doubleword integers from mm/mem64 to two packed double-precision floating-point values in xmm."},"CVTPI2PS":{"_":"cvtpi2ps","*":"Convert two signed doubleword integers from mm/m64 to two single-precision floating-point values in xmm."},"CVTPS2DQ":{"_":"cvtps2dq","*":"Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1."},"VCVTPS2DQ":{"_":"cvtps2dq","*":"Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed signed doubleword values in zmm1 subject to writemask k1."},"CVTPS2PD":{"_":"cvtps2pd","*":"Convert two packed single-precision floating-point values in xmm2/m64 to two packed double-precision floating-point values in xmm1."},"VCVTPS2PD":{"_":"cvtps2pd","*":"Convert eight packed single-precision floating-point values in ymm2/m256/b32bcst to eight packed double-precision floating-point values in zmm1 with writemask k1."},"CVTPS2PI":{"_":"cvtps2pi","*":"Convert two packed single-precision floating-point values from xmm/m64 to two packed signed doubleword integers in mm."},"CVTSD2SI":{"_":"cvtsd2si","*":"Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer sign-extended into r64."},"VCVTSD2SI":{"_":"cvtsd2si","*":"Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer sign-extended into r64."},"CVTSD2SS":{"_":"cvtsd2ss","*":"Convert one double-precision floating-point value in xmm2/m64 to one single-precision floating-point value in xmm1."},"VCVTSD2SS":{"_":"cvtsd2ss","*":"Convert one double-precision floating-point value in xmm3/m64 to one single-precision floating-point value and merge with high bits in xmm2 under writemask k1."},"CVTSI2SD":{"_":"cvtsi2sd","*":"Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1."},"VCVTSI2SD":{"_":"cvtsi2sd","*":"Convert one signed quadword integer from r/m64 to one double-precision floating-point value in xmm1."},"CVTSI2SS":{"_":"cvtsi2ss","*":"Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1."},"VCVTSI2SS":{"_":"cvtsi2ss","*":"Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1."},"CVTSS2SD":{"_":"cvtss2sd","*":"Convert one single-precision floating-point value in xmm2/m32 to one double-precision floating-point value in xmm1."},"VCVTSS2SD":{"_":"cvtss2sd","*":"Convert one single-precision floating-point value in xmm3/m32 to one double-precision floating-point value and merge with high bits of xmm2 under writemask k1."},"CVTSS2SI":{"_":"cvtss2si","*":"Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64."},"VCVTSS2SI":{"_":"cvtss2si","*":"Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64."},"CVTTPD2DQ":{"_":"cvttpd2dq","*":"Convert two packed double-precision floating-point values in xmm2/mem to two signed doubleword integers in xmm1 using truncation."},"VCVTTPD2DQ":{"_":"cvttpd2dq","*":"Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight signed doubleword integers in ymm1 using truncation subject to writemask k1."},"CVTTPD2PI":{"_":"cvttpd2pi","*":"Convert two packer double-precision floating-point values from xmm/m128 to two packed signed doubleword integers in mm using truncation."},"CVTTPS2DQ":{"_":"cvttps2dq","*":"Convert four packed single-precision floating-point values from xmm2/mem to four packed signed doubleword values in xmm1 using truncation."},"VCVTTPS2DQ":{"_":"cvttps2dq","*":"Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed signed doubleword values in zmm1 using truncation subject to writemask k1."},"CVTTPS2PI":{"_":"cvttps2pi","*":"Convert two single-precision floating-point values from xmm/m64 to two signed doubleword signed integers in mm using truncation."},"CVTTSD2SI":{"_":"cvttsd2si","*":"Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation."},"VCVTTSD2SI":{"_":"cvttsd2si","*":"Convert one double-precision floating-point value from xmm1/m64 to one signed quadword integer in r64 using truncation."},"CVTTSS2SI":{"_":"cvttss2si","*":"Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation."},"VCVTTSS2SI":{"_":"cvttss2si","*":"Convert one single-precision floating-point value from xmm1/m32 to one signed quadword integer in r64 using truncation."},"CWD:CDQ:CQO":{"_":"cwd:cdq:cqo","*":"Doubles the size of the operand in register AX, EAX, or RAX (depending on the operand size) by means of sign extension and stores the result in registers DX:AX, EDX:EAX, or RDX:RAX, respectively. The CWD instruction copies the sign (bit 15) of the value in the AX register into every bit position in the DX register. The CDQ instruction copies the sign (bit 31) of the value in the EAX register into every bit position in the EDX register. The CQO instruction (available in 64-bit mode only) copies the sign (bit 63) of the value in the RAX register into every bit position in the RDX register."},"CWD":{"_":"cwd:cdq:cqo","*":"DX:AX ← sign-extend of AX."},"CDQ":{"_":"cwd:cdq:cqo","*":"EDX:EAX ← sign-extend of EAX."},"CQO":{"_":"cwd:cdq:cqo","*":"RDX:RAX← sign-extend of RAX."},"DAA":{"_":"daa","*":"Decimal adjust AL after addition."},"DAS":{"_":"das","*":"Decimal adjust AL after subtraction."},"DEC":{"_":"dec","*":"Decrement r32 by 1."},"DIV":{"_":"div","*":"Unsigned divide RDX:RAX by r/m64, with result stored in RAX ← Quotient, RDX ← Remainder."},"DIVPD":{"_":"divpd","*":"Divide packed double-precision floating-point values in xmm1 by packed double-precision floating-point values in xmm2/mem."},"VDIVPD":{"_":"divpd","*":"Divide packed double-precision floating-point values in zmm2 by packed double-precision FP values in zmm3/m512/m64bcst and write results to zmm1 subject to writemask k1."},"DIVPS":{"_":"divps","*":"Divide packed single-precision floating-point values in xmm1 by packed single-precision floating-point values in xmm2/mem."},"VDIVPS":{"_":"divps","*":"Divide packed single-precision floating-point values in zmm2 by packed single-precision floating-point values in zmm3/m512/m32bcst and write results to zmm1 subject to writemask k1."},"DIVSD":{"_":"divsd","*":"Divide low double-precision floating-point value in xmm1 by low double-precision floating-point value in xmm2/m64."},"VDIVSD":{"_":"divsd","*":"Divide low double-precision floating-point value in xmm2 by low double-precision floating-point value in xmm3/m64."},"DIVSS":{"_":"divss","*":"Divide low single-precision floating-point value in xmm1 by low single-precision floating-point value in xmm2/m32."},"VDIVSS":{"_":"divss","*":"Divide low single-precision floating-point value in xmm2 by low single-precision floating-point value in xmm3/m32."},"DPPD":{"_":"dppd","*":"Selectively multiply packed DP floating-point values from xmm1 with packed DP floating-point values from xmm2, add and selectively store the packed DP floating-point values to xmm1."},"VDPPD":{"_":"dppd","*":"Selectively multiply packed DP floating-point values from xmm2 with packed DP floating-point values from xmm3, add and selectively store the packed DP floating-point values to xmm1."},"DPPS":{"_":"dpps","*":"Selectively multiply packed SP floating-point values from xmm1 with packed SP floating-point values from xmm2, add and selectively store the packed SP floating-point values or zero values to xmm1."},"VDPPS":{"_":"dpps","*":"Multiply packed single-precision floating-point values from ymm2 with packed SP floating point values from ymm3/mem, selectively add pairs of elements and store to ymm1."},"EMMS":{"_":"emms","*":"Set the x87 FPU tag word to empty."},"ENCLV":{"_":"enclv","*":"This instruction is used to execute privileged SGX leaf functions that are reserved for VMM use. They are used for managing the enclaves."},"ENTER":{"_":"enter","*":"Create a stack frame with nested pointers for a procedure."},"EXTRACTPS":{"_":"extractps","*":"Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in reg or m32. Zero extend the results in 64-bit register if applicable."},"VEXTRACTPS":{"_":"extractps","*":"Extract one single-precision floating-point value from xmm1 at the offset specified by imm8 and store the result in reg or m32. Zero extend the results in 64-bit register if applicable."},"F2XM1":{"_":"f2xm1","*":"Replace ST(0) with (2ST(0) – 1)."},"FABS":{"_":"fabs","*":"Replace ST with its absolute value."},"FADD:FADDP:FIADD":{"_":"fadd:faddp:fiadd","*":"Adds the destination and source operands and stores the sum in the destination location. The destination operand is always an FPU register; the source operand can be a register or a memory location. Source operands in memory can be in single-precision or double-precision floating-point format or in word or doubleword integer format."},"FIADD":{"_":"fadd:faddp:fiadd","*":"Add m16int to ST(0) and store result in ST(0)."},"FADDP":{"_":"fadd:faddp:fiadd","*":"Add ST(0) to ST(1), store result in ST(1), and pop the register stack."},"FADD":{"_":"fadd:faddp:fiadd","*":"Add ST(i) to ST(0) and store result in ST(i)."},"FBLD":{"_":"fbld","*":"Convert BCD value to floating-point and push onto the FPU stack."},"FBSTP":{"_":"fbstp","*":"Store ST(0) in m80bcd and pop ST(0)."},"FCHS":{"_":"fchs","*":"Complements sign of ST(0)."},"FCLEX:FNCLEX":{"_":"fclex:fnclex","*":"Clears the floating-point exception flags (PE, UE, OE, ZE, DE, and IE), the exception summary status flag (ES), the stack fault flag (SF), and the busy flag (B) in the FPU status word. The FCLEX instruction checks for and handles any pending unmasked floating-point exceptions before clearing the exception flags; the FNCLEX instruction does not."},"FNCLEX":{"_":"fclex:fnclex","*":"Clear floating-point exception flags without checking for pending unmasked floating-point exceptions."},"FCLEX":{"_":"fclex:fnclex","*":"Clear floating-point exception flags after checking for pending unmasked floating-point exceptions."},"FCMOVCC":{"_":"fcmovcc","*":"Tests the status flags in the EFLAGS register and moves the source operand (second operand) to the destination operand (first operand) if the given test condition is true. The condition for each mnemonic os given in the Description column above and in Chapter 8 in the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1. The source operand is always in the ST(i) register and the destination operand is always ST(0)."},"FCMOVB":{"_":"fcmovcc","*":"Move if below (CF=1)."},"FCMOVNE":{"_":"fcmovcc","*":"Move if not equal (ZF=0)."},"FCMOVBE":{"_":"fcmovcc","*":"Move if below or equal (CF=1 or ZF=1)."},"FCMOVU":{"_":"fcmovcc","*":"Move if unordered (PF=1)."},"FCMOVE":{"_":"fcmovcc","*":"Move if equal (ZF=1)."},"FCMOVNU":{"_":"fcmovcc","*":"Move if not unordered (PF=0)."},"FCMOVNB":{"_":"fcmovcc","*":"Move if not below (CF=0)."},"FCMOVNBE":{"_":"fcmovcc","*":"Move if not below or equal (CF=0 and ZF=0)."},"FCOM:FCOMP:FCOMPP":{"_":"fcom:fcomp:fcompp","*":"Compares the contents of register ST(0) and source value and sets condition code flags C0, C2, and C3 in the FPU status word according to the results (see the table below). The source operand can be a data register or a memory location. If no source operand is given, the value in ST(0) is compared with the value in ST(1). The sign of zero is ignored, so that –0.0 is equal to +0.0."},"FCOMP":{"_":"fcom:fcomp:fcompp","*":"Compare ST(0) with ST(1) and pop register stack."},"FCOM":{"_":"fcom:fcomp:fcompp","*":"Compare ST(0) with ST(1)."},"FCOMPP":{"_":"fcom:fcomp:fcompp","*":"Compare ST(0) with ST(1) and pop register stack twice."},"FCOMI:FCOMIP:FUCOMI:FUCOMIP":{"_":"fcomi:fcomip:fucomi:fucomip","*":"Performs an unordered comparison of the contents of registers ST(0) and ST(i) and sets the status flags ZF, PF, and CF in the EFLAGS register according to the results (see the table below). The sign of zero is ignored for comparisons, so that –0.0 is equal to +0.0."},"FUCOMIP":{"_":"fcomi:fcomip:fucomi:fucomip","*":"Compare ST(0) with ST(i), check for ordered values, set status flags accordingly, and pop register stack."},"FUCOMI":{"_":"fcomi:fcomip:fucomi:fucomip","*":"Compare ST(0) with ST(i), check for ordered values, and set status flags accordingly."},"FCOMI":{"_":"fcomi:fcomip:fucomi:fucomip","*":"Compare ST(0) with ST(i) and set status flags accordingly."},"FCOMIP":{"_":"fcomi:fcomip:fucomi:fucomip","*":"Compare ST(0) with ST(i), set status flags accordingly, and pop register stack."},"FCOS":{"_":"fcos","*":"Replace ST(0) with its approximate cosine."},"FDECSTP":{"_":"fdecstp","*":"Decrement TOP field in FPU status word."},"FDIV:FDIVP:FIDIV":{"_":"fdiv:fdivp:fidiv","*":"Divides the destination operand by the source operand and stores the result in the destination location. The destination operand (dividend) is always in an FPU register; the source operand (divisor) can be a register or a memory location. Source operands in memory can be in single-precision or double-precision floating-point format, word or doubleword integer format."},"FDIV":{"_":"fdiv:fdivp:fidiv","*":"Divide ST(i) by ST(0) and store result in ST(i)."},"FDIVP":{"_":"fdiv:fdivp:fidiv","*":"Divide ST(1) by ST(0), store result in ST(1), and pop the register stack."},"FIDIV":{"_":"fdiv:fdivp:fidiv","*":"Divide ST(0) by m16int and store result in ST(0)."},"FDIVR:FDIVRP:FIDIVR":{"_":"fdivr:fdivrp:fidivr","*":"Divides the source operand by the destination operand and stores the result in the destination location. The destination operand (divisor) is always in an FPU register; the source operand (dividend) can be a register or a memory location. Source operands in memory can be in single-precision or double-precision floating-point format, word or doubleword integer format."},"FDIVR":{"_":"fdivr:fdivrp:fidivr","*":"Divide ST(0) by ST(i) and store result in ST(i)."},"FDIVRP":{"_":"fdivr:fdivrp:fidivr","*":"Divide ST(0) by ST(1), store result in ST(1), and pop the register stack."},"FIDIVR":{"_":"fdivr:fdivrp:fidivr","*":"Divide m16int by ST(0) and store result in ST(0)."},"FFREE":{"_":"ffree","*":"Sets tag for ST(i) to empty."},"FICOM:FICOMP":{"_":"ficom:ficomp","*":"Compares the value in ST(0) with an integer source operand and sets the condition code flags C0, C2, and C3 in the FPU status word according to the results (see table below). The integer value is converted to double extended-precision floating-point format before the comparison is made."},"FICOM":{"_":"ficom:ficomp","*":"Compare ST(0) with m32int."},"FICOMP":{"_":"ficom:ficomp","*":"Compare ST(0) with m32int and pop stack register."},"FILD":{"_":"fild","*":"Push m64int onto the FPU register stack."},"FINCSTP":{"_":"fincstp","*":"Increment the TOP field in the FPU status register."},"FINIT:FNINIT":{"_":"finit:fninit","*":"Sets the FPU control, status, tag, instruction pointer, and data pointer registers to their default states. The FPU control word is set to 037FH (round to nearest, all exceptions masked, 64-bit precision). The status word is cleared (no exception flags set, TOP is set to 0). The data registers in the register stack are left unchanged, but they are all tagged as empty (11B). Both the instruction and data pointers are cleared."},"FINIT":{"_":"finit:fninit","*":"Initialize FPU after checking for pending unmasked floating-point exceptions."},"FNINIT":{"_":"finit:fninit","*":"Initialize FPU without checking for pending unmasked floating-point exceptions."},"FIST:FISTP":{"_":"fist:fistp","*":"The FIST instruction converts the value in the ST(0) register to a signed integer and stores the result in the destination operand. Values can be stored in word or doubleword integer format. The destination operand specifies the address where the first byte of the destination value is to be stored."},"FISTP":{"_":"fist:fistp","*":"Store ST(0) in m64int and pop register stack."},"FIST":{"_":"fist:fistp","*":"Store ST(0) in m32int."},"FISTTP":{"_":"fisttp","*":"Store ST(0) in m64int with truncation."},"FLD":{"_":"fld","*":"Push ST(i) onto the FPU register stack."},"FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ":{"_":"fld1:fldl2t:fldl2e:fldpi:fldlg2:fldln2:fldz","*":"Push one of seven commonly used constants (in double extended-precision floating-point format) onto the FPU register stack. The constants that can be loaded with these instructions include +1.0, +0.0, log210, log2e, π, log102, and loge2. For each constant, an internal 66-bit constant is rounded (as specified by the RC field in the FPU control word) to double extended-precision floating-point format. The inexact-result exception (#P) is not generated as a result of the rounding, nor is the C1 flag set in the x87 FPU status word if the value is rounded up."},"FLDLG2":{"_":"fld1:fldl2t:fldl2e:fldpi:fldlg2:fldln2:fldz","*":"Push log102 onto the FPU register stack."},"FLDLN2":{"_":"fld1:fldl2t:fldl2e:fldpi:fldlg2:fldln2:fldz","*":"Push loge2 onto the FPU register stack."},"FLDL2T":{"_":"fld1:fldl2t:fldl2e:fldpi:fldlg2:fldln2:fldz","*":"Push log210 onto the FPU register stack."},"FLDL2E":{"_":"fld1:fldl2t:fldl2e:fldpi:fldlg2:fldln2:fldz","*":"Push log2e onto the FPU register stack."},"FLD1":{"_":"fld1:fldl2t:fldl2e:fldpi:fldlg2:fldln2:fldz","*":"Push +1.0 onto the FPU register stack."},"FLDPI":{"_":"fld1:fldl2t:fldl2e:fldpi:fldlg2:fldln2:fldz","*":"Push π onto the FPU register stack."},"FLDZ":{"_":"fld1:fldl2t:fldl2e:fldpi:fldlg2:fldln2:fldz","*":"Push +0.0 onto the FPU register stack."},"FLDCW":{"_":"fldcw","*":"Load FPU control word from m2byte."},"FLDENV":{"_":"fldenv","*":"Load FPU environment from m14byte or m28byte."},"FMUL:FMULP:FIMUL":{"_":"fmul:fmulp:fimul","*":"Multiplies the destination and source operands and stores the product in the destination location. The destination operand is always an FPU data register; the source operand can be an FPU data register or a memory location. Source operands in memory can be in single-precision or double-precision floating-point format or in word or doubleword integer format."},"FMUL":{"_":"fmul:fmulp:fimul","*":"Multiply ST(i) by ST(0) and store result in ST(i)."},"FIMUL":{"_":"fmul:fmulp:fimul","*":"Multiply ST(0) by m16int and store result in ST(0)."},"FMULP":{"_":"fmul:fmulp:fimul","*":"Multiply ST(1) by ST(0), store result in ST(1), and pop the register stack."},"FNOP":{"_":"fnop","*":"No operation is performed."},"FPATAN":{"_":"fpatan","*":"Replace ST(1) with arctan(ST(1)/ST(0)) and pop the register stack."},"FPREM":{"_":"fprem","*":"Replace ST(0) with the remainder obtained from dividing ST(0) by ST(1)."},"FPREM1":{"_":"fprem1","*":"Replace ST(0) with the IEEE remainder obtained from dividing ST(0) by ST(1)."},"FPTAN":{"_":"fptan","*":"Replace ST(0) with its approximate tangent and push 1 onto the FPU stack."},"FRNDINT":{"_":"frndint","*":"Round ST(0) to an integer."},"FRSTOR":{"_":"frstor","*":"Load FPU state from m94byte or m108byte."},"FSAVE:FNSAVE":{"_":"fsave:fnsave","*":"Stores the current FPU state (operating environment and register stack) at the specified destination in memory, and then re-initializes the FPU. The FSAVE instruction checks for and handles pending unmasked floating-point exceptions before storing the FPU state; the FNSAVE instruction does not."},"FNSAVE":{"_":"fsave:fnsave","*":"Store FPU environment to m94byte or m108byte without checking for pending unmasked floating-point exceptions. Then re-initialize the FPU."},"FSAVE":{"_":"fsave:fnsave","*":"Store FPU state to m94byte or m108byte after checking for pending unmasked floating-point exceptions. Then re-initialize the FPU."},"FSCALE":{"_":"fscale","*":"Scale ST(0) by ST(1)."},"FSIN":{"_":"fsin","*":"Replace ST(0) with the approximate of its sine."},"FSINCOS":{"_":"fsincos","*":"Compute the sine and cosine of ST(0); replace ST(0) with the approximate sine, and push the approximate cosine onto the register stack."},"FSQRT":{"_":"fsqrt","*":"Computes square root of ST(0) and stores the result in ST(0)."},"FST:FSTP":{"_":"fst:fstp","*":"The FST instruction copies the value in the ST(0) register to the destination operand, which can be a memory location or another register in the FPU register stack. When storing the value in memory, the value is converted to single-precision or double-precision floating-point format."},"FST":{"_":"fst:fstp","*":"Copy ST(0) to ST(i)."},"FSTP":{"_":"fst:fstp","*":"Copy ST(0) to ST(i) and pop register stack."},"FSTCW:FNSTCW":{"_":"fstcw:fnstcw","*":"Stores the current value of the FPU control word at the specified destination in memory. The FSTCW instruction checks for and handles pending unmasked floating-point exceptions before storing the control word; the FNSTCW instruction does not."},"FNSTCW":{"_":"fstcw:fnstcw","*":"Store FPU control word to m2byte without checking for pending unmasked floating-point exceptions."},"FSTCW":{"_":"fstcw:fnstcw","*":"Store FPU control word to m2byte after checking for pending unmasked floating-point exceptions."},"FSTENV:FNSTENV":{"_":"fstenv:fnstenv","*":"Saves the current FPU operating environment at the memory location specified with the destination operand, and then masks all floating-point exceptions. The FPU operating environment consists of the FPU control word, status word, tag word, instruction pointer, data pointer, and last opcode. Figures 8-9 through 8-12 in the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1, show the layout in memory of the stored environment, depending on the operating mode of the processor (protected or real) and the current operand-size attribute (16-bit or 32-bit). In virtual-8086 mode, the real mode layouts are used."},"FSTENV":{"_":"fstenv:fnstenv","*":"Store FPU environment to m14byte or m28byte after checking for pending unmasked floating-point exceptions. Then mask all floating-point exceptions."},"FNSTENV":{"_":"fstenv:fnstenv","*":"Store FPU environment to m14byte or m28byte without checking for pending unmasked floating-point exceptions. Then mask all floating-point exceptions."},"FSTSW:FNSTSW":{"_":"fstsw:fnstsw","*":"Stores the current value of the x87 FPU status word in the destination location. The destination operand can be either a two-byte memory location or the AX register. The FSTSW instruction checks for and handles pending unmasked floating-point exceptions before storing the status word; the FNSTSW instruction does not."},"FSTSW":{"_":"fstsw:fnstsw","*":"Store FPU status word in AX register after checking for pending unmasked floating-point exceptions."},"FNSTSW":{"_":"fstsw:fnstsw","*":"Store FPU status word in AX register without checking for pending unmasked floating-point exceptions."},"FSUB:FSUBP:FISUB":{"_":"fsub:fsubp:fisub","*":"Subtracts the source operand from the destination operand and stores the difference in the destination location. The destination operand is always an FPU data register; the source operand can be a register or a memory location. Source operands in memory can be in single-precision or double-precision floating-point format or in word or doubleword integer format."},"FISUB":{"_":"fsub:fsubp:fisub","*":"Subtract m16int from ST(0) and store result in ST(0)."},"FSUBP":{"_":"fsub:fsubp:fisub","*":"Subtract ST(0) from ST(1), store result in ST(1), and pop register stack."},"FSUB":{"_":"fsub:fsubp:fisub","*":"Subtract ST(0) from ST(i) and store result in ST(i)."},"FSUBR:FSUBRP:FISUBR":{"_":"fsubr:fsubrp:fisubr","*":"Subtracts the destination operand from the source operand and stores the difference in the destination location. The destination operand is always an FPU register; the source operand can be a register or a memory location. Source operands in memory can be in single-precision or double-precision floating-point format or in word or doubleword integer format."},"FSUBR":{"_":"fsubr:fsubrp:fisubr","*":"Subtract ST(i) from ST(0) and store result in ST(i)."},"FSUBRP":{"_":"fsubr:fsubrp:fisubr","*":"Subtract ST(1) from ST(0), store result in ST(1), and pop register stack."},"FISUBR":{"_":"fsubr:fsubrp:fisubr","*":"Subtract ST(0) from m16int and store result in ST(0)."},"FTST":{"_":"ftst","*":"Compare ST(0) with 0.0."},"FUCOM:FUCOMP:FUCOMPP":{"_":"fucom:fucomp:fucompp","*":"Performs an unordered comparison of the contents of register ST(0) and ST(i) and sets condition code flags C0, C2, and C3 in the FPU status word according to the results (see the table below). If no operand is specified, the contents of registers ST(0) and ST(1) are compared. The sign of zero is ignored, so that –0.0 is equal to +0.0."},"FUCOM":{"_":"fucom:fucomp:fucompp","*":"Compare ST(0) with ST(1)."},"FUCOMP":{"_":"fucom:fucomp:fucompp","*":"Compare ST(0) with ST(1) and pop register stack."},"FUCOMPP":{"_":"fucom:fucomp:fucompp","*":"Compare ST(0) with ST(1) and pop register stack twice."},"FXAM":{"_":"fxam","*":"Classify value or number in ST(0)."},"FXCH":{"_":"fxch","*":"Exchange the contents of ST(0) and ST(1)."},"FXRSTOR":{"_":"fxrstor","*":"Restore the x87 FPU, MMX, XMM, and MXCSR register state from m512byte."},"FXSAVE":{"_":"fxsave","*":"Save the x87 FPU, MMX, XMM, and MXCSR register state to m512byte."},"FXTRACT":{"_":"fxtract","*":"Separate value in ST(0) into exponent and significand, store exponent in ST(0), and push the significand onto the register stack."},"FYL2X":{"_":"fyl2x","*":"Replace ST(1) with (ST(1) ∗ log2ST(0)) and pop the register stack."},"FYL2XP1":{"_":"fyl2xp1","*":"Replace ST(1) with ST(1) ∗ log2(ST(0) + 1.0) and pop the register stack."},"HADDPD":{"_":"haddpd","*":"Horizontal add packed double-precision floating-point values from xmm2/m128 to xmm1."},"VHADDPD":{"_":"haddpd","*":"Horizontal add packed double-precision floating-point values from ymm2 and ymm3/mem."},"HADDPS":{"_":"haddps","*":"Horizontal add packed single-precision floating-point values from xmm2/m128 to xmm1."},"VHADDPS":{"_":"haddps","*":"Horizontal add packed single-precision floating-point values from ymm2 and ymm3/mem."},"HLT":{"_":"hlt","*":"Halt"},"HSUBPD":{"_":"hsubpd","*":"Horizontal subtract packed double-precision floating-point values from xmm2/m128 to xmm1."},"VHSUBPD":{"_":"hsubpd","*":"Horizontal subtract packed double-precision floating-point values from ymm2 and ymm3/mem."},"HSUBPS":{"_":"hsubps","*":"Horizontal subtract packed single-precision floating-point values from xmm2/m128 to xmm1."},"VHSUBPS":{"_":"hsubps","*":"Horizontal subtract packed single-precision floating-point values from ymm2 and ymm3/mem."},"IDIV":{"_":"idiv","*":"Signed divide RDX:RAX by r/m64, with result stored in RAX ← Quotient, RDX ← Remainder."},"IMUL":{"_":"imul","*":"Quadword register ← r/m64 ∗ immediate doubleword."},"IN":{"_":"in","*":"Input doubleword from I/O port in DX into EAX."},"INC":{"_":"inc","*":"Increment doubleword register by 1."},"INS:INSB:INSW:INSD":{"_":"ins:insb:insw:insd","*":"Copies the data from the I/O port specified with the source operand (second operand) to the destination operand (first operand). The source operand is an I/O port address (from 0 to 65,535) that is read from the DX register. The destination operand is a memory location, the address of which is read from either the ES:DI, ES:EDI or the RDI registers (depending on the address-size attribute of the instruction, 16, 32 or 64, respectively). (The ES segment cannot be overridden with a segment override prefix.) The size of the I/O port being accessed (that is, the size of the source and destination operands) is determined by the opcode for an 8-bit I/O port or by the operand-size attribute of the instruction for a 16- or 32-bit I/O port."},"INSD":{"_":"ins:insb:insw:insd","*":"Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.1"},"INS":{"_":"ins:insb:insw:insd","*":"Input doubleword from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.1"},"INSB":{"_":"ins:insb:insw:insd","*":"Input byte from I/O port specified in DX into memory location specified with ES:(E)DI or RDI.1"},"INSW":{"_":"ins:insb:insw:insd","*":"Input word from I/O port specified in DX into memory location specified in ES:(E)DI or RDI.1"},"INSERTPS":{"_":"insertps","*":"Insert a single-precision floating-point value selected by imm8 from xmm2/m32 into xmm1 at the specified destination element specified by imm8 and zero out destination elements in xmm1 as indicated in imm8."},"VINSERTPS":{"_":"insertps","*":"Insert a single-precision floating-point value selected by imm8 from xmm3/m32 and merge with values in xmm2 at the specified destination element specified by imm8 and write out the result and zero out destination elements in xmm1 as indicated in imm8."},"INTN:INTO:INT3:INT1":{"_":"intn:into:int3:int1","*":"The INT n instruction generates a call to the interrupt or exception handler specified with the destination operand (see the section titled “Interrupts and Exceptions” in Chapter 6 of the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1). The destination operand specifies a vector from 0 to 255, encoded as an 8-bit unsigned intermediate value. Each vector provides an index to a gate descriptor in the IDT. The first 32 vectors are reserved by Intel for system use. Some of these vectors are used for internally generated exceptions."},"INTO":{"_":"intn:into:int3:int1","*":"Generate overflow trap if overflow flag is 1."},"INT1":{"_":"intn:into:int3:int1","*":"Generate debug trap."},"INT3":{"_":"intn:into:int3:int1","*":"Generate breakpoint trap."},"INT":{"_":"intn:into:int3:int1","*":"Generate software interrupt with vector specified by immediate byte."},"INVD":{"_":"invd","*":"Flush internal caches; initiate flushing of external caches."},"INVPCID":{"_":"invpcid","*":"Invalidates entries in the TLBs and paging-structure caches based on invalidation type in r64 and descriptor in m128."},"IRET:IRETD":{"_":"iret:iretd","*":"Returns program control from an exception or interrupt handler to a program or procedure that was interrupted by an exception, an external interrupt, or a software-generated interrupt. These instructions are also used to perform a return from a nested task. (A nested task is created when a CALL instruction is used to initiate a task switch or when an interrupt or exception causes a task switch to an interrupt or exception handler.) See the section titled “Task Linking” in Chapter 7 of the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 3A."},"IRETD":{"_":"iret:iretd","*":"Interrupt return (32-bit operand size)."},"IRETQ":{"_":"iret:iretd","*":"Interrupt return (64-bit operand size)."},"IRET":{"_":"iret:iretd","*":"Interrupt return (16-bit operand size)."},"JMP":{"_":"jmp","*":"Jump far, absolute indirect, address given in m16:64."},"JCC":{"_":"jcc","*":"Checks the state of one or more of the status flags in the EFLAGS register (CF, OF, PF, SF, and ZF) and, if the flags are in the specified state (condition), performs a jump to the target instruction specified by the destination operand. A condition code (cc) is associated with each instruction to indicate the condition being tested for. If the condition is not satisfied, the jump is not performed and execution continues with the instruction following the Jcc instruction."},"JE":{"_":"jcc","*":"Jump near if equal (ZF=1)."},"JL":{"_":"jcc","*":"Jump near if less (SF≠ OF)."},"JLE":{"_":"jcc","*":"Jump near if less or equal (ZF=1 or SF≠ OF)."},"JNE":{"_":"jcc","*":"Jump near if not equal (ZF=0)."},"JCXZ":{"_":"jcc","*":"Jump short if CX register is 0."},"JC":{"_":"jcc","*":"Jump near if carry (CF=1)."},"JA":{"_":"jcc","*":"Jump near if above (CF=0 and ZF=0)."},"JECXZ":{"_":"jcc","*":"Jump short if ECX register is 0."},"JNZ":{"_":"jcc","*":"Jump near if not zero (ZF=0)."},"JB":{"_":"jcc","*":"Jump near if below (CF=1)."},"JNP":{"_":"jcc","*":"Jump near if not parity (PF=0)."},"JNLE":{"_":"jcc","*":"Jump near if not less or equal (ZF=0 and SF=OF)."},"JNG":{"_":"jcc","*":"Jump near if not greater (ZF=1 or SF≠ OF)."},"JNA":{"_":"jcc","*":"Jump near if not above (CF=1 or ZF=1)."},"JNC":{"_":"jcc","*":"Jump near if not carry (CF=0)."},"JRCXZ":{"_":"jcc","*":"Jump short if RCX register is 0."},"JPO":{"_":"jcc","*":"Jump near if parity odd (PF=0)."},"JNB":{"_":"jcc","*":"Jump near if not below (CF=0)."},"JNGE":{"_":"jcc","*":"Jump near if not greater or equal (SF≠ OF)."},"JNL":{"_":"jcc","*":"Jump near if not less (SF=OF)."},"JNS":{"_":"jcc","*":"Jump near if not sign (SF=0)."},"JP":{"_":"jcc","*":"Jump near if parity (PF=1)."},"JNO":{"_":"jcc","*":"Jump near if not overflow (OF=0)."},"JO":{"_":"jcc","*":"Jump near if overflow (OF=1)."},"JNBE":{"_":"jcc","*":"Jump near if not below or equal (CF=0 and ZF=0)."},"JAE":{"_":"jcc","*":"Jump near if above or equal (CF=0)."},"JPE":{"_":"jcc","*":"Jump near if parity even (PF=1)."},"JBE":{"_":"jcc","*":"Jump near if below or equal (CF=1 or ZF=1)."},"JS":{"_":"jcc","*":"Jump near if sign (SF=1)."},"JNAE":{"_":"jcc","*":"Jump near if not above or equal (CF=1)."},"JZ":{"_":"jcc","*":"Jump near if 0 (ZF=1)."},"JGE":{"_":"jcc","*":"Jump near if greater or equal (SF=OF)."},"JG":{"_":"jcc","*":"Jump near if greater (ZF=0 and SF=OF)."},"KADDW:KADDB:KADDQ:KADDD":{"_":"kaddw:kaddb:kaddq:kaddd","*":"Adds the vector mask k2 and the vector mask k3, and writes the result into vector mask k1."},"KADDW":{"_":"kaddw:kaddb:kaddq:kaddd","*":"Add 16 bits masks in k2 and k3 and place result in k1."},"KADDQ":{"_":"kaddw:kaddb:kaddq:kaddd","*":"Add 64 bits masks in k2 and k3 and place result in k1."},"KADDB":{"_":"kaddw:kaddb:kaddq:kaddd","*":"Add 8 bits masks in k2 and k3 and place result in k1."},"KADDD":{"_":"kaddw:kaddb:kaddq:kaddd","*":"Add 32 bits masks in k2 and k3 and place result in k1."},"KANDNW:KANDNB:KANDNQ:KANDND":{"_":"kandnw:kandnb:kandnq:kandnd","*":"Performs a bitwise AND NOT between the vector mask k2 and the vector mask k3, and writes the result into vector mask k1."},"KANDNW":{"_":"kandnw:kandnb:kandnq:kandnd","*":"Bitwise AND NOT 16 bits masks k2 and k3 and place result in k1."},"KANDND":{"_":"kandnw:kandnb:kandnq:kandnd","*":"Bitwise AND NOT 32 bits masks k2 and k3 and place result in k1."},"KANDNB":{"_":"kandnw:kandnb:kandnq:kandnd","*":"Bitwise AND NOT 8 bits masks k1 and k2 and place result in k1."},"KANDNQ":{"_":"kandnw:kandnb:kandnq:kandnd","*":"Bitwise AND NOT 64 bits masks k2 and k3 and place result in k1."},"KANDW:KANDB:KANDQ:KANDD":{"_":"kandw:kandb:kandq:kandd","*":"Performs a bitwise AND between the vector mask k2 and the vector mask k3, and writes the result into vector mask k1."},"KANDB":{"_":"kandw:kandb:kandq:kandd","*":"Bitwise AND 8 bits masks k2 and k3 and place result in k1."},"KANDQ":{"_":"kandw:kandb:kandq:kandd","*":"Bitwise AND 64 bits masks k2 and k3 and place result in k1."},"KANDD":{"_":"kandw:kandb:kandq:kandd","*":"Bitwise AND 32 bits masks k2 and k3 and place result in k1."},"KANDW":{"_":"kandw:kandb:kandq:kandd","*":"Bitwise AND 16 bits masks k2 and k3 and place result in k1."},"KMOVW:KMOVB:KMOVQ:KMOVD":{"_":"kmovw:kmovb:kmovq:kmovd","*":"Copies values from the source operand (second operand) to the destination operand (first operand). The source and destination operands can be mask registers, memory location or general purpose. The instruction cannot be used to transfer data between general purpose registers and or memory locations."},"KMOVB":{"_":"kmovw:kmovb:kmovq:kmovd","*":"Move 8 bits mask from k1 to r32."},"KMOVW":{"_":"kmovw:kmovb:kmovq:kmovd","*":"Move 16 bits mask from k1 to r32."},"KMOVQ":{"_":"kmovw:kmovb:kmovq:kmovd","*":"Move 64 bits mask from k1 to r64."},"KMOVD":{"_":"kmovw:kmovb:kmovq:kmovd","*":"Move 32 bits mask from k1 to r32."},"KNOTW:KNOTB:KNOTQ:KNOTD":{"_":"knotw:knotb:knotq:knotd","*":"Performs a bitwise NOT of vector mask k2 and writes the result into vector mask k1."},"KNOTD":{"_":"knotw:knotb:knotq:knotd","*":"Bitwise NOT of 32 bits mask k2."},"KNOTQ":{"_":"knotw:knotb:knotq:knotd","*":"Bitwise NOT of 64 bits mask k2."},"KNOTB":{"_":"knotw:knotb:knotq:knotd","*":"Bitwise NOT of 8 bits mask k2."},"KNOTW":{"_":"knotw:knotb:knotq:knotd","*":"Bitwise NOT of 16 bits mask k2."},"KORTESTW:KORTESTB:KORTESTQ:KORTESTD":{"_":"kortestw:kortestb:kortestq:kortestd","*":"Performs a bitwise OR between the vector mask register k2, and the vector mask register k1, and sets CF and ZF based on the operation result."},"KORTESTB":{"_":"kortestw:kortestb:kortestq:kortestd","*":"Bitwise OR 8 bits masks k1 and k2 and update ZF and CF accordingly."},"KORTESTQ":{"_":"kortestw:kortestb:kortestq:kortestd","*":"Bitwise OR 64 bits masks k1 and k2 and update ZF and CF accordingly."},"KORTESTW":{"_":"kortestw:kortestb:kortestq:kortestd","*":"Bitwise OR 16 bits masks k1 and k2 and update ZF and CF accordingly."},"KORTESTD":{"_":"kortestw:kortestb:kortestq:kortestd","*":"Bitwise OR 32 bits masks k1 and k2 and update ZF and CF accordingly."},"KORW:KORB:KORQ:KORD":{"_":"korw:korb:korq:kord","*":"Performs a bitwise OR between the vector mask k2 and the vector mask k3, and writes the result into vector mask k1 (three-operand form)."},"KORB":{"_":"korw:korb:korq:kord","*":"Bitwise OR 8 bits masks k2 and k3 and place result in k1."},"KORD":{"_":"korw:korb:korq:kord","*":"Bitwise OR 32 bits masks k2 and k3 and place result in k1."},"KORW":{"_":"korw:korb:korq:kord","*":"Bitwise OR 16 bits masks k2 and k3 and place result in k1."},"KORQ":{"_":"korw:korb:korq:kord","*":"Bitwise OR 64 bits masks k2 and k3 and place result in k1."},"KSHIFTLW:KSHIFTLB:KSHIFTLQ:KSHIFTLD":{"_":"kshiftlw:kshiftlb:kshiftlq:kshiftld","*":"Shifts 8/16/32/64 bits in the second operand (source operand) left by the count specified in immediate byte and place the least significant 8/16/32/64 bits of the result in the destination operand. The higher bits of the destination are zero-extended. The destination is set to zero if the count value is greater than 7 (for byte shift), 15 (for word shift), 31 (for doubleword shift) or 63 (for quadword shift)."},"KSHIFTLD":{"_":"kshiftlw:kshiftlb:kshiftlq:kshiftld","*":"Shift left 32 bits in k2 by immediate and write result in k1."},"KSHIFTLW":{"_":"kshiftlw:kshiftlb:kshiftlq:kshiftld","*":"Shift left 16 bits in k2 by immediate and write result in k1."},"KSHIFTLQ":{"_":"kshiftlw:kshiftlb:kshiftlq:kshiftld","*":"Shift left 64 bits in k2 by immediate and write result in k1."},"KSHIFTLB":{"_":"kshiftlw:kshiftlb:kshiftlq:kshiftld","*":"Shift left 8 bits in k2 by immediate and write result in k1."},"KSHIFTRW:KSHIFTRB:KSHIFTRQ:KSHIFTRD":{"_":"kshiftrw:kshiftrb:kshiftrq:kshiftrd","*":"Shifts 8/16/32/64 bits in the second operand (source operand) right by the count specified in immediate and place the least significant 8/16/32/64 bits of the result in the destination operand. The higher bits of the destination are zero-extended. The destination is set to zero if the count value is greater than 7 (for byte shift), 15 (for word shift), 31 (for doubleword shift) or 63 (for quadword shift)."},"KSHIFTRW":{"_":"kshiftrw:kshiftrb:kshiftrq:kshiftrd","*":"Shift right 16 bits in k2 by immediate and write result in k1."},"KSHIFTRB":{"_":"kshiftrw:kshiftrb:kshiftrq:kshiftrd","*":"Shift right 8 bits in k2 by immediate and write result in k1."},"KSHIFTRD":{"_":"kshiftrw:kshiftrb:kshiftrq:kshiftrd","*":"Shift right 32 bits in k2 by immediate and write result in k1."},"KSHIFTRQ":{"_":"kshiftrw:kshiftrb:kshiftrq:kshiftrd","*":"Shift right 64 bits in k2 by immediate and write result in k1."},"KTESTW:KTESTB:KTESTQ:KTESTD":{"_":"ktestw:ktestb:ktestq:ktestd","*":"Performs a bitwise comparison of the bits of the first source operand and corresponding bits in the second source operand. If the AND operation produces all zeros, the ZF is set else the ZF is clear. If the bitwise AND operation of the inverted first source operand with the second source operand produces all zeros the CF is set else the CF is clear. Only the EFLAGS register is updated."},"KTESTD":{"_":"ktestw:ktestb:ktestq:ktestd","*":"Set ZF and CF depending on sign bit AND and ANDN of 32 bits mask register sources."},"KTESTW":{"_":"ktestw:ktestb:ktestq:ktestd","*":"Set ZF and CF depending on sign bit AND and ANDN of 16 bits mask register sources."},"KTESTQ":{"_":"ktestw:ktestb:ktestq:ktestd","*":"Set ZF and CF depending on sign bit AND and ANDN of 64 bits mask register sources."},"KTESTB":{"_":"ktestw:ktestb:ktestq:ktestd","*":"Set ZF and CF depending on sign bit AND and ANDN of 8 bits mask register sources."},"KUNPCKBW:KUNPCKWD:KUNPCKDQ":{"_":"kunpckbw:kunpckwd:kunpckdq","*":"Unpacks the lower 8/16/32 bits of the second and third operands (source operands) into the low part of the first operand (destination operand), starting from the low bytes. The result is zero-extended in the destination."},"KUNPCKWD":{"_":"kunpckbw:kunpckwd:kunpckdq","*":"Unpack 16-bit masks in k2 and k3 and write doubleword result in k1."},"KUNPCKBW":{"_":"kunpckbw:kunpckwd:kunpckdq","*":"Unpack 8-bit masks in k2 and k3 and write word result in k1."},"KUNPCKDQ":{"_":"kunpckbw:kunpckwd:kunpckdq","*":"Unpack 32-bit masks in k2 and k3 and write quadword result in k1."},"KXNORW:KXNORB:KXNORQ:KXNORD":{"_":"kxnorw:kxnorb:kxnorq:kxnord","*":"Performs a bitwise XNOR between the vector mask k2 and the vector mask k3, and writes the result into vector mask k1 (three-operand form)."},"KXNORD":{"_":"kxnorw:kxnorb:kxnorq:kxnord","*":"Bitwise XNOR 32-bit masks k2 and k3 and place result in k1."},"KXNORW":{"_":"kxnorw:kxnorb:kxnorq:kxnord","*":"Bitwise XNOR 16-bit masks k2 and k3 and place result in k1."},"KXNORQ":{"_":"kxnorw:kxnorb:kxnorq:kxnord","*":"Bitwise XNOR 64-bit masks k2 and k3 and place result in k1."},"KXNORB":{"_":"kxnorw:kxnorb:kxnorq:kxnord","*":"Bitwise XNOR 8-bit masks k2 and k3 and place result in k1."},"KXORW:KXORB:KXORQ:KXORD":{"_":"kxorw:kxorb:kxorq:kxord","*":"Performs a bitwise XOR between the vector mask k2 and the vector mask k3, and writes the result into vector mask k1 (three-operand form)."},"KXORD":{"_":"kxorw:kxorb:kxorq:kxord","*":"Bitwise XOR 32-bit masks k2 and k3 and place result in k1."},"KXORQ":{"_":"kxorw:kxorb:kxorq:kxord","*":"Bitwise XOR 64-bit masks k2 and k3 and place result in k1."},"KXORB":{"_":"kxorw:kxorb:kxorq:kxord","*":"Bitwise XOR 8-bit masks k2 and k3 and place result in k1."},"KXORW":{"_":"kxorw:kxorb:kxorq:kxord","*":"Bitwise XOR 16-bit masks k2 and k3 and place result in k1."},"LAR":{"_":"lar","*":"reg ← access rights referenced by r32/m16"},"LDDQU":{"_":"lddqu","*":"Load unaligned data from mem and return double quadword in xmm1."},"VLDDQU":{"_":"lddqu","*":"Load unaligned packed integer values from mem to ymm1."},"LDMXCSR":{"_":"ldmxcsr","*":"Load MXCSR register from m32."},"VLDMXCSR":{"_":"ldmxcsr","*":"Load MXCSR register from m32."},"LDS:LES:LFS:LGS:LSS":{"_":"lds:les:lfs:lgs:lss","*":"Loads a far pointer (segment selector and offset) from the second operand (source operand) into a segment register and the first operand (destination operand). The source operand specifies a 48-bit or a 32-bit pointer in memory depending on the current setting of the operand-size attribute (32 bits or 16 bits, respectively). The instruction opcode and the destination operand specify a segment register/general-purpose register pair. The 16-bit segment selector from the source operand is loaded into the segment register specified with the opcode (DS, SS, ES, FS, or GS). The 32-bit or 16-bit offset is loaded into the register specified with the destination operand."},"LDS":{"_":"lds:les:lfs:lgs:lss","*":"Load DS:r32 with far pointer from memory."},"LFS":{"_":"lds:les:lfs:lgs:lss","*":"Load FS:r64 with far pointer from memory."},"LGS":{"_":"lds:les:lfs:lgs:lss","*":"Load GS:r64 with far pointer from memory."},"LSS":{"_":"lds:les:lfs:lgs:lss","*":"Load SS:r64 with far pointer from memory."},"LES":{"_":"lds:les:lfs:lgs:lss","*":"Load ES:r32 with far pointer from memory."},"LEA":{"_":"lea","*":"Store effective address for m in register r64."},"LEAVE":{"_":"leave","*":"Set RSP to RBP, then pop RBP."},"LFENCE":{"_":"lfence","*":"Serializes load operations."},"LGDT:LIDT":{"_":"lgdt:lidt","*":"Loads the values in the source operand into the global descriptor table register (GDTR) or the interrupt descriptor table register (IDTR). The source operand specifies a 6-byte memory location that contains the base address (a linear address) and the limit (size of table in bytes) of the global descriptor table (GDT) or the interrupt descriptor table (IDT). If operand-size attribute is 32 bits, a 16-bit limit (lower 2 bytes of the 6-byte data operand) and a 32-bit base address (upper 4 bytes of the data operand) are loaded into the register. If the operand-size attribute is 16 bits, a 16-bit limit (lower 2 bytes) and a 24-bit base address (third, fourth, and fifth byte) are loaded. Here, the high-order byte of the operand is not used and the high-order byte of the base address in the GDTR or IDTR is filled with zeros."},"LGDT":{"_":"lgdt:lidt","*":"Load m into GDTR."},"LIDT":{"_":"lgdt:lidt","*":"Load m into IDTR."},"LLDT":{"_":"lldt","*":"Load segment selector r/m16 into LDTR."},"LMSW":{"_":"lmsw","*":"Loads r/m16 in machine status word of CR0."},"LOCK":{"_":"lock","*":"Asserts LOCK# signal for duration of the accompanying instruction."},"LODS:LODSB:LODSW:LODSD:LODSQ":{"_":"lods:lodsb:lodsw:lodsd:lodsq","*":"Loads a byte, word, or doubleword from the source operand into the AL, AX, or EAX register, respectively. The source operand is a memory location, the address of which is read from the DS:ESI or the DS:SI registers (depending on the address-size attribute of the instruction, 32 or 16, respectively). The DS segment may be overridden with a segment override prefix."},"LODSB":{"_":"lods:lodsb:lodsw:lodsd:lodsq","*":"For legacy mode, Load byte at address DS:(E)SI into AL. For 64-bit mode load byte at address (R)SI into AL."},"LODSQ":{"_":"lods:lodsb:lodsw:lodsd:lodsq","*":"Load qword at address (R)SI into RAX."},"LODSD":{"_":"lods:lodsb:lodsw:lodsd:lodsq","*":"For legacy mode, Load dword at address DS:(E)SI into EAX. For 64-bit mode load dword at address (R)SI into EAX."},"LODS":{"_":"lods:lodsb:lodsw:lodsd:lodsq","*":"Load qword at address (R)SI into RAX."},"LODSW":{"_":"lods:lodsb:lodsw:lodsd:lodsq","*":"For legacy mode, Load word at address DS:(E)SI into AX. For 64-bit mode load word at address (R)SI into AX."},"LOOP:LOOPCC":{"_":"loop:loopcc","*":"Performs a loop operation using the RCX, ECX or CX register as a counter (depending on whether address size is 64 bits, 32 bits, or 16 bits). Note that the LOOP instruction ignores REX.W; but 64-bit address size can be over-ridden using a 67H prefix."},"LOOPE":{"_":"loop:loopcc","*":"Decrement count; jump short if count ≠ 0 and ZF = 1."},"LOOPNE":{"_":"loop:loopcc","*":"Decrement count; jump short if count ≠ 0 and ZF = 0."},"LOOP":{"_":"loop:loopcc","*":"Decrement count; jump short if count ≠ 0."},"LSL":{"_":"lsl","*":"Load: r64 ← segment limit, selector r32/m16"},"LTR":{"_":"ltr","*":"Load r/m16 into task register."},"LZCNT":{"_":"lzcnt","*":null},"MASKMOVDQU":{"_":"maskmovdqu","*":"Selectively write bytes from xmm1 to memory location using the byte mask in xmm2. The default memory location is specified by DS:DI/EDI/RDI."},"VMASKMOVDQU":{"_":"maskmovdqu","*":"Selectively write bytes from xmm1 to memory location using the byte mask in xmm2. The default memory location is specified by DS:DI/EDI/RDI."},"MASKMOVQ":{"_":"maskmovq","*":"Selectively write bytes from mm1 to memory location using the byte mask in mm2. The default memory location is specified by DS:DI/EDI/RDI."},"MAXPD":{"_":"maxpd","*":"Return the maximum double-precision floating-point values between xmm1 and xmm2/m128."},"VMAXPD":{"_":"maxpd","*":"Return the maximum packed double-precision floating-point values between zmm2 and zmm3/m512/m64bcst and store result in zmm1 subject to writemask k1."},"MAXPS":{"_":"maxps","*":"Return the maximum single-precision floating-point values between xmm1 and xmm2/mem."},"VMAXPS":{"_":"maxps","*":"Return the maximum packed single-precision floating-point values between zmm2 and zmm3/m512/m32bcst and store result in zmm1 subject to writemask k1."},"MAXSD":{"_":"maxsd","*":"Return the maximum scalar double-precision floating-point value between xmm2/m64 and xmm1."},"VMAXSD":{"_":"maxsd","*":"Return the maximum scalar double-precision floating-point value between xmm3/m64 and xmm2."},"MAXSS":{"_":"maxss","*":"Return the maximum scalar single-precision floating-point value between xmm2/m32 and xmm1."},"VMAXSS":{"_":"maxss","*":"Return the maximum scalar single-precision floating-point value between xmm3/m32 and xmm2."},"MINPD":{"_":"minpd","*":"Return the minimum double-precision floating-point values between xmm1 and xmm2/mem"},"VMINPD":{"_":"minpd","*":"Return the minimum packed double-precision floating-point values between zmm2 and zmm3/m512/m64bcst and store result in zmm1 subject to writemask k1."},"MINPS":{"_":"minps","*":"Return the minimum single-precision floating-point values between xmm1 and xmm2/mem."},"VMINPS":{"_":"minps","*":"Return the minimum packed single-precision floating-point values between zmm2 and zmm3/m512/m32bcst and store result in zmm1 subject to writemask k1."},"MINSD":{"_":"minsd","*":"Return the minimum scalar double-precision floating-point value between xmm2/m64 and xmm1."},"VMINSD":{"_":"minsd","*":"Return the minimum scalar double-precision floating-point value between xmm3/m64 and xmm2."},"MINSS":{"_":"minss","*":"Return the minimum scalar single-precision floating-point value between xmm2/m32 and xmm1."},"VMINSS":{"_":"minss","*":"Return the minimum scalar single-precision floating-point value between xmm3/m32 and xmm2."},"MOV":{"_":"mov","*":"Move imm32 sign extended to 64-bits to r/m64."},"MOVAPD":{"_":"movapd","*":"Move aligned packed double-precision floating-point values from xmm1 to xmm2/mem."},"VMOVAPD":{"_":"movapd","*":"Move aligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1."},"MOVAPS":{"_":"movaps","*":"Move aligned packed single-precision floating-point values from xmm1 to xmm2/mem."},"VMOVAPS":{"_":"movaps","*":"Move aligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1."},"MOVBE":{"_":"movbe","*":"Performs a byte swap operation on the data copied from the second operand (source operand) and store the result in the first operand (destination operand). The source operand can be a general-purpose register, or memory location; the destination register ..."},"MOVD:MOVQ":{"_":"movd:movq","*":"Copies a doubleword from the source operand (second operand) to the destination operand (first operand). The source and destination operands can be general-purpose registers, MMX technology registers, XMM registers, or 32-bit memory locations. This instruction can be used to move a doubleword to and from the low doubleword of an MMX technology register and a general-purpose register or a 32-bit memory location, or to and from the low doubleword of an XMM register and a general-purpose register or a 32-bit memory location. The instruction cannot be used to transfer data between MMX technology registers, between XMM registers, between general-purpose registers, or between memory locations."},"VMOVQ":{"_":"movd:movq","*":"Move quadword from xmm1 register to r/m64."},"VMOVD":{"_":"movd:movq","*":"Move doubleword from xmm1 register to r/m32."},"MOVQ":{"_":"movd:movq","*":"Move quadword from xmm register to r/m64."},"MOVD":{"_":"movd:movq","*":"Move doubleword from xmm register to r/m32."},"MOVDDUP":{"_":"movddup","*":"Move double-precision floating-point value from xmm2/m64 and duplicate into xmm1."},"VMOVDDUP":{"_":"movddup","*":"Move even index double-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 subject to writemask k1."},"MOVDIR64B":{"_":"movdir64b","*":"Move 64-bytes as direct-store with guaranteed 64-byte write atomicity from the source memory operand address to destination memory address specified as offset to ES segment in the register operand."},"MOVDIRI":{"_":"movdiri","*":"Move doubleword from r32 to m32 using direct store."},"MOVDQA:VMOVDQA32:VMOVDQA64":{"_":"movdqa:vmovdqa32:vmovdqa64","*":"Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise instructions will #UD."},"MOVDQA":{"_":"movdqa:vmovdqa32:vmovdqa64","*":"Move aligned packed integer values from xmm1 to xmm2/mem."},"VMOVDQA32":{"_":"movdqa:vmovdqa32:vmovdqa64","*":"Move aligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1."},"VMOVDQA":{"_":"movdqa:vmovdqa32:vmovdqa64","*":"Move aligned packed integer values from ymm1 to ymm2/mem."},"VMOVDQA64":{"_":"movdqa:vmovdqa32:vmovdqa64","*":"Move aligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1."},"MOVDQU:VMOVDQU8:VMOVDQU16:VMOVDQU32:VMOVDQU64":{"_":"movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64","*":"Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise instructions will #UD."},"VMOVDQU32":{"_":"movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64","*":"Move unaligned packed doubleword integer values from zmm1 to zmm2/m512 using writemask k1."},"VMOVDQU64":{"_":"movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64","*":"Move unaligned packed quadword integer values from zmm1 to zmm2/m512 using writemask k1."},"VMOVDQU8":{"_":"movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64","*":"Move unaligned packed byte integer values from zmm1 to zmm2/m512 using writemask k1."},"MOVDQU":{"_":"movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64","*":"Move unaligned packed integer values from xmm1 to xmm2/m128."},"VMOVDQU16":{"_":"movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64","*":"Move unaligned packed word integer values from zmm1 to zmm2/m512 using writemask k1."},"VMOVDQU":{"_":"movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64","*":"Move unaligned packed integer values from ymm1 to ymm2/m256."},"MOVHLPS":{"_":"movhlps","*":"Move two packed single-precision floating-point values from high quadword of xmm2 to low quadword of xmm1."},"VMOVHLPS":{"_":"movhlps","*":"Merge two packed single-precision floating-point values from high quadword of xmm3 and low quadword of xmm2."},"MOVHPD":{"_":"movhpd","*":"Move double-precision floating-point value from high quadword of xmm1 to m64."},"VMOVHPD":{"_":"movhpd","*":"Move double-precision floating-point value from high quadword of xmm1 to m64."},"MOVHPS":{"_":"movhps","*":"Move two packed single-precision floating-point values from high quadword of xmm1 to m64."},"VMOVHPS":{"_":"movhps","*":"Move two packed single-precision floating-point values from high quadword of xmm1 to m64."},"MOVLHPS":{"_":"movlhps","*":"Move two packed single-precision floating-point values from low quadword of xmm2 to high quadword of xmm1."},"VMOVLHPS":{"_":"movlhps","*":"Merge two packed single-precision floating-point values from low quadword of xmm3 and low quadword of xmm2."},"MOVLPD":{"_":"movlpd","*":"Move double-precision floating-point value from low quadword of xmm1 to m64."},"VMOVLPD":{"_":"movlpd","*":"Move double-precision floating-point value from low quadword of xmm1 to m64."},"MOVLPS":{"_":"movlps","*":"Move two packed single-precision floating-point values from low quadword of xmm1 to m64."},"VMOVLPS":{"_":"movlps","*":"Move two packed single-precision floating-point values from low quadword of xmm1 to m64."},"MOVMSKPD":{"_":"movmskpd","*":"Extract 2-bit sign mask from xmm and store in reg. The upper bits of r32 or r64 are filled with zeros."},"VMOVMSKPD":{"_":"movmskpd","*":"Extract 4-bit sign mask from ymm2 and store in reg. The upper bits of r32 or r64 are zeroed."},"MOVMSKPS":{"_":"movmskps","*":"Extract 4-bit sign mask from xmm and store in reg. The upper bits of r32 or r64 are filled with zeros."},"VMOVMSKPS":{"_":"movmskps","*":"Extract 8-bit sign mask from ymm2 and store in reg. The upper bits of r32 or r64 are zeroed."},"MOVNTDQ":{"_":"movntdq","*":"Move packed integer values in xmm1 to m128 using non-temporal hint."},"VMOVNTDQ":{"_":"movntdq","*":"Move packed integer values in zmm1 to m512 using non-temporal hint."},"MOVNTDQA":{"_":"movntdqa","*":"Move double quadword from m128 to xmm1 using non-temporal hint if WC memory type."},"VMOVNTDQA":{"_":"movntdqa","*":"Move 512-bit data from m512 to zmm using non-temporal hint if WC memory type."},"MOVNTI":{"_":"movnti","*":"Move quadword from r64 to m64 using non-temporal hint."},"MOVNTPD":{"_":"movntpd","*":"Move packed double-precision values in xmm1 to m128 using non-temporal hint."},"VMOVNTPD":{"_":"movntpd","*":"Move packed double-precision values in zmm1 to m512 using non-temporal hint."},"MOVNTPS":{"_":"movntps","*":"Move packed single-precision values xmm1 to mem using non-temporal hint."},"VMOVNTPS":{"_":"movntps","*":"Move packed single-precision values in zmm1 to m512 using non-temporal hint."},"MOVNTQ":{"_":"movntq","*":"Move quadword from mm to m64 using non-temporal hint."},"MOVQ2DQ":{"_":"movq2dq","*":"Move quadword from mmx to low quadword of xmm."},"MOVS:MOVSB:MOVSW:MOVSD:MOVSQ":{"_":"movs:movsb:movsw:movsd:movsq","*":"Moves the byte, word, or doubleword specified with the second operand (source operand) to the location specified with the first operand (destination operand). Both the source and destination operands are located in memory. The address of the source operand is read from the DS:ESI or the DS:SI registers (depending on the address-size attribute of the instruction, 32 or 16, respectively). The address of the destination operand is read from the ES:EDI or the ES:DI registers (again depending on the address-size attribute of the instruction). The DS segment may be overridden with a segment override prefix, but the ES segment cannot be overridden."},"MOVSD":{"_":"movs:movsb:movsw:movsd:movsq","*":"For legacy mode, move dword from address DS:(E)SI to ES:(E)DI. For 64-bit mode move dword from address (R|E)SI to (R|E)DI."},"MOVSQ":{"_":"movs:movsb:movsw:movsd:movsq","*":"Move qword from address (R|E)SI to (R|E)DI."},"MOVSW":{"_":"movs:movsb:movsw:movsd:movsq","*":"For legacy mode, move word from address DS:(E)SI to ES:(E)DI. For 64-bit mode move word at address (R|E)SI to (R|E)DI."},"MOVSB":{"_":"movs:movsb:movsw:movsd:movsq","*":"For legacy mode, Move byte from address DS:(E)SI to ES:(E)DI. For 64-bit mode move byte from address (R|E)SI to (R|E)DI."},"MOVS":{"_":"movs:movsb:movsw:movsd:movsq","*":"Move qword from address (R|E)SI to (R|E)DI."},"MOVSHDUP":{"_":"movshdup","*":"Move odd index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1."},"VMOVSHDUP":{"_":"movshdup","*":"Move odd index single-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 under writemask."},"MOVSLDUP":{"_":"movsldup","*":"Move even index single-precision floating-point values from xmm2/mem and duplicate each element into xmm1."},"VMOVSLDUP":{"_":"movsldup","*":"Move even index single-precision floating-point values from zmm2/m512 and duplicate each element into zmm1 under writemask."},"MOVSS":{"_":"movss","*":"Move scalar single-precision floating-point value from xmm1 register to xmm2/m32."},"VMOVSS":{"_":"movss","*":"Move scalar single-precision floating-point values from xmm1 to m32 under writemask k1."},"MOVSX:MOVSXD":{"_":"movsx:movsxd","*":"Copies the contents of the source operand (register or memory location) to the destination operand (register) and sign extends the value to 16 or 32 bits (see Figure 7-6 in the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1). The size of the converted value depends on the operand-size attribute."},"MOVSXD":{"_":"movsx:movsxd","*":"Move doubleword to quadword with sign-extension."},"MOVSX":{"_":"movsx:movsxd","*":"Move word to quadword with sign-extension."},"MOVUPD":{"_":"movupd","*":"Move unaligned packed double-precision floating-point from xmm1 to xmm2/mem."},"VMOVUPD":{"_":"movupd","*":"Move unaligned packed double-precision floating-point values from zmm1 to zmm2/m512 using writemask k1."},"MOVUPS":{"_":"movups","*":"Move unaligned packed single-precision floating-point from xmm1 to xmm2/mem."},"VMOVUPS":{"_":"movups","*":"Move unaligned packed single-precision floating-point values from zmm1 to zmm2/m512 using writemask k1."},"MOVZX":{"_":"movzx","*":"Move word to quadword, zero-extension."},"MPSADBW":{"_":"mpsadbw","*":"Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm1 and xmm2/m128 and writes the results in xmm1. Starting offsets within xmm1 and xmm2/m128 are determined by imm8."},"VMPSADBW":{"_":"mpsadbw","*":"Sums absolute 8-bit integer difference of adjacent groups of 4 byte integers in xmm2 and ymm3/m128 and writes the results in ymm1. Starting offsets within ymm2 and xmm3/m128 are determined by imm8."},"MUL":{"_":"mul","*":"Unsigned multiply (RDX:RAX ← RAX ∗ r/m64)."},"MULPD":{"_":"mulpd","*":"Multiply packed double-precision floating-point values in xmm2/m128 with xmm1 and store result in xmm1."},"VMULPD":{"_":"mulpd","*":"Multiply packed double-precision floating-point values in zmm3/m512/m64bcst with zmm2 and store result in zmm1."},"MULPS":{"_":"mulps","*":"Multiply packed single-precision floating-point values in xmm2/m128 with xmm1 and store result in xmm1."},"VMULPS":{"_":"mulps","*":"Multiply packed single-precision floating-point values in zmm3/m512/m32bcst with zmm2 and store result in zmm1."},"MULSD":{"_":"mulsd","*":"Multiply the low double-precision floating-point value in xmm2/m64 by low double-precision floating-point value in xmm1."},"VMULSD":{"_":"mulsd","*":"Multiply the low double-precision floating-point value in xmm3/m64 by low double-precision floating-point value in xmm2."},"MULSS":{"_":"mulss","*":"Multiply the low single-precision floating-point value in xmm2/m32 by the low single-precision floating-point value in xmm1."},"VMULSS":{"_":"mulss","*":"Multiply the low single-precision floating-point value in xmm3/m32 by the low single-precision floating-point value in xmm2."},"MULX":{"_":"mulx","*":"Unsigned multiply of r/m64 with RDX without affecting arithmetic flags."},"MWAIT":{"_":"mwait","*":"A hint that allows the processor to stop instruction execution and enter an implementation-dependent optimized state until occurrence of a class of events."},"NEG":{"_":"neg","*":"Two\'s complement negate r/m64."},"NOP":{"_":"nop","*":"Multi-byte no-operation instruction."},"NOT":{"_":"not","*":"Reverse each bit of r/m64."},"OR":{"_":"or","*":"r64 OR r/m64."},"ORPD":{"_":"orpd","*":"Return the bitwise logical OR of packed double-precision floating-point values in xmm1 and xmm2/mem."},"VORPD":{"_":"orpd","*":"Return the bitwise logical OR of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1."},"ORPS":{"_":"orps","*":"Return the bitwise logical OR of packed single-precision floating-point values in xmm1 and xmm2/mem."},"VORPS":{"_":"orps","*":"Return the bitwise logical OR of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1."},"OUT":{"_":"out","*":"Output doubleword in EAX to I/O port address in DX."},"OUTS:OUTSB:OUTSW:OUTSD":{"_":"outs:outsb:outsw:outsd","*":"Copies data from the source operand (second operand) to the I/O port specified with the destination operand (first operand). The source operand is a memory location, the address of which is read from either the DS:SI, DS:ESI or the RSI registers (depending on the address-size attribute of the instruction, 16, 32 or 64, respectively). (The DS segment may be overridden with a segment override prefix.) The destination operand is an I/O port address (from 0 to 65,535) that is read from the DX register. The size of the I/O port being accessed (that is, the size of the source and destination operands) is determined by the opcode for an 8-bit I/O port or by the operand-size attribute of the instruction for a 16- or 32-bit I/O port."},"OUTSW":{"_":"outs:outsb:outsw:outsd","*":"Output word from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**."},"OUTSB":{"_":"outs:outsb:outsw:outsd","*":"Output byte from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**."},"OUTS":{"_":"outs:outsb:outsw:outsd","*":"Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**."},"OUTSD":{"_":"outs:outsb:outsw:outsd","*":"Output doubleword from memory location specified in DS:(E)SI or RSI to I/O port specified in DX**."},"PABSB:PABSW:PABSD:PABSQ":{"_":"pabsb:pabsw:pabsd:pabsq","*":"PABSB/W/D computes the absolute value of each data element of the source operand (the second operand) and stores the UNSIGNED results in the destination operand (the first operand). PABSB operates on signed bytes, PABSW operates on signed 16-bit words, and PABSD operates on signed 32-bit integers."},"PABSB":{"_":"pabsb:pabsw:pabsd:pabsq","*":"Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1."},"PABSW":{"_":"pabsb:pabsw:pabsd:pabsq","*":"Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1."},"PABSD":{"_":"pabsb:pabsw:pabsd:pabsq","*":"Compute the absolute value of 32-bit integers in xmm2/m128 and store UNSIGNED result in xmm1."},"VPABSD":{"_":"pabsb:pabsw:pabsd:pabsq","*":"Compute the absolute value of 32-bit integers in ymm2/m256 and store UNSIGNED result in ymm1."},"VPABSB":{"_":"pabsb:pabsw:pabsd:pabsq","*":"Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1."},"VPABSW":{"_":"pabsb:pabsw:pabsd:pabsq","*":"Compute the absolute value of 16-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1."},"PACKSSWB:PACKSSDW":{"_":"packsswb:packssdw","*":"Converts packed signed word integers into packed signed byte integers (PACKSSWB) or converts packed signed doubleword integers into packed signed word integers (PACKSSDW), using saturation to handle overflow conditions. See Figure 4-6 for an example of the packing operation."},"PACKSSWB":{"_":"packsswb:packssdw","*":"Converts 8 packed signed word integers from xmm1 and from xxm2/m128 into 16 packed signed byte integers in xxm1 using signed saturation."},"PACKSSDW":{"_":"packsswb:packssdw","*":"Converts 4 packed signed doubleword integers from xmm1 and from xxm2/m128 into 8 packed signed word integers in xxm1 using signed saturation."},"VPACKSSWB":{"_":"packsswb:packssdw","*":"Converts packed signed word integers from zmm2 and from zmm3/m512 into packed signed byte integers in zmm1 using signed saturation under writemask k1."},"VPACKSSDW":{"_":"packsswb:packssdw","*":"Converts packed signed doubleword integers from xmm2 and from xmm3/m128/m32bcst into packed signed word integers in xmm1 using signed saturation under writemask k1."},"PACKUSDW":{"_":"packusdw","*":"Convert 4 packed signed doubleword integers from xmm1 and 4 packed signed doubleword integers from xmm2/m128 into 8 packed unsigned word integers in xmm1 using unsigned saturation."},"VPACKUSDW":{"_":"packusdw","*":"Convert packed signed doubleword integers from zmm2 and packed signed doubleword integers from zmm3/m512/m32bcst into packed unsigned word integers in zmm1 using unsigned saturation under writemask k1."},"PACKUSWB":{"_":"packuswb","*":"Converts 8 signed word integers from xmm1 and 8 signed word integers from xmm2/m128 into 16 unsigned byte integers in xmm1 using unsigned saturation."},"VPACKUSWB":{"_":"packuswb","*":"Converts signed word integers from zmm2 and signed word integers from zmm3/m512 into unsigned byte integers in zmm1 using unsigned saturation under writemask k1."},"PADDB:PADDW:PADDD:PADDQ":{"_":"paddb:paddw:paddd:paddq","*":"Performs a SIMD add of the packed integers from the source operand (second operand) and the destination operand (first operand), and stores the packed integer results in the destination operand. See Figure 9-4 in the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1, for an illustration of a SIMD operation. Overflow is handled with wraparound, as described in the following paragraphs."},"PADDD":{"_":"paddb:paddw:paddd:paddq","*":"Add packed doubleword integers from xmm2/m128 and xmm1."},"PADDB":{"_":"paddb:paddw:paddd:paddq","*":"Add packed byte integers from xmm2/m128 and xmm1."},"VPADDQ":{"_":"paddb:paddw:paddd:paddq","*":"Add packed quadword integers from zmm2, zmm3/m512/m64bcst and store in zmm1 using writemask k1."},"VPADDD":{"_":"paddb:paddw:paddd:paddq","*":"Add packed doubleword integers from zmm2, zmm3/m512/m32bcst and store in zmm1 using writemask k1."},"VPADDB":{"_":"paddb:paddw:paddd:paddq","*":"Add packed byte integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1."},"VPADDW":{"_":"paddb:paddw:paddd:paddq","*":"Add packed word integers from zmm2, and zmm3/m512 and store in zmm1 using writemask k1."},"PADDW":{"_":"paddb:paddw:paddd:paddq","*":"Add packed word integers from xmm2/m128 and xmm1."},"PADDQ":{"_":"paddb:paddw:paddd:paddq","*":"Add packed quadword integers from xmm2/m128 and xmm1."},"PADDSB:PADDSW":{"_":"paddsb:paddsw","*":"Performs a SIMD add of the packed signed integers from the source operand (second operand) and the destination operand (first operand), and stores the packed integer results in the destination operand. See Figure 9-4 in the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1, for an illustration of a SIMD operation. Overflow is handled with signed saturation, as described in the following paragraphs."},"PADDSW":{"_":"paddsb:paddsw","*":"Add packed signed word integers from xmm2/m128 and xmm1 and saturate the results."},"VPADDSB":{"_":"paddsb:paddsw","*":"Add packed signed byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1."},"VPADDSW":{"_":"paddsb:paddsw","*":"Add packed signed word integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1."},"PADDSB":{"_":"paddsb:paddsw","*":"Add packed signed byte integers from xmm2/m128 and xmm1 saturate the results."},"PADDUSB:PADDUSW":{"_":"paddusb:paddusw","*":"Performs a SIMD add of the packed unsigned integers from the source operand (second operand) and the destination operand (first operand), and stores the packed integer results in the destination operand. See Figure 9-4 in the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1, for an illustration of a SIMD operation. Overflow is handled with unsigned saturation, as described in the following paragraphs."},"VPADDUSB":{"_":"paddusb:paddusw","*":"Add packed unsigned byte integers from zmm2, and zmm3/m512 and store the saturated results in zmm1 under writemask k1."},"PADDUSB":{"_":"paddusb:paddusw","*":"Add packed unsigned byte integers from xmm2/m128 and xmm1 saturate the results."},"VPADDUSW":{"_":"paddusb:paddusw","*":"Add packed unsigned word integers from ymm2, and ymm3/m256 and store the saturated results in ymm1 under writemask k1."},"PADDUSW":{"_":"paddusb:paddusw","*":"Add packed unsigned word integers from xmm2/m128 to xmm1 and saturate the results."},"PALIGNR":{"_":"palignr","*":"Concatenate destination and source operands, extract byte-aligned result shifted to the right by constant value in imm8 into xmm1."},"VPALIGNR":{"_":"palignr","*":"Concatenate pairs of 16 bytes in zmm2 and zmm3/m512 into 32-byte intermediate result, extract byte-aligned, 16-byte result shifted to the right by constant values in imm8 from each intermediate result, and four 16-byte results are stored in zmm1."},"PAND":{"_":"pand","*":"Bitwise AND of xmm2/m128 and xmm1."},"VPAND":{"_":"pand","*":"Bitwise AND of ymm2, and ymm3/m256 and store result in ymm1."},"VPANDD":{"_":"pand","*":"Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1."},"VPANDQ":{"_":"pand","*":"Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1."},"PANDN":{"_":"pandn","*":"Bitwise AND NOT of xmm2/m128 and xmm1."},"VPANDN":{"_":"pandn","*":"Bitwise AND NOT of ymm2, and ymm3/m256 and store result in ymm1."},"VPANDND":{"_":"pandn","*":"Bitwise AND NOT of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and store result in zmm1 using writemask k1."},"VPANDNQ":{"_":"pandn","*":"Bitwise AND NOT of packed quadword integers in zmm2 and zmm3/m512/m64bcst and store result in zmm1 using writemask k1."},"PAUSE":{"_":"pause","*":"Gives hint to processor that improves performance of spin-wait loops."},"PAVGB:PAVGW":{"_":"pavgb:pavgw","*":"Performs a SIMD average of the packed unsigned integers from the source operand (second operand) and the destination operand (first operand), and stores the results in the destination operand. For each corresponding pair of data elements in the first and second operands, the elements are added together, a 1 is added to the temporary sum, and that result is shifted right one bit position."},"PAVGW":{"_":"pavgb:pavgw","*":"Average packed unsigned word integers from xmm2/m128 and xmm1 with rounding."},"VPAVGW":{"_":"pavgb:pavgw","*":"Average packed unsigned word integers from zmm2, zmm3/m512 with rounding to zmm1 under writemask k1."},"PAVGB":{"_":"pavgb:pavgw","*":"Average packed unsigned byte integers from mm2/m64 and mm1 with rounding."},"VPAVGB":{"_":"pavgb:pavgw","*":"Average packed unsigned byte integers from zmm2, and zmm3/m512 with rounding and store to zmm1 under writemask k1."},"PBLENDVB":{"_":"pblendvb","*":"Select byte values from xmm1 and xmm2/m128 from mask specified in the high bit of each byte in XMM0 and store the values into xmm1."},"VPBLENDVB":{"_":"pblendvb","*":"Select byte values from ymm2 and ymm3/m256 from mask specified in the high bit of each byte in ymm4 and store the values into ymm1."},"PBLENDW":{"_":"pblendw","*":"Select words from xmm1 and xmm2/m128 from mask specified in imm8 and store the values into xmm1."},"VPBLENDW":{"_":"pblendw","*":"Select words from ymm2 and ymm3/m256 from mask specified in imm8 and store the values into ymm1."},"PCLMULQDQ":{"_":"pclmulqdq","*":"Carry-less multiplication of one quadword of xmm1 by one quadword of xmm2/m128, stores the 128-bit result in xmm1. The immediate is used to determine which quadwords of xmm1 and xmm2/m128 should be used."},"VPCLMULQDQ":{"_":"pclmulqdq","*":"Carry-less multiplication of one quadword of xmm2 by one quadword of xmm3/m128, stores the 128-bit result in xmm1. The immediate is used to determine which quadwords of xmm2 and xmm3/m128 should be used."},"PCMPEQB:PCMPEQW:PCMPEQD":{"_":"pcmpeqb:pcmpeqw:pcmpeqd","*":"Performs a SIMD compare for equality of the packed bytes, words, or doublewords in the destination operand (first operand) and the source operand (second operand). If a pair of data elements is equal, the corresponding data element in the destination operand is set to all 1s; otherwise, it is set to all 0s."},"VPCMPEQW":{"_":"pcmpeqb:pcmpeqw:pcmpeqd","*":"Compare packed words in ymm3/m256 and ymm2 for equality."},"PCMPEQW":{"_":"pcmpeqb:pcmpeqw:pcmpeqd","*":"Compare packed words in xmm2/m128 and xmm1 for equality."},"VPCMPEQB":{"_":"pcmpeqb:pcmpeqw:pcmpeqd","*":"Compare packed bytes in xmm3/m128 and xmm2 for equality and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask."},"PCMPEQB":{"_":"pcmpeqb:pcmpeqw:pcmpeqd","*":"Compare packed bytes in xmm2/m128 and xmm1 for equality."},"PCMPEQD":{"_":"pcmpeqb:pcmpeqw:pcmpeqd","*":"Compare packed doublewords in xmm2/m128 and xmm1 for equality."},"VPCMPEQD":{"_":"pcmpeqb:pcmpeqw:pcmpeqd","*":"Compare Equal between int32 vectors in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask k2."},"PCMPEQQ":{"_":"pcmpeqq","*":"Compare packed qwords in xmm2/m128 and xmm1 for equality."},"VPCMPEQQ":{"_":"pcmpeqq","*":"Compare Equal between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask."},"PCMPESTRI":{"_":"pcmpestri","*":"The instruction compares and processes data from two string fragments based on the encoded value in the Imm8 Control Byte (see Section 4.1, “Imm8 Control Byte Operation for PCMPESTRI / PCMPESTRM / PCMPISTRI / PCMPISTRM”), and generates an index stored to the count register (ECX)."},"VPCMPESTRI":{"_":"pcmpestri","*":"Perform a packed comparison of string data with explicit lengths, generating an index, and storing the result in ECX."},"PCMPESTRM":{"_":"pcmpestrm","*":"The instruction compares data from two string fragments based on the encoded value in the imm8 contol byte (see Section 4.1, “Imm8 Control Byte Operation for PCMPESTRI / PCMPESTRM / PCMPISTRI / PCMPISTRM”), and generates a mask stored to XMM0."},"VPCMPESTRM":{"_":"pcmpestrm","*":"Perform a packed comparison of string data with explicit lengths, generating a mask, and storing the result in XMM0."},"PCMPGTB:PCMPGTW:PCMPGTD":{"_":"pcmpgtb:pcmpgtw:pcmpgtd","*":"Performs an SIMD signed compare for the greater value of the packed byte, word, or doubleword integers in the destination operand (first operand) and the source operand (second operand). If a data element in the destination operand is greater than the corresponding date element in the source operand, the corresponding data element in the destination operand is set to all 1s; otherwise, it is set to all 0s."},"VPCMPGTD":{"_":"pcmpgtb:pcmpgtw:pcmpgtd","*":"Compare Greater between int32 elements in zmm2 and zmm3/m512/m32bcst, and set destination k1 according to the comparison results under writemask. k2."},"PCMPGTW":{"_":"pcmpgtb:pcmpgtw:pcmpgtd","*":"Compare packed signed word integers in xmm1 and xmm2/m128 for greater than."},"VPCMPGTB":{"_":"pcmpgtb:pcmpgtw:pcmpgtd","*":"Compare packed signed byte integers in ymm2 and ymm3/m256 for greater than, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask."},"VPCMPGTW":{"_":"pcmpgtb:pcmpgtw:pcmpgtd","*":"Compare packed signed word integers in ymm2 and ymm3/m256 for greater than."},"PCMPGTD":{"_":"pcmpgtb:pcmpgtw:pcmpgtd","*":"Compare packed signed doubleword integers in xmm1 and xmm2/m128 for greater than."},"PCMPGTB":{"_":"pcmpgtb:pcmpgtw:pcmpgtd","*":"Compare packed signed byte integers in xmm1 and xmm2/m128 for greater than."},"PCMPGTQ":{"_":"pcmpgtq","*":"Compare packed signed qwords in xmm2/m128 and xmm1 for greater than."},"VPCMPGTQ":{"_":"pcmpgtq","*":"Compare Greater between int64 vector zmm2 and int64 vector zmm3/m512/m64bcst, and set vector mask k1 to reflect the zero/nonzero status of each element of the result, under writemask."},"PCMPISTRI":{"_":"pcmpistri","*":"The instruction compares data from two strings based on the encoded value in the Imm8 Control Byte (see Section 4.1, “Imm8 Control Byte Operation for PCMPESTRI / PCMPESTRM / PCMPISTRI / PCMPISTRM”), and generates an index stored to ECX."},"VPCMPISTRI":{"_":"pcmpistri","*":"Perform a packed comparison of string data with implicit lengths, generating an index, and storing the result in ECX."},"PCMPISTRM":{"_":"pcmpistrm","*":"The instruction compares data from two strings based on the encoded value in the imm8 byte (see Section 4.1, “Imm8 Control Byte Operation for PCMPESTRI / PCMPESTRM / PCMPISTRI / PCMPISTRM”) generating a mask stored to XMM0."},"VPCMPISTRM":{"_":"pcmpistrm","*":"Perform a packed comparison of string data with implicit lengths, generating a Mask, and storing the result in XMM0."},"PDEP":{"_":"pdep","*":"Parallel deposit of bits from r64b using mask in r/m64, result is written to r64a."},"PEXT":{"_":"pext","*":"Parallel extract of bits from r64b using mask in r/m64, result is written to r64a."},"PEXTRB:PEXTRD:PEXTRQ":{"_":"pextrb:pextrd:pextrq","*":"Extract a byte/dword/qword integer value from the source XMM register at a byte/dword/qword offset determined from imm8[3:0]. The destination can be a register or byte/dword/qword memory location. If the destination is a register, the upper bits of the register are zero extended."},"PEXTRQ":{"_":"pextrb:pextrd:pextrq","*":"Extract a qword integer value from xmm2 at the source qword offset specified by imm8 into r/m64."},"VPEXTRD":{"_":"pextrb:pextrd:pextrq","*":"Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r32/m32."},"PEXTRD":{"_":"pextrb:pextrd:pextrq","*":"Extract a dword integer value from xmm2 at the source dword offset specified by imm8 into r/m32."},"PEXTRB":{"_":"pextrb:pextrd:pextrq","*":"Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r32 or r64 are zeroed."},"VPEXTRB":{"_":"pextrb:pextrd:pextrq","*":"Extract a byte integer value from xmm2 at the source byte offset specified by imm8 into reg or m8. The upper bits of r64/r32 is filled with zeros."},"VPEXTRQ":{"_":"pextrb:pextrd:pextrq","*":"Extract a qword integer value from xmm2 at the source dword offset specified by imm8 into r64/m64."},"PEXTRW":{"_":"pextrw","*":"Extract the word specified by imm8 from xmm and copy it to lowest 16 bits of reg or m16. Zero-extend the result in the destination, r32 or r64."},"VPEXTRW":{"_":"pextrw","*":"Extract a word integer value from xmm2 at the source word offset specified by imm8 into reg or m16. The upper bits of r64/r32 is filled with zeros."},"PHADDSW":{"_":"phaddsw","*":"Add 16-bit signed integers horizontally, pack saturated integers to xmm1."},"VPHADDSW":{"_":"phaddsw","*":"Add 16-bit signed integers horizontally, pack saturated integers to ymm1."},"PHADDW:PHADDD":{"_":"phaddw:phaddd","*":"(V)PHADDW adds two adjacent 16-bit signed integers horizontally from the source and destination operands and packs the 16-bit signed results to the destination operand (first operand). (V)PHADDD adds two adjacent 32-bit signed integers horizontally from the source and destination operands and packs the 32-bit signed results to the destination operand (first operand). When the source operand is a 128-bit memory operand, the operand must be aligned on a 16-byte boundary or a general-protection exception (#GP) will be generated."},"VPHADDD":{"_":"phaddw:phaddd","*":"Add 32-bit signed integers horizontally, pack to ymm1."},"VPHADDW":{"_":"phaddw:phaddd","*":"Add 16-bit signed integers horizontally, pack to ymm1."},"PHADDW":{"_":"phaddw:phaddd","*":"Add 16-bit integers horizontally, pack to xmm1."},"PHADDD":{"_":"phaddw:phaddd","*":"Add 32-bit integers horizontally, pack to xmm1."},"PHMINPOSUW":{"_":"phminposuw","*":"Find the minimum unsigned word in xmm2/m128 and place its value in the low word of xmm1 and its index in the second-lowest word of xmm1."},"VPHMINPOSUW":{"_":"phminposuw","*":"Find the minimum unsigned word in xmm2/m128 and place its value in the low word of xmm1 and its index in the second-lowest word of xmm1."},"PHSUBSW":{"_":"phsubsw","*":"Subtract 16-bit signed integer horizontally, pack saturated integers to xmm1."},"VPHSUBSW":{"_":"phsubsw","*":"Subtract 16-bit signed integer horizontally, pack saturated integers to ymm1."},"PHSUBW:PHSUBD":{"_":"phsubw:phsubd","*":"(V)PHSUBW performs horizontal subtraction on each adjacent pair of 16-bit signed integers by subtracting the most significant word from the least significant word of each pair in the source and destination operands, and packs the signed 16-bit results to the destination operand (first operand). (V)PHSUBD performs horizontal subtraction on each adjacent pair of 32-bit signed integers by subtracting the most significant doubleword from the least significant doubleword of each pair, and packs the signed 32-bit result to the destination operand. When the source operand is a 128-bit memory operand, the operand must be aligned on a 16-byte boundary or a general-protection exception (#GP) will be generated."},"VPHSUBW":{"_":"phsubw:phsubd","*":"Subtract 16-bit signed integers horizontally, pack to ymm1."},"PHSUBD":{"_":"phsubw:phsubd","*":"Subtract 32-bit signed integers horizontally, pack to xmm1."},"VPHSUBD":{"_":"phsubw:phsubd","*":"Subtract 32-bit signed integers horizontally, pack to ymm1."},"PHSUBW":{"_":"phsubw:phsubd","*":"Subtract 16-bit signed integers horizontally, pack to xmm1."},"PINSRB:PINSRD:PINSRQ":{"_":"pinsrb:pinsrd:pinsrq","*":"Copies a byte/dword/qword from the source operand (second operand) and inserts it in the destination operand (first operand) at the location specified with the count operand (third operand). (The other elements in the destination register are left untouched.) The source operand can be a general-purpose register or a memory location. (When the source operand is a general-purpose register, PINSRB copies the low byte of the register.) The destination operand is an XMM register. The count operand is an 8-bit immediate. When specifying a qword[dword, byte] location in an XMM register, the [2, 4] least-significant bit(s) of the count operand specify the location."},"PINSRD":{"_":"pinsrb:pinsrd:pinsrq","*":"Insert a dword integer value from r/m32 into the xmm1 at the destination element specified by imm8."},"VPINSRQ":{"_":"pinsrb:pinsrd:pinsrq","*":"Insert a qword integer value from r64/m64 and rest from xmm2 into xmm1 at the qword offset in imm8."},"PINSRQ":{"_":"pinsrb:pinsrd:pinsrq","*":"Insert a qword integer value from r/m64 into the xmm1 at the destination element specified by imm8."},"VPINSRD":{"_":"pinsrb:pinsrd:pinsrq","*":"Insert a dword integer value from r32/m32 and rest from xmm2 into xmm1 at the dword offset in imm8."},"PINSRB":{"_":"pinsrb:pinsrd:pinsrq","*":"Insert a byte integer value from r32/m8 into xmm1 at the destination element in xmm1 specified by imm8."},"VPINSRB":{"_":"pinsrb:pinsrd:pinsrq","*":"Merge a byte integer value from r32/m8 and rest from xmm2 into xmm1 at the byte offset in imm8."},"PINSRW":{"_":"pinsrw","*":"Move the low word of r32 or from m16 into xmm at the word position specified by imm8."},"VPINSRW":{"_":"pinsrw","*":"Insert a word integer value from r32/m16 and rest from xmm2 into xmm1 at the word offset in imm8."},"PMADDUBSW":{"_":"pmaddubsw","*":"Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to xmm1."},"VPMADDUBSW":{"_":"pmaddubsw","*":"Multiply signed and unsigned bytes, add horizontal pair of signed words, pack saturated signed-words to zmm1 under writemask k1."},"PMADDWD":{"_":"pmaddwd","*":"Multiply the packed word integers in xmm1 by the packed word integers in xmm2/m128, add adjacent doubleword results, and store in xmm1."},"VPMADDWD":{"_":"pmaddwd","*":"Multiply the packed word integers in zmm2 by the packed word integers in zmm3/m512, add adjacent doubleword results, and store in zmm1 under writemask k1."},"PMAXSB:PMAXSW:PMAXSD:PMAXSQ":{"_":"pmaxsb:pmaxsw:pmaxsd:pmaxsq","*":"Performs a SIMD compare of the packed signed byte, word, dword or qword integers in the second source operand and the first source operand and returns the maximum value for each pair of integers to the destination operand."},"VPMAXSW":{"_":"pmaxsb:pmaxsw:pmaxsd:pmaxsq","*":"Compare packed signed word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1."},"PMAXSD":{"_":"pmaxsb:pmaxsw:pmaxsd:pmaxsq","*":"Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1."},"PMAXSB":{"_":"pmaxsb:pmaxsw:pmaxsd:pmaxsq","*":"Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1."},"PMAXSW":{"_":"pmaxsb:pmaxsw:pmaxsd:pmaxsq","*":"Compare packed signed word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1."},"VPMAXSQ":{"_":"pmaxsb:pmaxsw:pmaxsd:pmaxsq","*":"Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 using writemask k1."},"VPMAXSD":{"_":"pmaxsb:pmaxsw:pmaxsd:pmaxsq","*":"Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 using writemask k1."},"VPMAXSB":{"_":"pmaxsb:pmaxsw:pmaxsd:pmaxsq","*":"Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1."},"PMAXUB:PMAXUW":{"_":"pmaxub:pmaxuw","*":"Performs a SIMD compare of the packed unsigned byte, word integers in the second source operand and the first source operand and returns the maximum value for each pair of integers to the destination operand."},"PMAXUW":{"_":"pmaxub:pmaxuw","*":"Compare packed unsigned word integers in xmm2/m128 and xmm1 and stores maximum packed values in xmm1."},"VPMAXUW":{"_":"pmaxub:pmaxuw","*":"Compare packed unsigned word integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1."},"VPMAXUB":{"_":"pmaxub:pmaxuw","*":"Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed maximum values in zmm1 under writemask k1."},"PMAXUB":{"_":"pmaxub:pmaxuw","*":"Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1."},"PMAXUD:PMAXUQ":{"_":"pmaxud:pmaxuq","*":"Performs a SIMD compare of the packed unsigned dword or qword integers in the second source operand and the first source operand and returns the maximum value for each pair of integers to the destination operand."},"VPMAXUD":{"_":"pmaxud:pmaxuq","*":"Compare packed unsigned dword integers in zmm2 and zmm3/m512/m32bcst and store packed maximum values in zmm1 under writemask k1."},"PMAXUD":{"_":"pmaxud:pmaxuq","*":"Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed maximum values in xmm1."},"VPMAXUQ":{"_":"pmaxud:pmaxuq","*":"Compare packed unsigned qword integers in zmm2 and zmm3/m512/m64bcst and store packed maximum values in zmm1 under writemask k1."},"PMINSB:PMINSW":{"_":"pminsb:pminsw","*":"Performs a SIMD compare of the packed signed byte, word, or dword integers in the second source operand and the first source operand and returns the minimum value for each pair of integers to the destination operand."},"VPMINSW":{"_":"pminsb:pminsw","*":"Compare packed signed word integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1."},"VPMINSB":{"_":"pminsb:pminsw","*":"Compare packed signed byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1."},"PMINSB":{"_":"pminsb:pminsw","*":"Compare packed signed byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1."},"PMINSW":{"_":"pminsb:pminsw","*":"Compare packed signed word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1."},"PMINSD:PMINSQ":{"_":"pminsd:pminsq","*":"Performs a SIMD compare of the packed signed dword or qword integers in the second source operand and the first source operand and returns the minimum value for each pair of integers to the destination operand."},"VPMINSQ":{"_":"pminsd:pminsq","*":"Compare packed signed qword integers in zmm2 and zmm3/m512/m64bcst and store packed minimum values in zmm1 under writemask k1."},"PMINSD":{"_":"pminsd:pminsq","*":"Compare packed signed dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1."},"VPMINSD":{"_":"pminsd:pminsq","*":"Compare packed signed dword integers in zmm2 and zmm3/m512/m32bcst and store packed minimum values in zmm1 under writemask k1."},"PMINUB:PMINUW":{"_":"pminub:pminuw","*":"Performs a SIMD compare of the packed unsigned byte or word integers in the second source operand and the first source operand and returns the minimum value for each pair of integers to the destination operand."},"VPMINUW":{"_":"pminub:pminuw","*":"Compare packed unsigned word integers in zmm3/m512 and zmm2 and return packed minimum values in zmm1 under writemask k1."},"VPMINUB":{"_":"pminub:pminuw","*":"Compare packed unsigned byte integers in zmm2 and zmm3/m512 and store packed minimum values in zmm1 under writemask k1."},"PMINUW":{"_":"pminub:pminuw","*":"Compare packed unsigned word integers in xmm2/m128 and xmm1 and store packed minimum values in xmm1."},"PMINUB":{"_":"pminub:pminuw","*":"Compare packed unsigned byte integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1."},"PMINUD:PMINUQ":{"_":"pminud:pminuq","*":"Performs a SIMD compare of the packed unsigned dword/qword integers in the second source operand and the first source operand and returns the minimum value for each pair of integers to the destination operand."},"VPMINUQ":{"_":"pminud:pminuq","*":"Compare packed unsigned qword integers in zmm2 and zmm3/m512/m64bcst and store packed minimum values in zmm1 under writemask k1."},"VPMINUD":{"_":"pminud:pminuq","*":"Compare packed unsigned dword integers in zmm2 and zmm3/m512/m32bcst and store packed minimum values in zmm1 under writemask k1."},"PMINUD":{"_":"pminud:pminuq","*":"Compare packed unsigned dword integers in xmm1 and xmm2/m128 and store packed minimum values in xmm1."},"PMOVMSKB":{"_":"pmovmskb","*":"Move a byte mask of xmm to reg. The upper bits of r32 or r64 are zeroed"},"VPMOVMSKB":{"_":"pmovmskb","*":"Move a 32-bit mask of ymm1 to reg. The upper bits of r64 are filled with zeros."},"PMOVSX":{"_":"pmovsx","*":"Legacy and VEX encoded versions: Packed byte, word, or dword integers in the low bytes of the source operand (second operand) are sign extended to word, dword, or quadword integers and stored in packed signed bytes the destination operand."},"PMOVSXBD":{"_":"pmovsx","*":"Sign extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1."},"VPMOVSXBQ":{"_":"pmovsx","*":"Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1."},"VPMOVSXBW":{"_":"pmovsx","*":"Sign extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1."},"VPMOVSXWD":{"_":"pmovsx","*":"Sign extend 16 packed 16-bit integers in the low 32 bytes of ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1."},"VPMOVSXWQ":{"_":"pmovsx","*":"Sign extend 8 packed 16-bit integers in the low 16 bytes of xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1."},"VPMOVSXDQ":{"_":"pmovsx","*":"Sign extend 8 packed 32-bit integers in the low 32 bytes of ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1."},"PMOVSXWD":{"_":"pmovsx","*":"Sign extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1."},"PMOVSXBQ":{"_":"pmovsx","*":"Sign extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1."},"VPMOVSXBD":{"_":"pmovsx","*":"Sign extend 16 packed 8-bit integers in the low 16 bytes of xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1."},"PMOVSXDQ":{"_":"pmovsx","*":"Sign extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1."},"PMOVSXBW":{"_":"pmovsx","*":"Sign extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1."},"PMOVSXWQ":{"_":"pmovsx","*":"Sign extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1."},"PMOVZX":{"_":"pmovzx","*":"Legacy, VEX and EVEX encoded versions: Packed byte, word, or dword integers starting from the low bytes of the source operand (second operand) are zero extended to word, dword, or quadword integers and stored in packed signed bytes the destination operand."},"PMOVZXBW":{"_":"pmovzx","*":"Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1."},"PMOVZXBD":{"_":"pmovzx","*":"Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1."},"PMOVZXWQ":{"_":"pmovzx","*":"Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1."},"VPMOVZXBD":{"_":"pmovzx","*":"Zero extend 16 packed 8-bit integers in xmm2/m128 to 16 packed 32-bit integers in zmm1 subject to writemask k1."},"VPMOVZXWQ":{"_":"pmovzx","*":"Zero extend 8 packed 16-bit integers in xmm2/m128 to 8 packed 64-bit integers in zmm1 subject to writemask k1."},"PMOVZXDQ":{"_":"pmovzx","*":"Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1."},"PMOVZXBQ":{"_":"pmovzx","*":"Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1."},"VPMOVZXBW":{"_":"pmovzx","*":"Zero extend 32 packed 8-bit integers in ymm2/m256 to 32 packed 16-bit integers in zmm1."},"VPMOVZXDQ":{"_":"pmovzx","*":"Zero extend 8 packed 32-bit integers in ymm2/m256 to 8 packed 64-bit integers in zmm1 using writemask k1."},"VPMOVZXBQ":{"_":"pmovzx","*":"Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 64-bit integers in zmm1 subject to writemask k1."},"VPMOVZXWD":{"_":"pmovzx","*":"Zero extend 16 packed 16-bit integers in ymm2/m256 to 16 packed 32-bit integers in zmm1 subject to writemask k1."},"PMOVZXWD":{"_":"pmovzx","*":"Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1."},"PMULDQ":{"_":"pmuldq","*":"Multiply packed signed doubleword integers in xmm1 by packed signed doubleword integers in xmm2/m128, and store the quadword results in xmm1."},"VPMULDQ":{"_":"pmuldq","*":"Multiply packed signed doubleword integers in zmm2 by packed signed doubleword integers in zmm3/m512/m64bcst, and store the quadword results in zmm1 using writemask k1."},"PMULHRSW":{"_":"pmulhrsw","*":"Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to xmm1."},"VPMULHRSW":{"_":"pmulhrsw","*":"Multiply 16-bit signed words, scale and round signed doublewords, pack high 16 bits to zmm1 under writemask k1."},"PMULHUW":{"_":"pmulhuw","*":"Multiply the packed unsigned word integers in xmm1 and xmm2/m128, and store the high 16 bits of the results in xmm1."},"VPMULHUW":{"_":"pmulhuw","*":"Multiply the packed unsigned word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1."},"PMULHW":{"_":"pmulhw","*":"Multiply the packed signed word integers in xmm1 and xmm2/m128, and store the high 16 bits of the results in xmm1."},"VPMULHW":{"_":"pmulhw","*":"Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the high 16 bits of the results in zmm1 under writemask k1."},"PMULLD:PMULLQ":{"_":"pmulld:pmullq","*":"Performs a SIMD signed multiply of the packed signed dword/qword integers from each element of the first source operand with the corresponding element in the second source operand. The low 32/64 bits of each 64/128-bit intermediate results are stored to the destination operand."},"VPMULLQ":{"_":"pmulld:pmullq","*":"Multiply the packed qword signed integers in zmm2 and zmm3/m512/m64bcst and store the low 64 bits of each product in zmm1 under writemask k1."},"PMULLD":{"_":"pmulld:pmullq","*":"Multiply the packed dword signed integers in xmm1 and xmm2/m128 and store the low 32 bits of each product in xmm1."},"VPMULLD":{"_":"pmulld:pmullq","*":"Multiply the packed dword signed integers in zmm2 and zmm3/m512/m32bcst and store the low 32 bits of each product in zmm1 under writemask k1."},"PMULLW":{"_":"pmullw","*":"Multiply the packed signed word integers in xmm1 and xmm2/m128, and store the low 16 bits of the results in xmm1."},"VPMULLW":{"_":"pmullw","*":"Multiply the packed signed word integers in zmm2 and zmm3/m512, and store the low 16 bits of the results in zmm1 under writemask k1."},"PMULUDQ":{"_":"pmuludq","*":"Multiply packed unsigned doubleword integers in xmm1 by packed unsigned doubleword integers in xmm2/m128, and store the quadword results in xmm1."},"VPMULUDQ":{"_":"pmuludq","*":"Multiply packed unsigned doubleword integers in zmm2 by packed unsigned doubleword integers in zmm3/m512/m64bcst, and store the quadword results in zmm1 under writemask k1."},"POP":{"_":"pop","*":"Pop top of stack into GS; increment stack pointer by 64 bits."},"POPA:POPAD":{"_":"popa:popad","*":"Pops doublewords (POPAD) or words (POPA) from the stack into the general-purpose registers. The registers are loaded in the following order: EDI, ESI, EBP, EBX, EDX, ECX, and EAX (if the operand-size attribute is 32) and DI, SI, BP, BX, DX, CX, and AX (if the operand-size attribute is 16). (These instructions reverse the operation of the PUSHA/PUSHAD instructions.) The value on the stack for the ESP or SP register is ignored. Instead, the ESP or SP register is incremented after each register is loaded."},"POPAD":{"_":"popa:popad","*":"Pop EDI, ESI, EBP, EBX, EDX, ECX, and EAX."},"POPA":{"_":"popa:popad","*":"Pop DI, SI, BP, BX, DX, CX, and AX."},"POPCNT":{"_":"popcnt","*":"POPCNT on r/m64"},"POPF:POPFD:POPFQ":{"_":"popf:popfd:popfq","*":"Pops a doubleword (POPFD) from the top of the stack (if the current operand-size attribute is 32) and stores the value in the EFLAGS register, or pops a word from the top of the stack (if the operand-size attribute is 16) and stores it in the lower 16 bits of the EFLAGS register (that is, the FLAGS register). These instructions reverse the operation of the PUSHF/PUSHFD/PUSHFQ instructions."},"POPFD":{"_":"popf:popfd:popfq","*":"Pop top of stack into EFLAGS."},"POPFQ":{"_":"popf:popfd:popfq","*":"Pop top of stack and zero-extend into RFLAGS."},"POPF":{"_":"popf:popfd:popfq","*":"Pop top of stack into lower 16 bits of EFLAGS."},"POR":{"_":"por","*":"Bitwise OR of xmm2/m128 and xmm1."},"VPOR":{"_":"por","*":"Bitwise OR of ymm2/m256 and ymm3."},"VPORD":{"_":"por","*":"Bitwise OR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1."},"VPORQ":{"_":"por","*":"Bitwise OR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1."},"PREFETCHW":{"_":"prefetchw","*":"Move data from m8 closer to the processor in anticipation of a write."},"PREFETCHWT1":{"_":"prefetchwt1","*":"Move data from m8 closer to the processor using T1 hint with intent to write."},"PREFETCHH":{"_":"prefetchh","*":"Fetches the line of data from memory that contains the byte specified with the source operand to a location in the cache hierarchy specified by a locality hint"},"PREFETCHT2":{"_":"prefetchh","*":"Move data from m8 closer to the processor using T2 hint."},"PREFETCHT0":{"_":"prefetchh","*":"Move data from m8 closer to the processor using T0 hint."},"PREFETCHT1":{"_":"prefetchh","*":"Move data from m8 closer to the processor using T1 hint."},"PREFETCHNTA":{"_":"prefetchh","*":"Move data from m8 closer to the processor using NTA hint."},"PSADBW":{"_":"psadbw","*":"Computes the absolute differences of the packed unsigned byte integers from xmm2 /m128 and xmm1; the 8 low differences and 8 high differences are then summed separately to produce two unsigned word integer results."},"VPSADBW":{"_":"psadbw","*":"Computes the absolute differences of the packed unsigned byte integers from zmm3 /m512 and zmm2; then each consecutive 8 differences are summed separately to produce four unsigned word integer results."},"PSHUFB":{"_":"pshufb","*":"Shuffle bytes in xmm1 according to contents of xmm2/m128."},"VPSHUFB":{"_":"pshufb","*":"Shuffle bytes in zmm2 according to contents of zmm3/m512 under write mask k1."},"PSHUFD":{"_":"pshufd","*":"Shuffle the doublewords in xmm2/m128 based on the encoding in imm8 and store the result in xmm1."},"VPSHUFD":{"_":"pshufd","*":"Shuffle the doublewords in zmm2/m512/m32bcst based on the encoding in imm8 and store the result in zmm1 using writemask k1."},"PSHUFHW":{"_":"pshufhw","*":"Shuffle the high words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1."},"VPSHUFHW":{"_":"pshufhw","*":"Shuffle the high words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1."},"PSHUFLW":{"_":"pshuflw","*":"Shuffle the low words in xmm2/m128 based on the encoding in imm8 and store the result in xmm1."},"VPSHUFLW":{"_":"pshuflw","*":"Shuffle the low words in zmm2/m512 based on the encoding in imm8 and store the result in zmm1 under write mask k1."},"PSHUFW":{"_":"pshufw","*":"Shuffle the words in mm2/m64 based on the encoding in imm8 and store the result in mm1."},"PSIGNB:PSIGNW:PSIGND":{"_":"psignb:psignw:psignd","*":"(V)PSIGNB/(V)PSIGNW/(V)PSIGND negates each data element of the destination operand (the first operand) if the signed integer value of the corresponding data element in the source operand (the second operand) is less than zero. If the signed integer value of a data element in the source operand is positive, the corresponding data element in the destination operand is unchanged. If a data element in the source operand is zero, the corresponding data element in the destination operand is set to zero."},"PSIGND":{"_":"psignb:psignw:psignd","*":"Negate/zero/preserve packed doubleword integers in xmm1 depending on the corresponding sign in xmm2/m128."},"VPSIGNB":{"_":"psignb:psignw:psignd","*":"Negate packed byte integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero."},"PSIGNW":{"_":"psignb:psignw:psignd","*":"Negate/zero/preserve packed word integers in xmm1 depending on the corresponding sign in xmm2/m128."},"PSIGNB":{"_":"psignb:psignw:psignd","*":"Negate/zero/preserve packed byte integers in xmm1 depending on the corresponding sign in xmm2/m128."},"VPSIGNW":{"_":"psignb:psignw:psignd","*":"Negate packed 16-bit integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero."},"VPSIGND":{"_":"psignb:psignw:psignd","*":"Negate packed doubleword integers in ymm2 if the corresponding sign in ymm3/m256 is less than zero."},"PSLLDQ":{"_":"pslldq","*":"Shift xmm1 left by imm8 bytes while shifting in 0s."},"VPSLLDQ":{"_":"pslldq","*":"Shift zmm2/m512 left by imm8 bytes while shifting in 0s and store result in zmm1."},"PSLLW:PSLLD:PSLLQ":{"_":"psllw:pslld:psllq","*":"Shifts the bits in the individual data elements (words, doublewords, or quadword) in the destination operand (first operand) to the left by the number of bits specified in the count operand (second operand). As the bits in the data elements are shifted left, the empty low-order bits are cleared (set to 0). If the value specified by the count operand is greater than 15 (for words), 31 (for doublewords), or 63 (for a quadword), then the destination operand is set to all 0s. Figure 4-17 gives an example of shifting words in a 64-bit operand."},"VPSLLQ":{"_":"psllw:pslld:psllq","*":"Shift quadwords in xmm2 left by imm8 while shifting in 0s."},"VPSLLD":{"_":"psllw:pslld:psllq","*":"Shift doublewords in xmm2 left by imm8 while shifting in 0s."},"PSLLW":{"_":"psllw:pslld:psllq","*":"Shift words in xmm1 left by imm8 while shifting in 0s."},"PSLLD":{"_":"psllw:pslld:psllq","*":"Shift doublewords in xmm1 left by imm8 while shifting in 0s."},"PSLLQ":{"_":"psllw:pslld:psllq","*":"Shift quadwords in xmm1 left by imm8 while shifting in 0s."},"VPSLLW":{"_":"psllw:pslld:psllq","*":"Shift words in ymm2 left by imm8 while shifting in 0s."},"PSRAW:PSRAD:PSRAQ":{"_":"psraw:psrad:psraq","*":"Shifts the bits in the individual data elements (words, doublewords or quadwords) in the destination operand (first operand) to the right by the number of bits specified in the count operand (second operand). As the bits in the data elements are shifted right, the empty high-order bits are filled with the initial value of the sign bit of the data element. If the value specified by the count operand is greater than 15 (for words), 31 (for doublewords), or 63 (for quadwords), each destination data element is filled with the initial value of the sign bit of the element. (Figure 4-18 gives an example of shifting words in a 64-bit operand.)"},"PSRAD":{"_":"psraw:psrad:psraq","*":"Shift doublewords in xmm1 right by imm8 while shifting in sign bits."},"VPSRAW":{"_":"psraw:psrad:psraq","*":"Shift words in zmm2 right by amount specified in xmm3/m128 while shifting in sign bits using writemask k1."},"VPSRAD":{"_":"psraw:psrad:psraq","*":"Shift doublewords in ymm2 right by imm8 while shifting in sign bits."},"PSRAW":{"_":"psraw:psrad:psraq","*":"Shift words in xmm1 right by imm8 while shifting in sign bits"},"PSRLDQ":{"_":"psrldq","*":"Shift xmm1 right by imm8 while shifting in 0s."},"VPSRLDQ":{"_":"psrldq","*":"Shift zmm2/m512 right by imm8 bytes while shifting in 0s and store result in zmm1."},"PSRLW:PSRLD:PSRLQ":{"_":"psrlw:psrld:psrlq","*":"Shifts the bits in the individual data elements (words, doublewords, or quadword) in the destination operand (first operand) to the right by the number of bits specified in the count operand (second operand). As the bits in the data elements are shifted right, the empty high-order bits are cleared (set to 0). If the value specified by the count operand is greater than 15 (for words), 31 (for doublewords), or 63 (for a quadword), then the destination operand is set to all 0s. Figure 4-19 gives an example of shifting words in a 64-bit operand."},"VPSRLQ":{"_":"psrlw:psrld:psrlq","*":"Shift quadwords in xmm2 right by imm8 while shifting in 0s."},"PSRLD":{"_":"psrlw:psrld:psrlq","*":"Shift doublewords in xmm1 right by imm8 while shifting in 0s."},"PSRLQ":{"_":"psrlw:psrld:psrlq","*":"Shift quadwords in xmm1 right by imm8 while shifting in 0s."},"VPSRLW":{"_":"psrlw:psrld:psrlq","*":"Shift words in ymm2 right by imm8 while shifting in 0s."},"PSRLW":{"_":"psrlw:psrld:psrlq","*":"Shift words in xmm1 right by imm8 while shifting in 0s."},"VPSRLD":{"_":"psrlw:psrld:psrlq","*":"Shift doublewords in xmm2 right by imm8 while shifting in 0s."},"PSUBB:PSUBW:PSUBD":{"_":"psubb:psubw:psubd","*":"Performs a SIMD subtract of the packed integers of the source operand (second operand) from the packed integers of the destination operand (first operand), and stores the packed integer results in the destination operand. See Figure 9-4 in the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1, for an illustration of a SIMD operation. Overflow is handled with wraparound, as described in the following paragraphs."},"PSUBD":{"_":"psubb:psubw:psubd","*":"Subtract packed doubleword integers in xmm2/mem128 from packed doubleword integers in xmm1."},"VPSUBD":{"_":"psubb:psubw:psubd","*":"Subtract packed doubleword integers in ymm3/m256 from ymm2."},"VPSUBB":{"_":"psubb:psubw:psubd","*":"Subtract packed byte integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1."},"VPSUBW":{"_":"psubb:psubw:psubd","*":"Subtract packed word integers in zmm3/m512 from zmm2 and store in zmm1 using writemask k1."},"PSUBW":{"_":"psubb:psubw:psubd","*":"Subtract packed word integers in xmm2/m128 from packed word integers in xmm1."},"PSUBB":{"_":"psubb:psubw:psubd","*":"Subtract packed byte integers in xmm2/m128 from packed byte integers in xmm1."},"PSUBQ":{"_":"psubq","*":"Subtract packed quadword integers in xmm1 from xmm2 /m128."},"VPSUBQ":{"_":"psubq","*":"Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1."},"PSUBSB:PSUBSW":{"_":"psubsb:psubsw","*":"Performs a SIMD subtract of the packed signed integers of the source operand (second operand) from the packed signed integers of the destination operand (first operand), and stores the packed integer results in the destination operand. See Figure 9-4 in the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1, for an illustration of a SIMD operation. Overflow is handled with signed saturation, as described in the following paragraphs."},"PSUBSW":{"_":"psubsb:psubsw","*":"Subtract packed signed word integers in xmm2/m128 from packed signed word integers in xmm1 and saturate results."},"PSUBSB":{"_":"psubsb:psubsw","*":"Subtract packed signed byte integers in xmm2/m128 from packed signed byte integers in xmm1 and saturate results."},"VPSUBSW":{"_":"psubsb:psubsw","*":"Subtract packed signed word integers in ymm3/m256 from packed signed word integers in ymm2 and saturate results and store in ymm1 using writemask k1."},"VPSUBSB":{"_":"psubsb:psubsw","*":"Subtract packed signed byte integers in zmm3/m512 from packed signed byte integers in zmm2 and saturate results and store in zmm1 using writemask k1."},"PSUBUSB:PSUBUSW":{"_":"psubusb:psubusw","*":"Performs a SIMD subtract of the packed unsigned integers of the source operand (second operand) from the packed unsigned integers of the destination operand (first operand), and stores the packed unsigned integer results in the destination operand. See Figure 9-4 in the Intel® 64 and IA-32 Architectures Software Developer’s Manual, Volume 1, for an illustration of a SIMD operation. Overflow is handled with unsigned saturation, as described in the following paragraphs."},"VPSUBUSW":{"_":"psubusb:psubusw","*":"Subtract packed unsigned word integers in ymm3/m256 from packed unsigned word integers in ymm2, saturate results and store in ymm1 using writemask k1."},"PSUBUSW":{"_":"psubusb:psubusw","*":"Subtract packed unsigned word integers in xmm2/m128 from packed unsigned word integers in xmm1 and saturate result."},"VPSUBUSB":{"_":"psubusb:psubusw","*":"Subtract packed unsigned byte integers in zmm3/m512 from packed unsigned byte integers in zmm2, saturate results and store in zmm1 using writemask k1."},"PSUBUSB":{"_":"psubusb:psubusw","*":"Subtract packed unsigned byte integers in xmm2/m128 from packed unsigned byte integers in xmm1 and saturate result."},"PTEST":{"_":"ptest","*":"Set ZF if xmm2/m128 AND xmm1 result is all 0s. Set CF if xmm2/m128 AND NOT xmm1 result is all 0s."},"VPTEST":{"_":"ptest","*":"Set ZF and CF depending on bitwise AND and ANDN of sources."},"PTWRITE":{"_":"ptwrite","*":"Reads the data from r32/m32 to encode into a PTW packet if dependencies are met (see details below)."},"PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ":{"_":"punpckhbw:punpckhwd:punpckhdq:punpckhqdq","*":"Unpacks and interleaves the high-order data elements (bytes, words, doublewords, or quadwords) of the destination operand (first operand) and source operand (second operand) into the destination operand. Figure 4-20 shows the unpack operation for bytes in 64-bit operands. The low-order data elements are ignored."},"VPUNPCKHDQ":{"_":"punpckhbw:punpckhwd:punpckhdq:punpckhqdq","*":"Interleave high-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask."},"VPUNPCKHBW":{"_":"punpckhbw:punpckhwd:punpckhdq:punpckhqdq","*":"Interleave high-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask."},"VPUNPCKHQDQ":{"_":"punpckhbw:punpckhwd:punpckhdq:punpckhqdq","*":"Interleave high-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask."},"VPUNPCKHWD":{"_":"punpckhbw:punpckhwd:punpckhdq:punpckhqdq","*":"Interleave high-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask."},"PUNPCKHDQ":{"_":"punpckhbw:punpckhwd:punpckhdq:punpckhqdq","*":"Unpack and interleave high-order doublewords from xmm1 and xmm2/m128 into xmm1."},"PUNPCKHBW":{"_":"punpckhbw:punpckhwd:punpckhdq:punpckhqdq","*":"Unpack and interleave high-order bytes from xmm1 and xmm2/m128 into xmm1."},"PUNPCKHQDQ":{"_":"punpckhbw:punpckhwd:punpckhdq:punpckhqdq","*":"Unpack and interleave high-order quadwords from xmm1 and xmm2/m128 into xmm1."},"PUNPCKHWD":{"_":"punpckhbw:punpckhwd:punpckhdq:punpckhqdq","*":"Unpack and interleave high-order words from xmm1 and xmm2/m128 into xmm1."},"PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ":{"_":"punpcklbw:punpcklwd:punpckldq:punpcklqdq","*":"Unpacks and interleaves the low-order data elements (bytes, words, doublewords, and quadwords) of the destination operand (first operand) and source operand (second operand) into the destination operand. (Figure 4-22 shows the unpack operation for bytes in 64-bit operands.). The high-order data elements are ignored."},"VPUNPCKLWD":{"_":"punpcklbw:punpcklwd:punpckldq:punpcklqdq","*":"Interleave low-order words from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1."},"PUNPCKLQDQ":{"_":"punpcklbw:punpcklwd:punpckldq:punpcklqdq","*":"Interleave low-order quadword from xmm1 and xmm2/m128 into xmm1 register."},"PUNPCKLBW":{"_":"punpcklbw:punpcklwd:punpckldq:punpcklqdq","*":"Interleave low-order bytes from xmm1 and xmm2/m128 into xmm1."},"PUNPCKLDQ":{"_":"punpcklbw:punpcklwd:punpckldq:punpcklqdq","*":"Interleave low-order doublewords from xmm1 and xmm2/m128 into xmm1."},"VPUNPCKLDQ":{"_":"punpcklbw:punpcklwd:punpckldq:punpcklqdq","*":"Interleave low-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register subject to write mask k1."},"PUNPCKLWD":{"_":"punpcklbw:punpcklwd:punpckldq:punpcklqdq","*":"Interleave low-order words from xmm1 and xmm2/m128 into xmm1."},"VPUNPCKLBW":{"_":"punpcklbw:punpcklwd:punpckldq:punpcklqdq","*":"Interleave low-order bytes from xmm2 and xmm3/m128 into xmm1 register subject to write mask k1."},"VPUNPCKLQDQ":{"_":"punpcklbw:punpcklwd:punpckldq:punpcklqdq","*":"Interleave low-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register subject to write mask k1."},"PUSH":{"_":"push","*":"Push GS."},"PUSHA:PUSHAD":{"_":"pusha:pushad","*":"Pushes the contents of the general-purpose registers onto the stack. The registers are stored on the stack in the following order: EAX, ECX, EDX, EBX, ESP (original value), EBP, ESI, and EDI (if the current operand-size attribute is 32) and AX, CX, DX, BX, SP (original value), BP, SI, and DI (if the operand-size attribute is 16). These instructions perform the reverse operation of the POPA/POPAD instructions. The value pushed for the ESP or SP register is its value before prior to pushing the first register (see the “Operation” section below)."},"PUSHAD":{"_":"pusha:pushad","*":"Push EAX, ECX, EDX, EBX, original ESP, EBP, ESI, and EDI."},"PUSHA":{"_":"pusha:pushad","*":"Push AX, CX, DX, BX, original SP, BP, SI, and DI."},"PUSHF:PUSHFD:PUSHFQ":{"_":"pushf:pushfd:pushfq","*":"Decrements the stack pointer by 4 (if the current operand-size attribute is 32) and pushes the entire contents of the EFLAGS register onto the stack, or decrements the stack pointer by 2 (if the operand-size attribute is 16) and pushes the lower 16 bits of the EFLAGS register (that is, the FLAGS register) onto the stack. These instructions reverse the operation of the POPF/POPFD instructions."},"PUSHFQ":{"_":"pushf:pushfd:pushfq","*":"Push RFLAGS."},"PUSHFD":{"_":"pushf:pushfd:pushfq","*":"Push EFLAGS."},"PUSHF":{"_":"pushf:pushfd:pushfq","*":"Push lower 16 bits of EFLAGS."},"PXOR":{"_":"pxor","*":"Bitwise XOR of xmm2/m128 and xmm1."},"VPXORQ":{"_":"pxor","*":"Bitwise XOR of packed quadword integers in zmm2 and zmm3/m512/m64bcst using writemask k1."},"VPXOR":{"_":"pxor","*":"Bitwise XOR of ymm3/m256 and ymm2."},"VPXORD":{"_":"pxor","*":"Bitwise XOR of packed doubleword integers in zmm2 and zmm3/m512/m32bcst using writemask k1."},"RCL:RCR:ROL:ROR":{"_":"rcl:rcr:rol:ror","*":"Shifts (rotates) the bits of the first operand (destination operand) the number of bit positions specified in the second operand (count operand) and stores the result in the destination operand. The destination operand can be a register or a memory location; the count operand is an unsigned integer that can be an immediate or a value in the CL register. The count is masked to 5 bits (or 6 bits if in 64-bit mode and REX.W = 1)."},"RCL":{"_":"rcl:rcr:rol:ror","*":"Rotate 65 bits (CF, r/m64) left imm8 times. Uses a 6 bit count."},"ROR":{"_":"rcl:rcr:rol:ror","*":"Rotate 64 bits r/m64 right imm8 times. Uses a 6 bit count."},"RCR":{"_":"rcl:rcr:rol:ror","*":"Rotate 65 bits (CF, r/m64) right imm8 times. Uses a 6 bit count."},"ROL":{"_":"rcl:rcr:rol:ror","*":"Rotate 64 bits r/m64 left imm8 times. Uses a 6 bit count."},"RCPPS":{"_":"rcpps","*":"Computes the approximate reciprocals of the packed single-precision floating-point values in xmm2/m128 and stores the results in xmm1."},"VRCPPS":{"_":"rcpps","*":"Computes the approximate reciprocals of packed single-precision values in ymm2/mem and stores the results in ymm1."},"RCPSS":{"_":"rcpss","*":"Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm2/m32 and stores the result in xmm1."},"VRCPSS":{"_":"rcpss","*":"Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm3/m32 and stores the result in xmm1. Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32]."},"RDFSBASE:RDGSBASE":{"_":"rdfsbase:rdgsbase","*":"Loads the general-purpose register indicated by the modR/M:r/m field with the FS or GS segment base address."},"RDFSBASE":{"_":"rdfsbase:rdgsbase","*":"Load the 64-bit destination register with the FS base address."},"RDGSBASE":{"_":"rdfsbase:rdgsbase","*":"FSGSBASE"},"RDPID":{"_":"rdpid","*":"Read IA32_TSC_AUX into r64."},"RDPKRU":{"_":"rdpkru","*":"Reads PKRU into EAX."},"RDPMC":{"_":"rdpmc","*":"Read performance-monitoring counter specified by ECX into EDX:EAX."},"RDTSC":{"_":"rdtsc","*":"Read time-stamp counter into EDX:EAX."},"RDTSCP":{"_":"rdtscp","*":"Read 64-bit time-stamp counter and IA32_TSC_AUX value into EDX:EAX and ECX."},"REP:REPE:REPZ:REPNE:REPNZ":{"_":"rep:repe:repz:repne:repnz","*":"Repeats a string instruction the number of times specified in the count register or until the indicated condition of the ZF flag is no longer met. The REP (repeat), REPE (repeat while equal), REPNE (repeat while not equal), REPZ (repeat while zero), and REPNZ (repeat while not zero) mnemonics are prefixes that can be added to one of the string instructions. The REP prefix can be added to the INS, OUTS, MOVS, LODS, and STOS instructions, and the REPE, REPNE, REPZ, and REPNZ prefixes can be added to the CMPS and SCAS instructions. (The REPZ and REPNZ prefixes are synonymous forms of the REPE and REPNE prefixes, respectively.) The F3H prefix is defined for the following instructions and undefined for the rest"},"REPNE":{"_":"rep:repe:repz:repne:repnz","*":"Find RAX, starting at [RDI]."},"REP":{"_":"rep:repe:repz:repne:repnz","*":"Fill RCX quadwords at [RDI] with RAX."},"REPE":{"_":"rep:repe:repz:repne:repnz","*":"Find non-RAX quadword starting at [RDI]."},"RET":{"_":"ret","*":"Far return to calling procedure and pop imm16 bytes from stack."},"RORX":{"_":"rorx","*":"Rotate 64-bit r/m64 right imm8 times without affecting arithmetic flags."},"ROUNDPD":{"_":"roundpd","*":"Round packed double precision floating-point values in xmm2/m128 and place the result in xmm1. The rounding mode is determined by imm8."},"VROUNDPD":{"_":"roundpd","*":"Round packed double-precision floating-point values in ymm2/m256 and place the result in ymm1. The rounding mode is determined by imm8."},"ROUNDPS":{"_":"roundps","*":"Round packed single precision floating-point values in xmm2/m128 and place the result in xmm1. The rounding mode is determined by imm8."},"VROUNDPS":{"_":"roundps","*":"Round packed single-precision floating-point values in ymm2/m256 and place the result in ymm1. The rounding mode is determined by imm8."},"ROUNDSD":{"_":"roundsd","*":"Round the low packed double precision floating-point value in xmm2/m64 and place the result in xmm1. The rounding mode is determined by imm8."},"VROUNDSD":{"_":"roundsd","*":"Round the low packed double precision floating-point value in xmm3/m64 and place the result in xmm1. The rounding mode is determined by imm8. Upper packed double precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64]."},"ROUNDSS":{"_":"roundss","*":"Round the low packed single precision floating-point value in xmm2/m32 and place the result in xmm1. The rounding mode is determined by imm8."},"VROUNDSS":{"_":"roundss","*":"Round the low packed single precision floating-point value in xmm3/m32 and place the result in xmm1. The rounding mode is determined by imm8. Also, upper packed single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32]."},"RSM":{"_":"rsm","*":"Resume operation of interrupted program."},"RSQRTPS":{"_":"rsqrtps","*":"Computes the approximate reciprocals of the square roots of the packed single-precision floating-point values in xmm2/m128 and stores the results in xmm1."},"VRSQRTPS":{"_":"rsqrtps","*":"Computes the approximate reciprocals of the square roots of packed single-precision values in ymm2/mem and stores the results in ymm1."},"RSQRTSS":{"_":"rsqrtss","*":"Computes the approximate reciprocal of the square root of the low single-precision floating-point value in xmm2/m32 and stores the results in xmm1."},"VRSQRTSS":{"_":"rsqrtss","*":"Computes the approximate reciprocal of the square root of the low single precision floating-point value in xmm3/m32 and stores the results in xmm1. Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32]."},"SAHF":{"_":"sahf","*":"Loads SF, ZF, AF, PF, and CF from AH into EFLAGS register."},"SAL:SAR:SHL:SHR":{"_":"sal:sar:shl:shr","*":"Shifts the bits in the first operand (destination operand) to the left or right by the number of bits specified in the second operand (count operand). Bits shifted beyond the destination operand boundary are first shifted into the CF flag, then discarded. At the end of the shift operation, the CF flag contains the last bit shifted out of the destination operand."},"SAL":{"_":"sal:sar:shl:shr","*":"Multiply r/m64 by 2, imm8 times."},"SAR":{"_":"sal:sar:shl:shr","*":"Signed divide* r/m64 by 2, imm8 times"},"SHL":{"_":"sal:sar:shl:shr","*":"Multiply r/m32 by 2, once."},"SARX:SHLX:SHRX":{"_":"sarx:shlx:shrx","*":"Shifts the bits of the first source operand (the second operand) to the left or right by a COUNT value specified in the second source operand (the third operand). The result is written to the destination operand (the first operand)."},"SARX":{"_":"sarx:shlx:shrx","*":"Shift r/m64 arithmetically right with count specified in r64b."},"SHRX":{"_":"sarx:shlx:shrx","*":"Shift r/m64 logically right with count specified in r64b."},"SHLX":{"_":"sarx:shlx:shrx","*":"Shift r/m64 logically left with count specified in r64b."},"SBB":{"_":"sbb","*":"Subtract with borrow r/m64 from r64."},"SCAS:SCASB:SCASW:SCASD":{"_":"scas:scasb:scasw:scasd","*":"In non-64-bit modes and in default 64-bit mode: this instruction compares a byte, word, doubleword or quadword specified using a memory operand with the value in AL, AX, or EAX. It then sets status flags in EFLAGS recording the results. The memory operand address is read from ES:(E)DI register (depending on the address-size attribute of the instruction and the current operational mode). Note that ES cannot be overridden with a segment override prefix."},"SCAS":{"_":"scas:scasb:scasw:scasd","*":"Compare RAX with quadword at RDI or EDI then set status flags."},"SCASD":{"_":"scas:scasb:scasw:scasd","*":"Compare EAX with doubleword at ES:(E)DI or RDI then set status flags.*"},"SCASQ":{"_":"scas:scasb:scasw:scasd","*":"Compare RAX with quadword at RDI or EDI then set status flags."},"SCASB":{"_":"scas:scasb:scasw:scasd","*":"Compare AL with byte at ES:(E)DI or RDI then set status flags.*"},"SCASW":{"_":"scas:scasb:scasw:scasd","*":"Compare AX with word at ES:(E)DI or RDI then set status flags.*"},"SETCC":{"_":"setcc","*":"Sets the destination operand to 0 or 1 depending on the settings of the status flags (CF, SF, OF, ZF, and PF) in the EFLAGS register. The destination operand points to a byte register or a byte in memory. The condition code suffix (cc) indicates the condition being tested for."},"SETNC":{"_":"setcc","*":"Set byte if not carry (CF=0)."},"SETO":{"_":"setcc","*":"Set byte if overflow (OF=1)."},"SETNO":{"_":"setcc","*":"Set byte if not overflow (OF=0)."},"SETNS":{"_":"setcc","*":"Set byte if not sign (SF=0)."},"SETGE":{"_":"setcc","*":"Set byte if greater or equal (SF=OF)."},"SETNB":{"_":"setcc","*":"Set byte if not below (CF=0)."},"SETG":{"_":"setcc","*":"Set byte if greater (ZF=0 and SF=OF)."},"SETE":{"_":"setcc","*":"Set byte if equal (ZF=1)."},"SETPE":{"_":"setcc","*":"Set byte if parity even (PF=1)."},"SETLE":{"_":"setcc","*":"Set byte if less or equal (ZF=1 or SF≠ OF)."},"SETNZ":{"_":"setcc","*":"Set byte if not zero (ZF=0)."},"SETL":{"_":"setcc","*":"Set byte if less (SF≠ OF)."},"SETNLE":{"_":"setcc","*":"Set byte if not less or equal (ZF=0 and SF=OF)."},"SETB":{"_":"setcc","*":"Set byte if below (CF=1)."},"SETNG":{"_":"setcc","*":"Set byte if not greater (ZF=1 or SF≠ OF)."},"SETAE":{"_":"setcc","*":"Set byte if above or equal (CF=0)."},"SETZ":{"_":"setcc","*":"Set byte if zero (ZF=1)."},"SETS":{"_":"setcc","*":"Set byte if sign (SF=1)."},"SETNE":{"_":"setcc","*":"Set byte if not equal (ZF=0)."},"SETPO":{"_":"setcc","*":"Set byte if parity odd (PF=0)."},"SETNGE":{"_":"setcc","*":"Set byte if not greater or equal (SF≠ OF)."},"SETBE":{"_":"setcc","*":"Set byte if below or equal (CF=1 or ZF=1)."},"SETP":{"_":"setcc","*":"Set byte if parity (PF=1)."},"SETNP":{"_":"setcc","*":"Set byte if not parity (PF=0)."},"SETA":{"_":"setcc","*":"Set byte if above (CF=0 and ZF=0)."},"SETNA":{"_":"setcc","*":"Set byte if not above (CF=1 or ZF=1)."},"SETNBE":{"_":"setcc","*":"Set byte if not below or equal (CF=0 and ZF=0)."},"SETC":{"_":"setcc","*":"Set byte if carry (CF=1)."},"SETNAE":{"_":"setcc","*":"Set byte if not above or equal (CF=1)."},"SETNL":{"_":"setcc","*":"Set byte if not less (SF=OF)."},"SFENCE":{"_":"sfence","*":"Serializes store operations."},"SHA1MSG1":{"_":"sha1msg1","*":"Performs an intermediate calculation for the next four SHA1 message dwords using previous message dwords from xmm1 and xmm2/m128, storing the result in xmm1."},"SHA1MSG2":{"_":"sha1msg2","*":"Performs the final calculation for the next four SHA1 message dwords using intermediate results from xmm1 and the previous message dwords from xmm2/m128, storing the result in xmm1."},"SHA1NEXTE":{"_":"sha1nexte","*":"Calculates SHA1 state variable E after four rounds of operation from the current SHA1 state variable A in xmm1. The calculated value of the SHA1 state variable E is added to the scheduled dwords in xmm2/m128, and stored with some of the scheduled dwords in xmm1."},"SHA1RNDS4":{"_":"sha1rnds4","*":"Performs four rounds of SHA1 operation operating on SHA1 state (A,B,C,D) from xmm1, with a pre-computed sum of the next 4 round message dwords and state variable E from xmm2/m128. The immediate byte controls logic functions and round constants."},"SHA256MSG1":{"_":"sha256msg1","*":"Performs an intermediate calculation for the next four SHA256 message dwords using previous message dwords from xmm1 and xmm2/m128, storing the result in xmm1."},"SHA256MSG2":{"_":"sha256msg2","*":"Performs the final calculation for the next four SHA256 message dwords using previous message dwords from xmm1 and xmm2/m128, storing the result in xmm1."},"SHA256RNDS2":{"_":"sha256rnds2","*":"Perform 2 rounds of SHA256 operation using an initial SHA256 state (C,D,G,H) from xmm1, an initial SHA256 state (A,B,E,F) from xmm2/m128, and a pre-computed sum of the next 2 round message dwords and the corresponding round constants from the implicit operand XMM0, storing the updated SHA256 state (A,B,E,F) result in xmm1."},"SHLD":{"_":"shld","*":"Shift r/m64 to left CL places while shifting bits from r64 in from the right."},"SHRD":{"_":"shrd","*":"Shift r/m64 to right CL places while shifting bits from r64 in from the left."},"SHUFPD":{"_":"shufpd","*":"Shuffle two pairs of double-precision floating-point values from xmm1 and xmm2/m128 using imm8 to select from each pair, interleaved result is stored in xmm1."},"VSHUFPD":{"_":"shufpd","*":"Shuffle eight paris of double-precision floating-point values from zmm2 and zmm3/m512/m64bcst using imm8 to select from each pair. store interleaved results in zmm1 subject to writemask k1."},"SHUFPS":{"_":"shufps","*":"Select from quadruplet of single-precision floating-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1."},"VSHUFPS":{"_":"shufps","*":"Select from quadruplet of single-precision floating-point values in zmm2 and zmm3/m512 using imm8, interleaved result pairs are stored in zmm1, subject to writemask k1."},"SIDT":{"_":"sidt","*":"Store IDTR to m."},"SLDT":{"_":"sldt","*":"Stores segment selector from LDTR in r64/m16."},"SMSW":{"_":"smsw","*":"Store machine status word in low-order 16 bits of r64/m16; high-order 16 bits of r32 are undefined."},"SQRTPD":{"_":"sqrtpd","*":"Computes Square Roots of the packed double-precision floating-point values in xmm2/m128 and stores the result in xmm1."},"VSQRTPD":{"_":"sqrtpd","*":"Computes Square Roots of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the result in zmm1 subject to writemask k1."},"SQRTPS":{"_":"sqrtps","*":"Computes Square Roots of the packed single-precision floating-point values in xmm2/m128 and stores the result in xmm1."},"VSQRTPS":{"_":"sqrtps","*":"Computes Square Roots of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the result in zmm1 subject to writemask k1."},"SQRTSD":{"_":"sqrtsd","*":"Computes square root of the low double-precision floating-point value in xmm2/m64 and stores the results in xmm1."},"VSQRTSD":{"_":"sqrtsd","*":"Computes square root of the low double-precision floating-point value in xmm3/m64 and stores the results in xmm1 under writemask k1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64]."},"SQRTSS":{"_":"sqrtss","*":"Computes square root of the low single-precision floating-point value in xmm2/m32 and stores the results in xmm1."},"VSQRTSS":{"_":"sqrtss","*":"Computes square root of the low single-precision floating-point value in xmm3/m32 and stores the results in xmm1 under writemask k1. Also, upper single-precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32]."},"STAC":{"_":"stac","*":"Set the AC flag in the EFLAGS register."},"STC":{"_":"stc","*":"Set CF flag."},"STD":{"_":"std","*":"Set DF flag."},"STI":{"_":"sti","*":"Set interrupt flag; external, maskable interrupts enabled at the end of the next instruction."},"STMXCSR":{"_":"stmxcsr","*":"Store contents of MXCSR register to m32."},"VSTMXCSR":{"_":"stmxcsr","*":"Store contents of MXCSR register to m32."},"STOS:STOSB:STOSW:STOSD:STOSQ":{"_":"stos:stosb:stosw:stosd:stosq","*":"In non-64-bit and default 64-bit mode; stores a byte, word, or doubleword from the AL, AX, or EAX register (respectively) into the destination operand. The destination operand is a memory location, the address of which is read from either the ES:EDI or ES:DI register (depending on the address-size attribute of the instruction and the mode of operation). The ES segment cannot be overridden with a segment override prefix."},"STOS":{"_":"stos:stosb:stosw:stosd:stosq","*":"Store RAX at address RDI or EDI."},"STOSD":{"_":"stos:stosb:stosw:stosd:stosq","*":"For legacy mode, store EAX at address ES:(E)DI; For 64-bit mode store EAX at address RDI or EDI."},"STOSW":{"_":"stos:stosb:stosw:stosd:stosq","*":"For legacy mode, store AX at address ES:(E)DI; For 64-bit mode store AX at address RDI or EDI."},"STOSB":{"_":"stos:stosb:stosw:stosd:stosq","*":"For legacy mode, store AL at address ES:(E)DI; For 64-bit mode store AL at address RDI or EDI."},"STOSQ":{"_":"stos:stosb:stosw:stosd:stosq","*":"Store RAX at address RDI or EDI."},"STR":{"_":"str","*":"Stores segment selector from TR in r/m16."},"SUB":{"_":"sub","*":"Subtract r/m64 from r64."},"SUBPD":{"_":"subpd","*":"Subtract packed double-precision floating-point values in xmm2/mem from xmm1 and store result in xmm1."},"VSUBPD":{"_":"subpd","*":"Subtract packed double-precision floating-point values from zmm3/m512/m64bcst to zmm2 and store result in zmm1 with writemask k1."},"SUBPS":{"_":"subps","*":"Subtract packed single-precision floating-point values in xmm2/mem from xmm1 and store result in xmm1."},"VSUBPS":{"_":"subps","*":"Subtract packed single-precision floating-point values in zmm3/m512/m32bcst from zmm2 and stores result in zmm1 with writemask k1."},"SUBSD":{"_":"subsd","*":"Subtract the low double-precision floating-point value in xmm2/m64 from xmm1 and store the result in xmm1."},"VSUBSD":{"_":"subsd","*":"Subtract the low double-precision floating-point value in xmm3/m64 from xmm2 and store the result in xmm1 under writemask k1."},"SUBSS":{"_":"subss","*":"Subtract the low single-precision floating-point value in xmm2/m32 from xmm1 and store the result in xmm1."},"VSUBSS":{"_":"subss","*":"Subtract the low single-precision floating-point value in xmm3/m32 from xmm2 and store the result in xmm1 under writemask k1."},"SWAPGS":{"_":"swapgs","*":"Exchanges the current GS base register value with the value contained in MSR address C0000102H."},"SYSCALL":{"_":"syscall","*":"Fast call to privilege level 0 system procedures."},"SYSENTER":{"_":"sysenter","*":"Fast call to privilege level 0 system procedures."},"SYSEXIT":{"_":"sysexit","*":"Fast return to 64-bit mode privilege level 3 user code."},"SYSRET":{"_":"sysret","*":"Return to 64-bit mode from fast system call"},"TEST":{"_":"test","*":"AND r64 with r/m64; set SF, ZF, PF according to result."},"TPAUSE":{"_":"tpause","*":"Directs the processor to enter an implementation-dependent optimized state until the TSC reaches the value in EDX:EAX."},"TZCNT":{"_":"tzcnt","*":"Count the number of trailing zero bits in r/m64, return result in r64."},"UCOMISD":{"_":"ucomisd","*":"Compare low double-precision floating-point values in xmm1 and xmm2/mem64 and set the EFLAGS flags accordingly."},"VUCOMISD":{"_":"ucomisd","*":"Compare low double-precision floating-point values in xmm1 and xmm2/m64 and set the EFLAGS flags accordingly."},"UCOMISS":{"_":"ucomiss","*":"Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly."},"VUCOMISS":{"_":"ucomiss","*":"Compare low single-precision floating-point values in xmm1 and xmm2/mem32 and set the EFLAGS flags accordingly."},"UD":{"_":"ud","*":"Generates an invalid opcode exception. This instruction is provided for software testing to explicitly generate an invalid opcode exception. The opcodes for this instruction are reserved for this purpose."},"UD1":{"_":"ud","*":"Raise invalid opcode exception."},"UD2":{"_":"ud","*":"Raise invalid opcode exception."},"UD01":{"_":"ud","*":"Raise invalid opcode exception."},"UMONITOR":{"_":"umonitor","*":"Sets up a linear address range to be monitored by hardware and activates the monitor. The address range should be a write-back memory caching type. The address is contained in r16/r32/r64."},"UMWAIT":{"_":"umwait","*":"A hint that allows the processor to stop instruction execution and enter an implementation-dependent optimized state until occurrence of a class of events."},"UNPCKHPD":{"_":"unpckhpd","*":"Unpacks and Interleaves double-precision floating-point values from high quadwords of xmm1 and xmm2/m128."},"VUNPCKHPD":{"_":"unpckhpd","*":"Unpacks and Interleaves double-precision floating-point values from high quadwords of zmm2 and zmm3/m512/m64bcst subject to writemask k1."},"UNPCKHPS":{"_":"unpckhps","*":"Unpacks and Interleaves single-precision floating-point values from high quadwords of xmm1 and xmm2/m128."},"VUNPCKHPS":{"_":"unpckhps","*":"Unpacks and Interleaves single-precision floating-point values from high quadwords of zmm2 and zmm3/m512/m32bcst and write result to zmm1 subject to writemask k1."},"UNPCKLPD":{"_":"unpcklpd","*":"Unpacks and Interleaves double-precision floating-point values from low quadwords of xmm1 and xmm2/m128."},"VUNPCKLPD":{"_":"unpcklpd","*":"Unpacks and Interleaves double-precision floating-point values from low quadwords of zmm2 and zmm3/m512/m64bcst subject to write mask k1."},"UNPCKLPS":{"_":"unpcklps","*":"Unpacks and Interleaves single-precision floating-point values from low quadwords of xmm1 and xmm2/m128."},"VUNPCKLPS":{"_":"unpcklps","*":"Unpacks and Interleaves single-precision floating-point values from low quadwords of zmm2 and zmm3/m512/m32bcst and write result to zmm1 subject to write mask k1."},"V4FMADDPS:V4FNMADDPS":{"_":"v4fmaddps:v4fnmaddps","*":"This instruction computes 4 sequential packed fused single-precision floating-point multiply-add instructions with a sequentially selected memory operand in each of the four steps."},"V4FMADDPS":{"_":"v4fmaddps:v4fnmaddps","*":"Multiply packed single-precision floating-point values from source register block indicated by zmm2 by values from m128 and accumulate the result in zmm1."},"V4FNMADDPS":{"_":"v4fmaddps:v4fnmaddps","*":"Multiply and negate packed single-precision floating-point values from source register block indicated by zmm2 by values from m128 and accumulate the result in zmm1."},"V4FMADDSS:V4FNMADDSS":{"_":"v4fmaddss:v4fnmaddss","*":"This instruction computes 4 sequential scalar fused single-precision floating-point multiply-add instructions with a sequentially selected memory operand in each of the four steps."},"V4FNMADDSS":{"_":"v4fmaddss:v4fnmaddss","*":"Multiply and negate scalar single-precision floating-point values from source register block indicated by xmm2 by values from m128 and accumulate the result in xmm1."},"V4FMADDSS":{"_":"v4fmaddss:v4fnmaddss","*":"Multiply scalar single-precision floating-point values from source register block indicated by xmm2 by values from m128 and accumulate the result in xmm1."},"VALIGND:VALIGNQ":{"_":"valignd:valignq","*":"Concatenates and shifts right doubleword/quadword elements of the first source operand (the second operand) and the second source operand (the third operand) into a 1024/512/256-bit intermediate vector. The low 512/256/128-bit of the intermediate vector is written to the destination operand (the first operand) using the writemask k1. The destination and first source operands are ZMM/YMM/XMM registers. The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit memory location."},"VALIGNQ":{"_":"valignd:valignq","*":"Shift right and merge vectors zmm2 and zmm3/m512/m64bcst with quad-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask."},"VALIGND":{"_":"valignd:valignq","*":"Shift right and merge vectors zmm2 and zmm3/m512/m32bcst with double-word granularity using imm8 as number of elements to shift, and store the final result in zmm1, under writemask."},"VBLENDMPD:VBLENDMPS":{"_":"vblendmpd:vblendmps","*":"Performs an element-by-element blending between float64/float32 elements in the first source operand (the second operand) with the elements in the second source operand (the third operand) using an opmask register as select control. The blended result is written to the destination register."},"VBLENDMPD":{"_":"vblendmpd:vblendmps","*":"Blend double-precision vector zmm2 and double-precision vector zmm3/m512/m64bcst and store the result in zmm1, under control mask."},"VBLENDMPS":{"_":"vblendmpd:vblendmps","*":"Blend single-precision vector zmm2 and single-precision vector zmm3/m512/m32bcst using k1 as select control and store the result in zmm1."},"VBROADCAST":{"_":"vbroadcast","*":"VBROADCASTSD/VBROADCASTSS/VBROADCASTF128 load floating-point values as one tuple from the source operand (second operand) in memory and broadcast to all elements of the destination operand (first operand)."},"VBROADCASTF32X4":{"_":"vbroadcast","*":"Broadcast 128 bits of 4 single-precision floating-point data in mem to locations in zmm1 using writemask k1."},"VBROADCASTF128":{"_":"vbroadcast","*":"Broadcast 128 bits of floating-point data in mem to low and high 128-bits in ymm1."},"VBROADCASTF64X2":{"_":"vbroadcast","*":"Broadcast 128 bits of 2 double-precision floating-point data in mem to locations in zmm1 using writemask k1."},"VBROADCASTF64X4":{"_":"vbroadcast","*":"Broadcast 256 bits of 4 double-precision floating-point data in mem to locations in zmm1 using writemask k1."},"VBROADCASTSD":{"_":"vbroadcast","*":"Broadcast low double-precision floating-point element in xmm2/m64 to eight locations in zmm1 using writemask k1."},"VBROADCASTSS":{"_":"vbroadcast","*":"Broadcast low single-precision floating-point element in xmm2/m32 to all locations in zmm1 using writemask k1."},"VBROADCASTF32X2":{"_":"vbroadcast","*":"Broadcast two single-precision floating-point elements in xmm2/m64 to locations in zmm1 using writemask k1."},"VBROADCASTF32X8":{"_":"vbroadcast","*":"Broadcast 256 bits of 8 single-precision floating-point data in mem to locations in zmm1 using writemask k1."},"VCOMPRESSPD":{"_":"vcompresspd","*":"Compress packed double-precision floating-point values from zmm2 using control mask k1 to zmm1/m512."},"VCOMPRESSPS":{"_":"vcompressps","*":"Compress packed single-precision floating-point values from zmm2 using control mask k1 to zmm1/m512."},"VCVTPD2QQ":{"_":"vcvtpd2qq","*":"Convert eight packed double-precision floating-point values from zmm2/m512/m64bcst to eight packed quadword integers in zmm1 with writemask k1."},"VCVTPD2UDQ":{"_":"vcvtpd2udq","*":"Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight unsigned doubleword integers in ymm1 subject to writemask k1."},"VCVTPD2UQQ":{"_":"vcvtpd2uqq","*":"Convert eight packed double-precision floating-point values from zmm2/mem to eight packed unsigned quadword integers in zmm1 with writemask k1."},"VCVTPH2PS":{"_":"vcvtph2ps","*":"Convert sixteen packed half precision (16-bit) floating-point values in ymm2/m256 to packed single-precision floating-point values in zmm1."},"VCVTPS2PH":{"_":"vcvtps2ph","*":"Convert sixteen packed single-precision floating-point values in zmm2 to packed half-precision (16-bit) floating-point values in ymm1/m256. Imm8 provides rounding controls."},"VCVTPS2QQ":{"_":"vcvtps2qq","*":"Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed quadword values in zmm1 subject to writemask k1."},"VCVTPS2UDQ":{"_":"vcvtps2udq","*":"Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed unsigned doubleword values in zmm1 subject to writemask k1."},"VCVTPS2UQQ":{"_":"vcvtps2uqq","*":"Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned quadword values in zmm1 subject to writemask k1."},"VCVTQQ2PD":{"_":"vcvtqq2pd","*":"Convert eight packed quadword integers from zmm2/m512/m64bcst to eight packed double-precision floating-point values in zmm1 with writemask k1."},"VCVTQQ2PS":{"_":"vcvtqq2ps","*":"Convert eight packed quadword integers from zmm2/mem to eight packed single-precision floating-point values in ymm1 with writemask k1."},"VCVTSD2USI":{"_":"vcvtsd2usi","*":"Convert one double-precision floating-point value from xmm1/m64 to one unsigned quadword integer zero-extended into r64."},"VCVTSS2USI":{"_":"vcvtss2usi","*":"Convert one single-precision floating-point value from xmm1/m32 to one unsigned quadword integer in r64."},"VCVTTPD2QQ":{"_":"vcvttpd2qq","*":"Convert eight packed double-precision floating-point values from zmm2/m512 to eight packed quadword integers in zmm1 using truncation with writemask k1."},"VCVTTPD2UDQ":{"_":"vcvttpd2udq","*":"Convert eight packed double-precision floating-point values in zmm2/m512/m64bcst to eight unsigned doubleword integers in ymm1 using truncation subject to writemask k1."},"VCVTTPD2UQQ":{"_":"vcvttpd2uqq","*":"Convert eight packed double-precision floating-point values from zmm2/mem to eight packed unsigned quadword integers in zmm1 using truncation with writemask k1."},"VCVTTPS2QQ":{"_":"vcvttps2qq","*":"Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed signed quadword values in zmm1 using truncation subject to writemask k1."},"VCVTTPS2UDQ":{"_":"vcvttps2udq","*":"Convert sixteen packed single-precision floating-point values from zmm2/m512/m32bcst to sixteen packed unsigned doubleword values in zmm1 using truncation subject to writemask k1."},"VCVTTPS2UQQ":{"_":"vcvttps2uqq","*":"Convert eight packed single precision floating-point values from ymm2/m256/m32bcst to eight packed unsigned quadword values in zmm1 using truncation subject to writemask k1."},"VCVTTSD2USI":{"_":"vcvttsd2usi","*":"Convert one double-precision floating-point value from xmm1/m64 to one unsigned quadword integer zero-extended into r64 using truncation."},"VCVTTSS2USI":{"_":"vcvttss2usi","*":"Convert one single-precision floating-point value from xmm1/m32 to one unsigned quadword integer in r64 using truncation."},"VCVTUDQ2PD":{"_":"vcvtudq2pd","*":"Convert eight packed unsigned doubleword integers from ymm2/m256/m32bcst to eight packed double-precision floating-point values in zmm1 with writemask k1."},"VCVTUDQ2PS":{"_":"vcvtudq2ps","*":"Convert sixteen packed unsigned doubleword integers from zmm2/m512/m32bcst to sixteen packed single-precision floating-point values in zmm1 with writemask k1."},"VCVTUQQ2PD":{"_":"vcvtuqq2pd","*":"Convert eight packed unsigned quadword integers from zmm2/m512/m64bcst to eight packed double-precision floating-point values in zmm1 with writemask k1."},"VCVTUQQ2PS":{"_":"vcvtuqq2ps","*":"Convert eight packed unsigned quadword integers from zmm2/m512/m64bcst to eight packed single-precision floating-point values in zmm1 with writemask k1."},"VCVTUSI2SD":{"_":"vcvtusi2sd","*":"Convert one unsigned quadword integer from r/m64 to one double-precision floating-point value in xmm1."},"VCVTUSI2SS":{"_":"vcvtusi2ss","*":"Convert one signed quadword integer from r/m64 to one single-precision floating-point value in xmm1."},"VDBPSADBW":{"_":"vdbpsadbw","*":"Compute packed SAD word results of unsigned bytes in dword block from zmm2 with unsigned bytes of dword blocks transformed from zmm3/m512 using the shuffle controls in imm8. Results are written to zmm1 under the writemask k1."},"VERR:VERW":{"_":"verr:verw","*":"Verifies whether the code or data segment specified with the source operand is readable (VERR) or writable (VERW) from the current privilege level (CPL). The source operand is a 16-bit register or a memory location that contains the segment selector for the segment to be verified. If the segment is accessible and readable (VERR) or writable (VERW), the ZF flag is set; otherwise, the ZF flag is cleared. Code segments are never verified as writable. This check cannot be performed on system segments."},"VERR":{"_":"verr:verw","*":"Set ZF=1 if segment specified with r/m16 can be read."},"VERW":{"_":"verr:verw","*":"Set ZF=1 if segment specified with r/m16 can be written."},"VEXP2PD":{"_":"vexp2pd","*":"Computes approximations to the exponential 2^x (with less than 2^-23 of maximum relative error) of the packed double-precision floating-point values from zmm2/m512/m64bcst and stores the floating-point result in zmm1with writemask k1."},"VEXP2PS":{"_":"vexp2ps","*":"Computes approximations to the exponential 2^x (with less than 2^-23 of maximum relative error) of the packed single-precision floating-point values from zmm2/m512/m32bcst and stores the floating-point result in zmm1with writemask k1."},"VEXPANDPD":{"_":"vexpandpd","*":"Expand packed double-precision floating-point values from zmm2/m512 to zmm1 using writemask k1."},"VEXPANDPS":{"_":"vexpandps","*":"Expand packed single-precision floating-point values from zmm2/m512 to zmm1 using writemask k1."},"VEXTRACTF128:VEXTRACTF32X4:VEXTRACTF64X2:VEXTRACTF32X8:VEXTRACTF64X4":{"_":"vextractf128:vextractf32x4:vextractf64x2:vextractf32x8:vextractf64x4","*":"VEXTRACTF128/VEXTRACTF32x4 and VEXTRACTF64x2 extract 128-bits of single-precision floating-point values from the source operand (the second operand) and store to the low 128-bit of the destination operand (the first operand). The 128-bit data extraction occurs at an 128-bit granular offset specified by imm8[0] (256-bit) or imm8[1:0] as the multiply factor. The destination may be either a vector register or an 128-bit memory location."},"VEXTRACTF128":{"_":"vextractf128:vextractf32x4:vextractf64x2:vextractf32x8:vextractf64x4","*":"Extract 128 bits of packed floating-point values from ymm2 and store results in xmm1/m128."},"VEXTRACTF32X4":{"_":"vextractf128:vextractf32x4:vextractf64x2:vextractf32x8:vextractf64x4","*":"Extract 128 bits of packed single-precision floating-point values from ymm2 and store results in xmm1/m128 subject to writemask k1."},"VEXTRACTF32X8":{"_":"vextractf128:vextractf32x4:vextractf64x2:vextractf32x8:vextractf64x4","*":"Extract 256 bits of packed single-precision floating-point values from zmm2 and store results in ymm1/m256 subject to writemask k1."},"VEXTRACTF64X2":{"_":"vextractf128:vextractf32x4:vextractf64x2:vextractf32x8:vextractf64x4","*":"Extract 128 bits of packed double-precision floating-point values from zmm2 and store results in xmm1/m128 subject to writemask k1."},"VEXTRACTI128:VEXTRACTI32X4:VEXTRACTI64X2:VEXTRACTI32X8:VEXTRACTI64X4":{"_":"vextracti128:vextracti32x4:vextracti64x2:vextracti32x8:vextracti64x4","*":"VEXTRACTI128/VEXTRACTI32x4 and VEXTRACTI64x2 extract 128-bits of doubleword integer values from the source operand (the second operand) and store to the low 128-bit of the destination operand (the first operand). The 128-bit data extraction occurs at an 128-bit granular offset specified by imm8[0] (256-bit) or imm8[1:0] as the multiply factor. The destination may be either a vector register or an 128-bit memory location."},"VEXTRACTI64X2":{"_":"vextracti128:vextracti32x4:vextracti64x2:vextracti32x8:vextracti64x4","*":"Extract 128 bits of quad-word integer values from zmm2 and store results in xmm1/m128 subject to writemask k1."},"VEXTRACTI32X4":{"_":"vextracti128:vextracti32x4:vextracti64x2:vextracti32x8:vextracti64x4","*":"Extract 128 bits of double-word integer values from ymm2 and store results in xmm1/m128 subject to writemask k1."},"VEXTRACTI128":{"_":"vextracti128:vextracti32x4:vextracti64x2:vextracti32x8:vextracti64x4","*":"Extract 128 bits of integer data from ymm2 and store results in xmm1/m128."},"VEXTRACTI32X8":{"_":"vextracti128:vextracti32x4:vextracti64x2:vextracti32x8:vextracti64x4","*":"Extract 256 bits of double-word integer values from zmm2 and store results in ymm1/m256 subject to writemask k1."},"VFIXUPIMMPD":{"_":"vfixupimmpd","*":"Fix up elements of float64 vector in zmm2 using int64 vector table in zmm3/m512/m64bcst, combine with preserved elements from zmm1, and store the result in zmm1."},"VFIXUPIMMPS":{"_":"vfixupimmps","*":"Fix up elements of float32 vector in zmm2 using int32 vector table in zmm3/m512/m32bcst, combine with preserved elements from zmm1, and store the result in zmm1."},"VFIXUPIMMSD":{"_":"vfixupimmsd","*":"Fix up a float64 number in the low quadword element of xmm2 using scalar int32 table in xmm3/m64 and store the result in xmm1."},"VFIXUPIMMSS":{"_":"vfixupimmss","*":"Fix up a float32 number in the low doubleword element in xmm2 using scalar int32 table in xmm3/m32 and store the result in xmm1."},"VFMADD132PD:VFMADD213PD:VFMADD231PD":{"_":"vfmadd132pd:vfmadd213pd:vfmadd231pd","*":"Performs a set of SIMD multiply-add computation on packed double-precision floating-point values using three source operands and writes the multiply-add results in the destination operand. The destination operand is also the first source operand. The second operand must be a SIMD register. The third source operand can be a SIMD register or a memory location."},"VFMADD231PD":{"_":"vfmadd132pd:vfmadd213pd:vfmadd231pd","*":"Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, add to zmm1 and put result in zmm1."},"VFMADD213PD":{"_":"vfmadd132pd:vfmadd213pd:vfmadd231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m64bcst and put result in zmm1."},"VFMADD132PD":{"_":"vfmadd132pd:vfmadd213pd:vfmadd231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, add to zmm2 and put result in zmm1."},"VFMADD132PS:VFMADD213PS:VFMADD231PS":{"_":"vfmadd132ps:vfmadd213ps:vfmadd231ps","*":"Performs a set of SIMD multiply-add computation on packed single-precision floating-point values using three source operands and writes the multiply-add results in the destination operand. The destination operand is also the first source operand. The second operand must be a SIMD register. The third source operand can be a SIMD register or a memory location."},"VFMADD231PS":{"_":"vfmadd132ps:vfmadd213ps:vfmadd231ps","*":"Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add to zmm1 and put result in zmm1."},"VFMADD132PS":{"_":"vfmadd132ps:vfmadd213ps:vfmadd231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add to zmm2 and put result in zmm1."},"VFMADD213PS":{"_":"vfmadd132ps:vfmadd213ps:vfmadd231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm2, add to zmm3/m512/m32bcst and put result in zmm1."},"VFMADD132SD:VFMADD213SD:VFMADD231SD":{"_":"vfmadd132sd:vfmadd213sd:vfmadd231sd","*":"Performs a SIMD multiply-add computation on the low double-precision floating-point values using three source operands and writes the multiply-add result in the destination operand. The destination operand is also the first source operand. The first and second operand are XMM registers. The third source operand can be an XMM register or a 64-bit memory location."},"VFMADD213SD":{"_":"vfmadd132sd:vfmadd213sd:vfmadd231sd","*":"Multiply scalar double-precision floating-point value from xmm1 and xmm2, add to xmm3/m64 and put result in xmm1."},"VFMADD231SD":{"_":"vfmadd132sd:vfmadd213sd:vfmadd231sd","*":"Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, add to xmm1 and put result in xmm1."},"VFMADD132SD":{"_":"vfmadd132sd:vfmadd213sd:vfmadd231sd","*":"Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, add to xmm2 and put result in xmm1."},"VFMADD132SS:VFMADD213SS:VFMADD231SS":{"_":"vfmadd132ss:vfmadd213ss:vfmadd231ss","*":"Performs a SIMD multiply-add computation on single-precision floating-point values using three source operands and writes the multiply-add results in the destination operand. The destination operand is also the first source operand. The first and second operands are XMM registers. The third source operand can be a XMM register or a 32-bit memory location."},"VFMADD213SS":{"_":"vfmadd132ss:vfmadd213ss:vfmadd231ss","*":"Multiply scalar single-precision floating-point value from xmm1 and xmm2, add to xmm3/m32 and put result in xmm1."},"VFMADD231SS":{"_":"vfmadd132ss:vfmadd213ss:vfmadd231ss","*":"Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, add to xmm1 and put result in xmm1."},"VFMADD132SS":{"_":"vfmadd132ss:vfmadd213ss:vfmadd231ss","*":"Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, add to xmm2 and put result in xmm1."},"VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD":{"_":"vfmaddsub132pd:vfmaddsub213pd:vfmaddsub231pd","*":"VFMADDSUB132PD: Multiplies the two, four, or eight packed double-precision floating-point values from the first source operand to the two or four packed double-precision floating-point values in the third source operand. From the infinite precision intermediate result, adds the odd double-precision floating-point elements and subtracts the even double-precision floating-point values in the second source operand, performs rounding and stores the resulting two or four packed double-precision floating-point values to the destination operand (first source operand)."},"VFMADDSUB132PD":{"_":"vfmaddsub132pd:vfmaddsub213pd:vfmaddsub231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1."},"VFMADDSUB213PD":{"_":"vfmaddsub132pd:vfmaddsub213pd:vfmaddsub231pd","*":"Multiply packed double-precision floating-point values from zmm1and zmm2, add/subtract elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1."},"VFMADDSUB231PD":{"_":"vfmaddsub132pd:vfmaddsub213pd:vfmaddsub231pd","*":"Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1."},"VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS":{"_":"vfmaddsub132ps:vfmaddsub213ps:vfmaddsub231ps","*":"VFMADDSUB132PS: Multiplies the four, eight or sixteen packed single-precision floating-point values from the first source operand to the corresponding packed single-precision floating-point values in the third source operand. From the infinite precision intermediate result, adds the odd single-precision floating-point elements and subtracts the even single-precision floating-point values in the second source operand, performs rounding and stores the resulting packed single-precision floating-point values to the destination operand (first source operand)."},"VFMADDSUB213PS":{"_":"vfmaddsub132ps:vfmaddsub213ps:vfmaddsub231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm2, add/subtract elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1."},"VFMADDSUB132PS":{"_":"vfmaddsub132ps:vfmaddsub213ps:vfmaddsub231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, add/subtract elements in zmm2 and put result in zmm1 subject to writemask k1."},"VFMADDSUB231PS":{"_":"vfmaddsub132ps:vfmaddsub213ps:vfmaddsub231ps","*":"Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, add/subtract elements in zmm1 and put result in zmm1 subject to writemask k1."},"VFMSUB132PD:VFMSUB213PD:VFMSUB231PD":{"_":"vfmsub132pd:vfmsub213pd:vfmsub231pd","*":"Performs a set of SIMD multiply-subtract computation on packed double-precision floating-point values using three source operands and writes the multiply-subtract results in the destination operand. The destination operand is also the first source operand. The second operand must be a SIMD register. The third source operand can be a SIMD register or a memory location."},"VFMSUB213PD":{"_":"vfmsub132pd:vfmsub213pd:vfmsub231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1."},"VFMSUB132PD":{"_":"vfmsub132pd:vfmsub213pd:vfmsub231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, subtract zmm2 and put result in zmm1 subject to writemask k1."},"VFMSUB231PD":{"_":"vfmsub132pd:vfmsub213pd:vfmsub231pd","*":"Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, subtract zmm1 and put result in zmm1 subject to writemask k1."},"VFMSUB132PS:VFMSUB213PS:VFMSUB231PS":{"_":"vfmsub132ps:vfmsub213ps:vfmsub231ps","*":"Performs a set of SIMD multiply-subtract computation on packed single-precision floating-point values using three source operands and writes the multiply-subtract results in the destination operand. The destination operand is also the first source operand. The second operand must be a SIMD register. The third source operand can be a SIMD register or a memory location."},"VFMSUB132PS":{"_":"vfmsub132ps:vfmsub213ps:vfmsub231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract zmm2 and put result in zmm1."},"VFMSUB213PS":{"_":"vfmsub132ps:vfmsub213ps:vfmsub231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract zmm3/m512/m32bcst and put result in zmm1."},"VFMSUB231PS":{"_":"vfmsub132ps:vfmsub213ps:vfmsub231ps","*":"Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract zmm1 and put result in zmm1."},"VFMSUB132SD:VFMSUB213SD:VFMSUB231SD":{"_":"vfmsub132sd:vfmsub213sd:vfmsub231sd","*":"Performs a SIMD multiply-subtract computation on the low packed double-precision floating-point values using three source operands and writes the multiply-subtract result in the destination operand. The destination operand is also the first source operand. The second operand must be a XMM register. The third source operand can be a XMM register or a 64-bit memory location."},"VFMSUB231SD":{"_":"vfmsub132sd:vfmsub213sd:vfmsub231sd","*":"Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, subtract xmm1 and put result in xmm1."},"VFMSUB213SD":{"_":"vfmsub132sd:vfmsub213sd:vfmsub231sd","*":"Multiply scalar double-precision floating-point value from xmm1 and xmm2, subtract xmm3/m64 and put result in xmm1."},"VFMSUB132SD":{"_":"vfmsub132sd:vfmsub213sd:vfmsub231sd","*":"Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, subtract xmm2 and put result in xmm1."},"VFMSUB132SS:VFMSUB213SS:VFMSUB231SS":{"_":"vfmsub132ss:vfmsub213ss:vfmsub231ss","*":"Performs a SIMD multiply-subtract computation on the low packed single-precision floating-point values using three source operands and writes the multiply-subtract result in the destination operand. The destination operand is also the first source operand. The second operand must be a XMM register. The third source operand can be a XMM register or a 32-bit memory location."},"VFMSUB132SS":{"_":"vfmsub132ss:vfmsub213ss:vfmsub231ss","*":"Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, subtract xmm2 and put result in xmm1."},"VFMSUB231SS":{"_":"vfmsub132ss:vfmsub213ss:vfmsub231ss","*":"Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, subtract xmm1 and put result in xmm1."},"VFMSUB213SS":{"_":"vfmsub132ss:vfmsub213ss:vfmsub231ss","*":"Multiply scalar single-precision floating-point value from xmm1 and xmm2, subtract xmm3/m32 and put result in xmm1."},"VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD":{"_":"vfmsubadd132pd:vfmsubadd213pd:vfmsubadd231pd","*":"VFMSUBADD132PD: Multiplies the two, four, or eight packed double-precision floating-point values from the first source operand to the two or four packed double-precision floating-point values in the third source operand. From the infinite precision intermediate result, subtracts the odd double-precision floating-point elements and adds the even double-precision floating-point values in the second source operand, performs rounding and stores the resulting two or four packed double-precision floating-point values to the destination operand (first source operand)."},"VFMSUBADD132PD":{"_":"vfmsubadd132pd:vfmsubadd213pd:vfmsubadd231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1."},"VFMSUBADD231PD":{"_":"vfmsubadd132pd:vfmsubadd213pd:vfmsubadd231pd","*":"Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1."},"VFMSUBADD213PD":{"_":"vfmsubadd132pd:vfmsubadd213pd:vfmsubadd231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm2, subtract/add elements in zmm3/m512/m64bcst and put result in zmm1 subject to writemask k1."},"VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS":{"_":"vfmsubadd132ps:vfmsubadd213ps:vfmsubadd231ps","*":"VFMSUBADD132PS: Multiplies the four, eight or sixteen packed single-precision floating-point values from the first source operand to the corresponding packed single-precision floating-point values in the third source operand. From the infinite precision intermediate result, subtracts the odd single-precision floating-point elements and adds the even single-precision floating-point values in the second source operand, performs rounding and stores the resulting packed single-precision floating-point values to the destination operand (first source operand)."},"VFMSUBADD231PS":{"_":"vfmsubadd132ps:vfmsubadd213ps:vfmsubadd231ps","*":"Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, subtract/add elements in zmm1 and put result in zmm1 subject to writemask k1."},"VFMSUBADD213PS":{"_":"vfmsubadd132ps:vfmsubadd213ps:vfmsubadd231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm2, subtract/add elements in zmm3/m512/m32bcst and put result in zmm1 subject to writemask k1."},"VFMSUBADD132PS":{"_":"vfmsubadd132ps:vfmsubadd213ps:vfmsubadd231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, subtract/add elements in zmm2 and put result in zmm1 subject to writemask k1."},"VFNMADD132PD:VFNMADD213PD:VFNMADD231PD":{"_":"vfnmadd132pd:vfnmadd213pd:vfnmadd231pd","*":"VFNMADD132PD: Multiplies the two, four or eight packed double-precision floating-point values from the first source operand to the two, four or eight packed double-precision floating-point values in the third source operand, adds the negated infinite precision intermediate result to the two, four or eight packed double-precision floating-point values in the second source operand, performs rounding and stores the resulting two, four or eight packed double-precision floating-point values to the destination operand (first source operand)."},"VFNMADD213PD":{"_":"vfnmadd132pd:vfnmadd213pd:vfnmadd231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m64bcst and put result in zmm1."},"VFNMADD132PD":{"_":"vfnmadd132pd:vfnmadd213pd:vfnmadd231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm2 and put result in zmm1."},"VFNMADD231PD":{"_":"vfnmadd132pd:vfnmadd213pd:vfnmadd231pd","*":"Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and add to zmm1 and put result in zmm1."},"VFNMADD132PS:VFNMADD213PS:VFNMADD231PS":{"_":"vfnmadd132ps:vfnmadd213ps:vfnmadd231ps","*":"VFNMADD132PS: Multiplies the four, eight or sixteen packed single-precision floating-point values from the first source operand to the four, eight or sixteen packed single-precision floating-point values in the third source operand, adds the negated infinite precision intermediate result to the four, eight or sixteen packed single-precision floating-point values in the second source operand, performs rounding and stores the resulting four, eight or sixteen packed single-precision floating-point values to the destination operand (first source operand)."},"VFNMADD231PS":{"_":"vfnmadd132ps:vfnmadd213ps:vfnmadd231ps","*":"Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm1 and put result in zmm1."},"VFNMADD132PS":{"_":"vfnmadd132ps:vfnmadd213ps:vfnmadd231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and add to zmm2 and put result in zmm1."},"VFNMADD213PS":{"_":"vfnmadd132ps:vfnmadd213ps:vfnmadd231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and add to zmm3/m512/m32bcst and put result in zmm1."},"VFNMADD132SD:VFNMADD213SD:VFNMADD231SD":{"_":"vfnmadd132sd:vfnmadd213sd:vfnmadd231sd","*":"VFNMADD132SD: Multiplies the low packed double-precision floating-point value from the first source operand to the low packed double-precision floating-point value in the third source operand, adds the negated infinite precision intermediate result to the low packed double-precision floating-point values in the second source operand, performs rounding and stores the resulting packed double-precision floating-point value to the destination operand (first source operand)."},"VFNMADD132SD":{"_":"vfnmadd132sd:vfnmadd213sd:vfnmadd231sd","*":"Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and add to xmm2 and put result in xmm1."},"VFNMADD231SD":{"_":"vfnmadd132sd:vfnmadd213sd:vfnmadd231sd","*":"Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and add to xmm1 and put result in xmm1."},"VFNMADD213SD":{"_":"vfnmadd132sd:vfnmadd213sd:vfnmadd231sd","*":"Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m64 and put result in xmm1."},"VFNMADD132SS:VFNMADD213SS:VFNMADD231SS":{"_":"vfnmadd132ss:vfnmadd213ss:vfnmadd231ss","*":"VFNMADD132SS: Multiplies the low packed single-precision floating-point value from the first source operand to the low packed single-precision floating-point value in the third source operand, adds the negated infinite precision intermediate result to the low packed single-precision floating-point value in the second source operand, performs rounding and stores the resulting packed single-precision floating-point value to the destination operand (first source operand)."},"VFNMADD213SS":{"_":"vfnmadd132ss:vfnmadd213ss:vfnmadd231ss","*":"Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and add to xmm3/m32 and put result in xmm1."},"VFNMADD132SS":{"_":"vfnmadd132ss:vfnmadd213ss:vfnmadd231ss","*":"Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and add to xmm2 and put result in xmm1."},"VFNMADD231SS":{"_":"vfnmadd132ss:vfnmadd213ss:vfnmadd231ss","*":"Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and add to xmm1 and put result in xmm1."},"VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD":{"_":"vfnmsub132pd:vfnmsub213pd:vfnmsub231pd","*":"VFNMSUB132PD: Multiplies the two, four or eight packed double-precision floating-point values from the first source operand to the two, four or eight packed double-precision floating-point values in the third source operand. From negated infinite precision intermediate results, subtracts the two, four or eight packed double-precision floating-point values in the second source operand, performs rounding and stores the resulting two, four or eight packed double-precision floating-point values to the destination operand (first source operand)."},"VFNMSUB213PD":{"_":"vfnmsub132pd:vfnmsub213pd:vfnmsub231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m64bcst and put result in zmm1."},"VFNMSUB132PD":{"_":"vfnmsub132pd:vfnmsub213pd:vfnmsub231pd","*":"Multiply packed double-precision floating-point values from zmm1 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm2 and put result in zmm1."},"VFNMSUB231PD":{"_":"vfnmsub132pd:vfnmsub213pd:vfnmsub231pd","*":"Multiply packed double-precision floating-point values from zmm2 and zmm3/m512/m64bcst, negate the multiplication result and subtract zmm1 and put result in zmm1."},"VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS":{"_":"vfnmsub132ps:vfnmsub213ps:vfnmsub231ps","*":"VFNMSUB132PS: Multiplies the four, eight or sixteen packed single-precision floating-point values from the first source operand to the four, eight or sixteen packed single-precision floating-point values in the third source operand. From negated infinite precision intermediate results, subtracts the four, eight or sixteen packed single-precision floating-point values in the second source operand, performs rounding and stores the resulting four, eight or sixteen packed single-precision floating-point values to the destination operand (first source operand)."},"VFNMSUB231PS":{"_":"vfnmsub132ps:vfnmsub213ps:vfnmsub231ps","*":"Multiply packed single-precision floating-point values from zmm2 and zmm3/m512/m32bcst, negate the multiplication result subtract add to zmm1 and put result in zmm1."},"VFNMSUB132PS":{"_":"vfnmsub132ps:vfnmsub213ps:vfnmsub231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm3/m512/m32bcst, negate the multiplication result and subtract zmm2 and put result in zmm1."},"VFNMSUB213PS":{"_":"vfnmsub132ps:vfnmsub213ps:vfnmsub231ps","*":"Multiply packed single-precision floating-point values from zmm1 and zmm2, negate the multiplication result and subtract zmm3/m512/m32bcst and put result in zmm1."},"VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD":{"_":"vfnmsub132sd:vfnmsub213sd:vfnmsub231sd","*":"VFNMSUB132SD: Multiplies the low packed double-precision floating-point value from the first source operand to the low packed double-precision floating-point value in the third source operand. From negated infinite precision intermediate result, subtracts the low double-precision floating-point value in the second source operand, performs rounding and stores the resulting packed double-precision floating-point value to the destination operand (first source operand)."},"VFNMSUB231SD":{"_":"vfnmsub132sd:vfnmsub213sd:vfnmsub231sd","*":"Multiply scalar double-precision floating-point value from xmm2 and xmm3/m64, negate the multiplication result and subtract xmm1 and put result in xmm1."},"VFNMSUB213SD":{"_":"vfnmsub132sd:vfnmsub213sd:vfnmsub231sd","*":"Multiply scalar double-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m64 and put result in xmm1."},"VFNMSUB132SD":{"_":"vfnmsub132sd:vfnmsub213sd:vfnmsub231sd","*":"Multiply scalar double-precision floating-point value from xmm1 and xmm3/m64, negate the multiplication result and subtract xmm2 and put result in xmm1."},"VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS":{"_":"vfnmsub132ss:vfnmsub213ss:vfnmsub231ss","*":"VFNMSUB132SS: Multiplies the low packed single-precision floating-point value from the first source operand to the low packed single-precision floating-point value in the third source operand. From negated infinite precision intermediate result, the low single-precision floating-point value in the second source operand, performs rounding and stores the resulting packed single-precision floating-point value to the destination operand (first source operand)."},"VFNMSUB132SS":{"_":"vfnmsub132ss:vfnmsub213ss:vfnmsub231ss","*":"Multiply scalar single-precision floating-point value from xmm1 and xmm3/m32, negate the multiplication result and subtract xmm2 and put result in xmm1."},"VFNMSUB231SS":{"_":"vfnmsub132ss:vfnmsub213ss:vfnmsub231ss","*":"Multiply scalar single-precision floating-point value from xmm2 and xmm3/m32, negate the multiplication result and subtract xmm1 and put result in xmm1."},"VFNMSUB213SS":{"_":"vfnmsub132ss:vfnmsub213ss:vfnmsub231ss","*":"Multiply scalar single-precision floating-point value from xmm1 and xmm2, negate the multiplication result and subtract xmm3/m32 and put result in xmm1."},"VFPCLASSPD":{"_":"vfpclasspd","*":"Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."},"VFPCLASSPS":{"_":"vfpclassps","*":"Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."},"VFPCLASSSD":{"_":"vfpclasssd","*":"Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."},"VFPCLASSSS":{"_":"vfpclassss","*":"Tests the input for the following categories: NaN, +0, -0, +Infinity, -Infinity, denormal, finite negative. The immediate field provides a mask bit for each of these category tests. The masked test results are OR-ed together to form a mask result."},"VGATHERDPD:VGATHERQPD":{"_":"vgatherdpd:vgatherqpd","*":"The instruction conditionally loads up to 2 or 4 double-precision floating-point values from memory addresses specified by the memory operand (the second operand) and using qword indices. The memory operand uses the VSIB form of the SIB byte to specify a general purpose register operand as the common base, a vector register for an array of indices relative to the base and a constant scale factor."},"VGATHERDPD":{"_":"vgatherdpd:vgatherqpd","*":"Using dword indices specified in vm32x, gather double-precision FP values from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1."},"VGATHERQPD":{"_":"vgatherdpd:vgatherqpd","*":"Using qword indices specified in vm64y, gather double-precision FP values from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1."},"VGATHERDPS:VGATHERQPS":{"_":"vgatherdps:vgatherqps","*":"The instruction conditionally loads up to 4 or 8 single-precision floating-point values from memory addresses specified by the memory operand (the second operand) and using dword indices. The memory operand uses the VSIB form of the SIB byte to specify a general purpose register operand as the common base, a vector register for an array of indices relative to the base and a constant scale factor."},"VGATHERDPS":{"_":"vgatherdps:vgatherqps","*":"Using dword indices specified in vm32y, gather single-precision FP values from memory conditioned on mask specified by ymm2. Conditionally gathered elements are merged into ymm1."},"VGATHERQPS":{"_":"vgatherdps:vgatherqps","*":"Using qword indices specified in vm64y, gather single-precision FP values from memory conditioned on mask specified by xmm2. Conditionally gathered elements are merged into xmm1."},"VGATHERPF0DPS:VGATHERPF0QPS:VGATHERPF0DPD:VGATHERPF0QPD":{"_":"vgatherpf0dps:vgatherpf0qps:vgatherpf0dpd:vgatherpf0qpd","*":"The instruction conditionally prefetches up to sixteen 32-bit or eight 64-bit integer byte data elements. The elements are specified via the VSIB (i.e., the index register is an zmm, holding packed indices). Elements will only be prefetched if their corresponding mask bit is one."},"VGATHERPF0QPD":{"_":"vgatherpf0dps:vgatherpf0qps:vgatherpf0dpd:vgatherpf0qpd","*":"Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint."},"VGATHERPF0DPD":{"_":"vgatherpf0dps:vgatherpf0qps:vgatherpf0dpd:vgatherpf0qpd","*":"Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T0 hint."},"VGATHERPF0QPS":{"_":"vgatherpf0dps:vgatherpf0qps:vgatherpf0dpd:vgatherpf0qpd","*":"Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint."},"VGATHERPF0DPS":{"_":"vgatherpf0dps:vgatherpf0qps:vgatherpf0dpd:vgatherpf0qpd","*":"Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T0 hint."},"VGATHERPF1DPS:VGATHERPF1QPS:VGATHERPF1DPD:VGATHERPF1QPD":{"_":"vgatherpf1dps:vgatherpf1qps:vgatherpf1dpd:vgatherpf1qpd","*":"The instruction conditionally prefetches up to sixteen 32-bit or eight 64-bit integer byte data elements. The elements are specified via the VSIB (i.e., the index register is an zmm, holding packed indices). Elements will only be prefetched if their corresponding mask bit is one."},"VGATHERPF1DPD":{"_":"vgatherpf1dps:vgatherpf1qps:vgatherpf1dpd:vgatherpf1qpd","*":"Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint."},"VGATHERPF1QPS":{"_":"vgatherpf1dps:vgatherpf1qps:vgatherpf1dpd:vgatherpf1qpd","*":"Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint."},"VGATHERPF1DPS":{"_":"vgatherpf1dps:vgatherpf1qps:vgatherpf1dpd:vgatherpf1qpd","*":"Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using opmask k1 and T1 hint."},"VGATHERPF1QPD":{"_":"vgatherpf1dps:vgatherpf1qps:vgatherpf1dpd:vgatherpf1qpd","*":"Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using opmask k1 and T1 hint."},"VGETEXPPD":{"_":"vgetexppd","*":"Convert the exponent of packed double-precision floating-point values in the source operand to DP FP results representing unbiased integer exponents and stores the results in the destination under writemask k1."},"VGETEXPPS":{"_":"vgetexpps","*":"Convert the exponent of packed single-precision floating-point values in the source operand to SP FP results representing unbiased integer exponents and stores the results in the destination register."},"VGETEXPSD":{"_":"vgetexpsd","*":"Convert the biased exponent (bits 62:52) of the low double-precision floating-point value in xmm3/m64 to a DP FP value representing unbiased integer exponent. Stores the result to the low 64-bit of xmm1 under the writemask k1 and merge with the other elements of xmm2."},"VGETEXPSS":{"_":"vgetexpss","*":"Convert the biased exponent (bits 30:23) of the low single-precision floating-point value in xmm3/m32 to a SP FP value representing unbiased integer exponent. Stores the result to xmm1 under the writemask k1 and merge with the other elements of xmm2."},"VGETMANTPD":{"_":"vgetmantpd","*":"Get Normalized Mantissa from float64 vector zmm2/m512/m64bcst and store the result in zmm1, using imm8 for sign control and mantissa interval normalization, under writemask."},"VGETMANTPS":{"_":"vgetmantps","*":"Get normalized mantissa from float32 vector zmm2/m512/m32bcst and store the result in zmm1, using imm8 for sign control and mantissa interval normalization, under writemask."},"VGETMANTSD":{"_":"vgetmantsd","*":"Extract the normalized mantissa of the low float64 element in xmm3/m64 using imm8 for sign control and mantissa interval normalization. Store the mantissa to xmm1 under the writemask k1 and merge with the other elements of xmm2."},"VGETMANTSS":{"_":"vgetmantss","*":"Extract the normalized mantissa from the low float32 element of xmm3/m32 using imm8 for sign control and mantissa interval normalization, store the mantissa to xmm1 under the writemask k1 and merge with the other elements of xmm2."},"VINSERTF128:VINSERTF32X4:VINSERTF64X2:VINSERTF32X8:VINSERTF64X4":{"_":"vinsertf128:vinsertf32x4:vinsertf64x2:vinsertf32x8:vinsertf64x4","*":"VINSERTF128/VINSERTF32x4 and VINSERTF64x2 insert 128-bits of packed floating-point values from the second source operand (the third operand) into the destination operand (the first operand) at an 128-bit granularity offset multiplied by imm8[0] (256-bit) or imm8[1:0]. The remaining portions of the destination operand are copied from the corresponding fields of the first source operand (the second operand). The second source operand can be either an XMM register or a 128-bit memory location. The destination and first source operands are vector registers."},"VINSERTF64X2":{"_":"vinsertf128:vinsertf32x4:vinsertf64x2:vinsertf32x8:vinsertf64x4","*":"Insert 128 bits of packed double-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1."},"VINSERTF32X4":{"_":"vinsertf128:vinsertf32x4:vinsertf64x2:vinsertf32x8:vinsertf64x4","*":"Insert 128 bits of packed single-precision floating-point values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1."},"VINSERTF128":{"_":"vinsertf128:vinsertf32x4:vinsertf64x2:vinsertf32x8:vinsertf64x4","*":"Insert 128 bits of packed floating-point values from xmm3/m128 and the remaining values from ymm2 into ymm1."},"VINSERTF64X4":{"_":"vinsertf128:vinsertf32x4:vinsertf64x2:vinsertf32x8:vinsertf64x4","*":"Insert 256 bits of packed double-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1."},"VINSERTF32X8":{"_":"vinsertf128:vinsertf32x4:vinsertf64x2:vinsertf32x8:vinsertf64x4","*":"Insert 256 bits of packed single-precision floating-point values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1."},"VINSERTI128:VINSERTI32X4:VINSERTI64X2:VINSERTI32X8:VINSERTI64X4":{"_":"vinserti128:vinserti32x4:vinserti64x2:vinserti32x8:vinserti64x4","*":"VINSERTI32x4 and VINSERTI64x2 inserts 128-bits of packed integer values from the second source operand (the third operand) into the destination operand (the first operand) at an 128-bit granular offset multiplied by imm8[0] (256-bit) or imm8[1:0]. The remaining portions of the destination are copied from the corresponding fields of the first source operand (the second operand). The second source operand can be either an XMM register or a 128-bit memory location. The high 6/7bits of the immediate are ignored. The destination operand is a ZMM/YMM register and updated at 32 and 64-bit granularity according to the writemask."},"VINSERTI128":{"_":"vinserti128:vinserti32x4:vinserti64x2:vinserti32x8:vinserti64x4","*":"Insert 128 bits of integer data from xmm3/m128 and the remaining values from ymm2 into ymm1."},"VINSERTI64X4":{"_":"vinserti128:vinserti32x4:vinserti64x2:vinserti32x8:vinserti64x4","*":"Insert 256 bits of packed quadword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1."},"VINSERTI32X8":{"_":"vinserti128:vinserti32x4:vinserti64x2:vinserti32x8:vinserti64x4","*":"Insert 256 bits of packed doubleword integer values from ymm3/m256 and the remaining values from zmm2 into zmm1 under writemask k1."},"VINSERTI64X2":{"_":"vinserti128:vinserti32x4:vinserti64x2:vinserti32x8:vinserti64x4","*":"Insert 128 bits of packed quadword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1."},"VINSERTI32X4":{"_":"vinserti128:vinserti32x4:vinserti64x2:vinserti32x8:vinserti64x4","*":"Insert 128 bits of packed doubleword integer values from xmm3/m128 and the remaining values from zmm2 into zmm1 under writemask k1."},"VMASKMOV":{"_":"vmaskmov","*":"Conditionally moves packed data elements from the second source operand into the corresponding data element of the destination operand, depending on the mask bits associated with each data element. The mask bits are specified in the first source operand."},"VMASKMOVPD":{"_":"vmaskmov","*":"Conditionally store packed double-precision values from ymm2 using mask in ymm1."},"VMASKMOVPS":{"_":"vmaskmov","*":"Conditionally store packed single-precision values from ymm2 using mask in ymm1."},"VP4DPWSSD":{"_":"vp4dpwssd","*":"Multiply signed words from source register block indicated by zmm2 by signed words from m128 and accumulate resulting signed dwords in zmm1."},"VP4DPWSSDS":{"_":"vp4dpwssds","*":"Multiply signed words from source register block indicated by zmm2 by signed words from m128 and accumulate the resulting dword results with signed saturation in zmm1."},"VPBLENDD":{"_":"vpblendd","*":"Select dwords from ymm2 and ymm3/m256 from mask specified in imm8 and store the values into ymm1."},"VPBLENDMB:VPBLENDMW":{"_":"vpblendmb:vpblendmw","*":"Performs an element-by-element blending of byte/word elements between the first source operand byte vector register and the second source operand byte vector from memory or register, using the instruction mask as selector. The result is written into the destination byte vector register."},"VPBLENDMB":{"_":"vpblendmb:vpblendmw","*":"Blend byte integer vector zmm2 and byte vector zmm3/m512 and store the result in zmm1, under control mask."},"VPBLENDMW":{"_":"vpblendmb:vpblendmw","*":"Blend word integer vector zmm2 and word vector zmm3/m512 and store the result in zmm1, under control mask."},"VPBLENDMD:VPBLENDMQ":{"_":"vpblendmd:vpblendmq","*":"Performs an element-by-element blending of dword/qword elements between the first source operand (the second operand) and the elements of the second source operand (the third operand) using an opmask register as select control. The blended result is written into the destination."},"VPBLENDMD":{"_":"vpblendmd:vpblendmq","*":"Blend doubleword integer vector zmm2 and doubleword vector zmm3/m512/m32bcst and store the result in zmm1, under control mask."},"VPBLENDMQ":{"_":"vpblendmd:vpblendmq","*":"Blend quadword integer vector zmm2 and quadword vector zmm3/m512/m64bcst and store the result in zmm1, under control mask."},"VPBROADCAST":{"_":"vpbroadcast","*":"Load integer data from the source operand (the second operand) and broadcast to all elements of the destination operand (the first operand)."},"VBROADCASTI128":{"_":"vpbroadcast","*":"Broadcast 128 bits of integer data in mem to low and high 128-bits in ymm1."},"VPBROADCASTQ":{"_":"vpbroadcast","*":"Broadcast a qword element in source operand to locations in zmm1 subject to writemask k1."},"VPBROADCASTB":{"_":"vpbroadcast","*":"Broadcast a byte integer in the source operand to 64 locations in zmm1 subject to writemask k1."},"VBROADCASTI64X2":{"_":"vpbroadcast","*":"Broadcast 128 bits of 2 quadword integer data in mem to locations in zmm1 using writemask k1."},"VBROADCASTI64X4":{"_":"vpbroadcast","*":"Broadcast 256 bits of 4 quadword integer data in mem to locations in zmm1 using writemask k1."},"VPBROADCASTW":{"_":"vpbroadcast","*":"Broadcast a word integer in the source operand to 32 locations in zmm1 subject to writemask k1."},"VPBROADCASTD":{"_":"vpbroadcast","*":"Broadcast a dword integer in the source operand to locations in zmm1 subject to writemask k1."},"VBROADCASTI32X8":{"_":"vpbroadcast","*":"Broadcast 256 bits of 8 doubleword integer data in mem to locations in zmm1 using writemask k1."},"VBROADCASTI32X4":{"_":"vpbroadcast","*":"Broadcast 128 bits of 4 doubleword integer data in mem to locations in zmm1 using writemask k1."},"VPBROADCASTM":{"_":"vpbroadcastm","*":"Broadcasts the zero-extended 64/32 bit value of the low byte/word of the source operand (the second operand) to each 64/32 bit element of the destination operand (the first operand). The source operand is an opmask register. The destination operand is a ZMM register (EVEX.512), YMM register (EVEX.256), or XMM register (EVEX.128)."},"VPBROADCASTMW2D":{"_":"vpbroadcastm","*":"Broadcast low word value in k1 to sixteen locations in zmm1."},"VPBROADCASTMB2Q":{"_":"vpbroadcastm","*":"Broadcast low byte value in k1 to eight locations in zmm1."},"VPCMPB:VPCMPUB":{"_":"vpcmpb:vpcmpub","*":"Performs a SIMD compare of the packed byte values in the second source operand and the first source operand and returns the results of the comparison to the mask destination operand. The comparison predicate operand (immediate byte) specifies the type of comparison performed on each pair of packed values in the two source operands. The result of each comparison is a single mask bit result of 1 (comparison true) or 0 (comparison false)."},"VPCMPUB":{"_":"vpcmpb:vpcmpub","*":"Compare packed unsigned byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1."},"VPCMPB":{"_":"vpcmpb:vpcmpub","*":"Compare packed signed byte values in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1."},"VPCMPD:VPCMPUD":{"_":"vpcmpd:vpcmpud","*":"Performs a SIMD compare of the packed integer values in the second source operand and the first source operand and returns the results of the comparison to the mask destination operand. The comparison predicate operand (immediate byte) specifies the type of comparison performed on each pair of packed values in the two source operands. The result of each comparison is a single mask bit result of 1 (comparison true) or 0 (comparison false)."},"VPCMPUD":{"_":"vpcmpd:vpcmpud","*":"Compare packed unsigned doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2."},"VPCMPD":{"_":"vpcmpd:vpcmpud","*":"Compare packed signed doubleword integer values in zmm2 and zmm3/m512/m32bcst using bits 2:0 of imm8 as a comparison predicate. The comparison results are written to the destination k1 under writemask k2."},"VPCMPQ:VPCMPUQ":{"_":"vpcmpq:vpcmpuq","*":"Performs a SIMD compare of the packed integer values in the second source operand and the first source operand and returns the results of the comparison to the mask destination operand. The comparison predicate operand (immediate byte) specifies the type of comparison performed on each pair of packed values in the two source operands. The result of each comparison is a single mask bit result of 1 (comparison true) or 0 (comparison false)."},"VPCMPUQ":{"_":"vpcmpq:vpcmpuq","*":"Compare packed unsigned quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1."},"VPCMPQ":{"_":"vpcmpq:vpcmpuq","*":"Compare packed signed quadword integer values in zmm3/m512/m64bcst and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1."},"VPCMPW:VPCMPUW":{"_":"vpcmpw:vpcmpuw","*":"Performs a SIMD compare of the packed integer word in the second source operand and the first source operand and returns the results of the comparison to the mask destination operand. The comparison predicate operand (immediate byte) specifies the type of comparison performed on each pair of packed values in the two source operands. The result of each comparison is a single mask bit result of 1 (comparison true) or 0 (comparison false)."},"VPCMPUW":{"_":"vpcmpw:vpcmpuw","*":"Compare packed unsigned word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1."},"VPCMPW":{"_":"vpcmpw:vpcmpuw","*":"Compare packed signed word integers in zmm3/m512 and zmm2 using bits 2:0 of imm8 as a comparison predicate with writemask k2 and leave the result in mask register k1."},"VPCOMPRESSD":{"_":"vpcompressd","*":"Compress packed doubleword integer values from zmm2 to zmm1/m512 using controlmask k1."},"VPCOMPRESSQ":{"_":"vpcompressq","*":"Compress packed quadword integer values from zmm2 to zmm1/m512 using controlmask k1."},"VPCONFLICTD:VPCONFLICTQ":{"_":"vpconflictd:vpconflictq","*":"Test each dword/qword element of the source operand (the second operand) for equality with all other elements in the source operand closer to the least significant element. Each element’s comparison results form a bit vector, which is then zero extended and written to the destination according to the writemask."},"VPCONFLICTQ":{"_":"vpconflictd:vpconflictq","*":"Detect duplicate quad-word values in zmm2/m512/m64bcst using writemask k1."},"VPCONFLICTD":{"_":"vpconflictd:vpconflictq","*":"Detect duplicate double-word values in zmm2/m512/m32bcst using writemask k1."},"VPERM2F128":{"_":"vperm2f128","*":"Permute 128-bit floating-point fields in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1."},"VPERM2I128":{"_":"vperm2i128","*":"Permute 128-bit integer data in ymm2 and ymm3/mem using controls from imm8 and store result in ymm1."},"VPERMB":{"_":"vpermb","*":"Permute bytes in zmm3/m512 using byte indexes in zmm2 and store the result in zmm1 using writemask k1."},"VPERMD:VPERMW":{"_":"vpermd:vpermw","*":"Copies doublewords (or words) from the second source operand (the third operand) to the destination operand (the first operand) according to the indices in the first source operand (the second operand). Note that this instruction permits a doubleword (word) in the source operand to be copied to more than one location in the destination operand."},"VPERMW":{"_":"vpermd:vpermw","*":"Permute word integers in zmm3/m512 using indexes in zmm2 and store the result in zmm1 using writemask k1."},"VPERMD":{"_":"vpermd:vpermw","*":"Permute doublewords in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 using writemask k1."},"VPERMI2B":{"_":"vpermi2b","*":"Permute bytes in zmm3/m512 and zmm2 using byte indexes in zmm1 and store the byte results in zmm1 using writemask k1."},"VPERMI2W:VPERMI2D:VPERMI2Q:VPERMI2PS:VPERMI2PD":{"_":"vpermi2w:vpermi2d:vpermi2q:vpermi2ps:vpermi2pd","*":"Permutes 16-bit/32-bit/64-bit values in the second operand (the first source operand) and the third operand (the second source operand) using indices in the first operand to select elements from the second and third operands. The selected elements are written to the destination operand (the first operand) according to the writemask k1."},"VPERMI2D":{"_":"vpermi2w:vpermi2d:vpermi2q:vpermi2ps:vpermi2pd","*":"Permute double-words from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1."},"VPERMI2W":{"_":"vpermi2w:vpermi2d:vpermi2q:vpermi2ps:vpermi2pd","*":"Permute word integers from two tables in zmm3/m512 and zmm2 using indexes in zmm1 and store the result in zmm1 using writemask k1."},"VPERMI2PD":{"_":"vpermi2w:vpermi2d:vpermi2q:vpermi2ps:vpermi2pd","*":"Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1."},"VPERMI2PS":{"_":"vpermi2w:vpermi2d:vpermi2q:vpermi2ps:vpermi2pd","*":"Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1."},"VPERMI2Q":{"_":"vpermi2w:vpermi2d:vpermi2q:vpermi2ps:vpermi2pd","*":"Permute quad-words from two tables in zmm3/m512/m64bcst and zmm2 using indices in zmm1 and store the result in zmm1 using writemask k1."},"VPERMILPD":{"_":"vpermilpd","*":"Permute double-precision floating-point values in zmm2/m512/m64bcst using controls from imm8 and store the result in zmm1 using writemask k1."},"VPERMILPS":{"_":"vpermilps","*":"Permute single-precision floating-point values ymm2/m256/m32bcst using controls from imm8 and store the result in ymm1 using writemask k1."},"VPERMPD":{"_":"vpermpd","*":"Permute double-precision floating-point elements in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1 subject to writemask k1."},"VPERMPS":{"_":"vpermps","*":"Permute single-precision floating-point values in zmm3/m512/m32bcst using indices in zmm2 and store the result in zmm1 subject to write mask k1."},"VPERMQ":{"_":"vpermq","*":"Permute qwords in zmm3/m512/m64bcst using indices in zmm2 and store the result in zmm1."},"VPERMT2B":{"_":"vpermt2b","*":"Permute bytes in zmm3/m512 and zmm1 using byte indexes in zmm2 and store the byte results in zmm1 using writemask k1."},"VPERMT2W:VPERMT2D:VPERMT2Q:VPERMT2PS:VPERMT2PD":{"_":"vpermt2w:vpermt2d:vpermt2q:vpermt2ps:vpermt2pd","*":"Permutes 16-bit/32-bit/64-bit values in the first operand and the third operand (the second source operand) using indices in the second operand (the first source operand) to select elements from the first and third operands. The selected elements are written to the destination operand (the first operand) according to the writemask k1."},"VPERMT2PS":{"_":"vpermt2w:vpermt2d:vpermt2q:vpermt2ps:vpermt2pd","*":"Permute single-precision FP values from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1."},"VPERMT2D":{"_":"vpermt2w:vpermt2d:vpermt2q:vpermt2ps:vpermt2pd","*":"Permute double-words from two tables in zmm3/m512/m32bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1."},"VPERMT2W":{"_":"vpermt2w:vpermt2d:vpermt2q:vpermt2ps:vpermt2pd","*":"Permute word integers from two tables in zmm3/m512 and zmm1 using indexes in zmm2 and store the result in zmm1 using writemask k1."},"VPERMT2PD":{"_":"vpermt2w:vpermt2d:vpermt2q:vpermt2ps:vpermt2pd","*":"Permute double-precision FP values from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1."},"VPERMT2Q":{"_":"vpermt2w:vpermt2d:vpermt2q:vpermt2ps:vpermt2pd","*":"Permute quad-words from two tables in zmm3/m512/m64bcst and zmm1 using indices in zmm2 and store the result in zmm1 using writemask k1."},"VPEXPANDD":{"_":"vpexpandd","*":"Expand packed double-word integer values from zmm2/m512 to zmm1 using writemask k1."},"VPEXPANDQ":{"_":"vpexpandq","*":"Expand packed quad-word integer values from zmm2/m512 to zmm1 using writemask k1."},"VPGATHERDD:VPGATHERDQ":{"_":"vpgatherdd:vpgatherdq","*":"A set of 16 or 8 doubleword/quadword memory locations pointed to by base address BASE_ADDR and index vector VINDEX with scale SCALE are gathered. The result is written into vector zmm1. The elements are specified via the VSIB (i.e., the index register is a zmm, holding packed indices). Elements will only be loaded if their corresponding mask bit is one. If an element’s mask bit is not set, the corresponding element of the destination register (zmm1) is left unchanged. The entire mask register will be set to zero by this instruction unless it triggers an exception."},"VPGATHERDD":{"_":"vpgatherdd:vpgatherdq","*":"Using signed dword indices, gather dword values from memory using writemask k1 for merging-masking."},"VPGATHERDQ":{"_":"vpgatherdd:vpgatherdq","*":"Using signed dword indices, gather quadword values from memory using writemask k1 for merging-masking."},"VPGATHERQD:VPGATHERQQ":{"_":"vpgatherqd:vpgatherqq","*":"A set of 8 doubleword/quadword memory locations pointed to by base address BASE_ADDR and index vector VINDEX with scale SCALE are gathered. The result is written into a vector register. The elements are specified via the VSIB (i.e., the index register is a vector register, holding packed indices). Elements will only be loaded if their corresponding mask bit is one. If an element’s mask bit is not set, the corresponding element of the destination register is left unchanged. The entire mask register will be set to zero by this instruction unless it triggers an exception."},"VPGATHERQQ":{"_":"vpgatherqd:vpgatherqq","*":"Using signed qword indices, gather quadword values from memory using writemask k1 for merging-masking."},"VPGATHERQD":{"_":"vpgatherqd:vpgatherqq","*":"Using signed qword indices, gather dword values from memory using writemask k1 for merging-masking."},"VPLZCNTD:VPLZCNTQ":{"_":"vplzcntd:vplzcntq","*":"Counts the number of leading most significant zero bits in each dword or qword element of the source operand (the second operand) and stores the results in the destination register (the first operand) according to the writemask. If an element is zero, the result for that element is the operand size of the element."},"VPLZCNTD":{"_":"vplzcntd:vplzcntq","*":"Count the number of leading zero bits in each dword element of zmm2/m512/m32bcst using writemask k1."},"VPLZCNTQ":{"_":"vplzcntd:vplzcntq","*":"Count the number of leading zero bits in each qword element of zmm2/m512/m64bcst using writemask k1."},"VPMADD52HUQ":{"_":"vpmadd52huq","*":"Multiply unsigned 52-bit integers in zmm2 and zmm3/m128 and add the high 52 bits of the 104-bit product to the qword unsigned integers in zmm1 using writemask k1."},"VPMADD52LUQ":{"_":"vpmadd52luq","*":"Multiply unsigned 52-bit integers in zmm2 and zmm3/m128 and add the low 52 bits of the 104-bit product to the qword unsigned integers in zmm1 using writemask k1."},"VPMASKMOV":{"_":"vpmaskmov","*":"Conditionally moves packed data elements from the second source operand into the corresponding data element of the destination operand, depending on the mask bits associated with each data element. The mask bits are specified in the first source operand."},"VPMASKMOVD":{"_":"vpmaskmov","*":"Conditionally store dword values from ymm2 using mask in ymm1."},"VPMASKMOVQ":{"_":"vpmaskmov","*":"Conditionally store qword values from ymm2 using mask in ymm1."},"VPMOVB2M:VPMOVW2M:VPMOVD2M:VPMOVQ2M":{"_":"vpmovb2m:vpmovw2m:vpmovd2m:vpmovq2m","*":"Converts a vector register to a mask register. Each element in the destination register is set to 1 or 0 depending on the value of most significant bit of the corresponding element in the source register."},"VPMOVQ2M":{"_":"vpmovb2m:vpmovw2m:vpmovd2m:vpmovq2m","*":"Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding quadword in ZMM1."},"VPMOVD2M":{"_":"vpmovb2m:vpmovw2m:vpmovd2m:vpmovq2m","*":"Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding doubleword in ZMM1."},"VPMOVB2M":{"_":"vpmovb2m:vpmovw2m:vpmovd2m:vpmovq2m","*":"Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding byte in ZMM1."},"VPMOVW2M":{"_":"vpmovb2m:vpmovw2m:vpmovd2m:vpmovq2m","*":"Sets each bit in k1 to 1 or 0 based on the value of the most significant bit of the corresponding word in ZMM1."},"VPMOVDB:VPMOVSDB:VPMOVUSDB":{"_":"vpmovdb:vpmovsdb:vpmovusdb","*":"VPMOVDB down converts 32-bit integer elements in the source operand (the second operand) into packed bytes using truncation. VPMOVSDB converts signed 32-bit integers into packed signed bytes using signed saturation. VPMOVUSDB convert unsigned double-word values into unsigned byte values using unsigned saturation."},"VPMOVUSDB":{"_":"vpmovdb:vpmovsdb:vpmovusdb","*":"Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned byte integers in xmm1/m128 using unsigned saturation under writemask k1."},"VPMOVDB":{"_":"vpmovdb:vpmovsdb:vpmovusdb","*":"Converts 16 packed double-word integers from zmm2 into 16 packed byte integers in xmm1/m128 with truncation under writemask k1."},"VPMOVSDB":{"_":"vpmovdb:vpmovsdb:vpmovusdb","*":"Converts 16 packed signed double-word integers from zmm2 into 16 packed signed byte integers in xmm1/m128 using signed saturation under writemask k1."},"VPMOVDW:VPMOVSDW:VPMOVUSDW":{"_":"vpmovdw:vpmovsdw:vpmovusdw","*":"VPMOVDW down converts 32-bit integer elements in the source operand (the second operand) into packed words using truncation. VPMOVSDW converts signed 32-bit integers into packed signed words using signed saturation. VPMOVUSDW convert unsigned double-word values into unsigned word values using unsigned saturation."},"VPMOVDW":{"_":"vpmovdw:vpmovsdw:vpmovusdw","*":"Converts 16 packed double-word integers from zmm2 into 16 packed word integers in ymm1/m256 with truncation under writemask k1."},"VPMOVSDW":{"_":"vpmovdw:vpmovsdw:vpmovusdw","*":"Converts 16 packed signed double-word integers from zmm2 into 16 packed signed word integers in ymm1/m256 using signed saturation under writemask k1."},"VPMOVUSDW":{"_":"vpmovdw:vpmovsdw:vpmovusdw","*":"Converts 16 packed unsigned double-word integers from zmm2 into 16 packed unsigned word integers in ymm1/m256 using unsigned saturation under writemask k1."},"VPMOVM2B:VPMOVM2W:VPMOVM2D:VPMOVM2Q":{"_":"vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q","*":"Converts a mask register to a vector register. Each element in the destination register is set to all 1’s or all 0’s depending on the value of the corresponding bit in the source mask register."},"VPMOVM2B":{"_":"vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q","*":"Sets each byte in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1."},"VPMOVM2D":{"_":"vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q","*":"Sets each doubleword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1."},"VPMOVM2Q":{"_":"vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q","*":"Sets each quadword in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1."},"VPMOVM2W":{"_":"vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q","*":"Sets each word in ZMM1 to all 1’s or all 0’s based on the value of the corresponding bit in k1."},"VPMOVQB:VPMOVSQB:VPMOVUSQB":{"_":"vpmovqb:vpmovsqb:vpmovusqb","*":"VPMOVQB down converts 64-bit integer elements in the source operand (the second operand) into packed byte elements using truncation. VPMOVSQB converts signed 64-bit integers into packed signed bytes using signed saturation. VPMOVUSQB convert unsigned quad-word values into unsigned byte values using unsigned saturation. The source operand is a vector register. The destination operand is an XMM register or a memory location."},"VPMOVSQB":{"_":"vpmovqb:vpmovsqb:vpmovusqb","*":"Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed byte integers in xmm1/m64 using signed saturation under writemask k1."},"VPMOVUSQB":{"_":"vpmovqb:vpmovsqb:vpmovusqb","*":"Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned byte integers in xmm1/m64 using unsigned saturation under writemask k1."},"VPMOVQB":{"_":"vpmovqb:vpmovsqb:vpmovusqb","*":"Converts 8 packed quad-word integers from zmm2 into 8 packed byte integers in xmm1/m64 with truncation under writemask k1."},"VPMOVQD:VPMOVSQD:VPMOVUSQD":{"_":"vpmovqd:vpmovsqd:vpmovusqd","*":"VPMOVQW down converts 64-bit integer elements in the source operand (the second operand) into packed double-words using truncation. VPMOVSQW converts signed 64-bit integers into packed signed doublewords using signed saturation. VPMOVUSQW convert unsigned quad-word values into unsigned double-word values using unsigned saturation."},"VPMOVQD":{"_":"vpmovqd:vpmovsqd:vpmovusqd","*":"Converts 8 packed quad-word integers from zmm2 into 8 packed double-word integers in ymm1/m256 with truncation subject to writemask k1."},"VPMOVSQD":{"_":"vpmovqd:vpmovsqd:vpmovusqd","*":"Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed double-word integers in ymm1/m256 using signed saturation subject to writemask k1."},"VPMOVUSQD":{"_":"vpmovqd:vpmovsqd:vpmovusqd","*":"Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned double-word integers in ymm1/m256 using unsigned saturation subject to writemask k1."},"VPMOVQW:VPMOVSQW:VPMOVUSQW":{"_":"vpmovqw:vpmovsqw:vpmovusqw","*":"VPMOVQW down converts 64-bit integer elements in the source operand (the second operand) into packed words using truncation. VPMOVSQW converts signed 64-bit integers into packed signed words using signed saturation. VPMOVUSQW convert unsigned quad-word values into unsigned word values using unsigned saturation."},"VPMOVUSQW":{"_":"vpmovqw:vpmovsqw:vpmovusqw","*":"Converts 8 packed unsigned quad-word integers from zmm2 into 8 packed unsigned word integers in xmm1/m128 using unsigned saturation under writemask k1."},"VPMOVSQW":{"_":"vpmovqw:vpmovsqw:vpmovusqw","*":"Converts 8 packed signed quad-word integers from zmm2 into 8 packed signed word integers in xmm1/m128 using signed saturation under writemask k1."},"VPMOVQW":{"_":"vpmovqw:vpmovsqw:vpmovusqw","*":"Converts 8 packed quad-word integers from zmm2 into 8 packed word integers in xmm1/m128 with truncation under writemask k1."},"VPMOVWB:VPMOVSWB:VPMOVUSWB":{"_":"vpmovwb:vpmovswb:vpmovuswb","*":"VPMOVWB down converts 16-bit integers into packed bytes using truncation. VPMOVSWB converts signed 16-bit integers into packed signed bytes using signed saturation. VPMOVUSWB convert unsigned word values into unsigned byte values using unsigned saturation."},"VPMOVSWB":{"_":"vpmovwb:vpmovswb:vpmovuswb","*":"Converts 32 packed signed word integers from zmm2 into 32 packed signed bytes in ymm1/m256 using signed saturation under writemask k1."},"VPMOVWB":{"_":"vpmovwb:vpmovswb:vpmovuswb","*":"Converts 32 packed word integers from zmm2 into 32 packed bytes in ymm1/m256 with truncation under writemask k1."},"VPMOVUSWB":{"_":"vpmovwb:vpmovswb:vpmovuswb","*":"Converts 32 packed unsigned word integers from zmm2 into 32 packed unsigned bytes in ymm1/m256 using unsigned saturation under writemask k1."},"VPMULTISHIFTQB":{"_":"vpmultishiftqb","*":"Select unaligned bytes from qwords in zmm3/m512/m64bcst using control bytes in zmm2, write byte results to zmm1 under k1."},"VPROLD:VPROLVD:VPROLQ:VPROLVQ":{"_":"vprold:vprolvd:vprolq:vprolvq","*":"Rotates the bits in the individual data elements (doublewords, or quadword) in the first source operand to the left by the number of bits specified in the count operand. If the value specified by the count operand is greater than 31 (for doublewords), or 63 (for a quadword), then the count operand modulo the data size (32 or 64) is used."},"VPROLVD":{"_":"vprold:vprolvd:vprolq:vprolvq","*":"Rotate left of doublewords in zmm2 by count in the corresponding element of zmm3/m512/m32bcst. Result written to zmm1 using writemask k1."},"VPROLVQ":{"_":"vprold:vprolvd:vprolq:vprolvq","*":"Rotate quadwords in zmm2 left by count in the corresponding element of zmm3/m512/m64bcst. Result written to zmm1under writemask k1."},"VPROLD":{"_":"vprold:vprolvd:vprolq:vprolvq","*":"Rotate left of doublewords in zmm3/m512/m32bcst by imm8. Result written to zmm1 using writemask k1."},"VPROLQ":{"_":"vprold:vprolvd:vprolq:vprolvq","*":"Rotate quadwords in zmm2/m512/m64bcst left by imm8. Result written to zmm1 using writemask k1."},"VPRORD:VPRORVD:VPRORQ:VPRORVQ":{"_":"vprord:vprorvd:vprorq:vprorvq","*":"Rotates the bits in the individual data elements (doublewords, or quadword) in the first source operand to the right by the number of bits specified in the count operand. If the value specified by the count operand is greater than 31 (for doublewords), or 63 (for a quadword), then the count operand modulo the data size (32 or 64) is used."},"VPRORD":{"_":"vprord:vprorvd:vprorq:vprorvq","*":"Rotate doublewords in zmm2/m512/m32bcst right by imm8, store result using writemask k1."},"VPRORQ":{"_":"vprord:vprorvd:vprorq:vprorvq","*":"Rotate quadwords in zmm2/m512/m64bcst right by imm8, store result using writemask k1."},"VPRORVQ":{"_":"vprord:vprorvd:vprorq:vprorvq","*":"Rotate quadwords in zmm2 right by count in the corresponding element of zmm3/m512/m64bcst, store result using writemask k1."},"VPRORVD":{"_":"vprord:vprorvd:vprorq:vprorvq","*":"Rotate doublewords in zmm2 right by count in the corresponding element of zmm3/m512/m32bcst, store result using writemask k1."},"VPSCATTERDD:VPSCATTERDQ:VPSCATTERQD:VPSCATTERQQ":{"_":"vpscatterdd:vpscatterdq:vpscatterqd:vpscatterqq","*":"Stores up to 16 elements (8 elements for qword indices) in doubleword vector or 8 elements in quadword vector to the memory locations pointed by base address BASE_ADDR and index vector VINDEX, with scale SCALE. The elements are specified via the VSIB (i.e., the index register is a vector register, holding packed indices). Elements will only be stored if their corresponding mask bit is one. The entire mask register will be set to zero by this instruction unless it triggers an exception."},"VPSCATTERDD":{"_":"vpscatterdd:vpscatterdq:vpscatterqd:vpscatterqq","*":"Using signed dword indices, scatter dword values to memory using writemask k1."},"VPSCATTERDQ":{"_":"vpscatterdd:vpscatterdq:vpscatterqd:vpscatterqq","*":"Using signed dword indices, scatter qword values to memory using writemask k1."},"VPSCATTERQQ":{"_":"vpscatterdd:vpscatterdq:vpscatterqd:vpscatterqq","*":"Using signed qword indices, scatter qword values to memory using writemask k1."},"VPSCATTERQD":{"_":"vpscatterdd:vpscatterdq:vpscatterqd:vpscatterqq","*":"Using signed qword indices, scatter dword values to memory using writemask k1."},"VPSLLVW:VPSLLVD:VPSLLVQ":{"_":"vpsllvw:vpsllvd:vpsllvq","*":"Shifts the bits in the individual data elements (words, doublewords or quadword) in the first source operand to the left by the count value of respective data elements in the second source operand. As the bits in the data elements are shifted left, the empty low-order bits are cleared (set to 0)."},"VPSLLVW":{"_":"vpsllvw:vpsllvd:vpsllvq","*":"Shift words in zmm2 left by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1."},"VPSLLVD":{"_":"vpsllvw:vpsllvd:vpsllvq","*":"Shift doublewords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1."},"VPSLLVQ":{"_":"vpsllvw:vpsllvd:vpsllvq","*":"Shift quadwords in zmm2 left by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1."},"VPSRAVW:VPSRAVD:VPSRAVQ":{"_":"vpsravw:vpsravd:vpsravq","*":"Shifts the bits in the individual data elements (word/doublewords/quadword) in the first source operand (the second operand) to the right by the number of bits specified in the count value of respective data elements in the second source operand (the third operand). As the bits in the data elements are shifted right, the empty high-order bits are set to the MSB (sign extension)."},"VPSRAVW":{"_":"vpsravw:vpsravd:vpsravq","*":"Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in sign bits using writemask k1."},"VPSRAVQ":{"_":"vpsravw:vpsravd:vpsravq","*":"Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in sign bits using writemask k1."},"VPSRAVD":{"_":"vpsravw:vpsravd:vpsravq","*":"Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in sign bits using writemask k1."},"VPSRLVW:VPSRLVD:VPSRLVQ":{"_":"vpsrlvw:vpsrlvd:vpsrlvq","*":"Shifts the bits in the individual data elements (words, doublewords or quadword) in the first source operand to the right by the count value of respective data elements in the second source operand. As the bits in the data elements are shifted right, the empty high-order bits are cleared (set to 0)."},"VPSRLVD":{"_":"vpsrlvw:vpsrlvd:vpsrlvq","*":"Shift doublewords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m32bcst while shifting in 0s using writemask k1."},"VPSRLVQ":{"_":"vpsrlvw:vpsrlvd:vpsrlvq","*":"Shift quadwords in zmm2 right by amount specified in the corresponding element of zmm3/m512/m64bcst while shifting in 0s using writemask k1."},"VPSRLVW":{"_":"vpsrlvw:vpsrlvd:vpsrlvq","*":"Shift words in zmm2 right by amount specified in the corresponding element of zmm3/m512 while shifting in 0s using writemask k1."},"VPTERNLOGD:VPTERNLOGQ":{"_":"vpternlogd:vpternlogq","*":"VPTERNLOGD/Q takes three bit vectors of 512-bit length (in the first, second and third operand) as input data to form a set of 512 indices, each index is comprised of one bit from each input vector. The imm8 byte specifies a boolean logic table producing a binary value for each 3-bit index value. The final 512-bit boolean result is written to the destination operand (the first operand) using the writemask k1 with the granularity of doubleword element or quadword element into the destination."},"VPTERNLOGD":{"_":"vpternlogd:vpternlogq","*":"Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m32bcst as source operands and writing the result to zmm1 under writemask k1 with dword granularity. The immediate value determines the specific binary function being implemented."},"VPTERNLOGQ":{"_":"vpternlogd:vpternlogq","*":"Bitwise ternary logic taking zmm1, zmm2 and zmm3/m512/m64bcst as source operands and writing the result to zmm1 under writemask k1 with qword granularity. The immediate value determines the specific binary function being implemented."},"VPTESTMB:VPTESTMW:VPTESTMD:VPTESTMQ":{"_":"vptestmb:vptestmw:vptestmd:vptestmq","*":"Performs a bitwise logical AND operation on the first source operand (the second operand) and second source operand (the third operand) and stores the result in the destination operand (the first operand) under the writemask. Each bit of the result is set to 1 if the bitwise AND of the corresponding elements of the first and second src operands is non-zero; otherwise it is set to 0."},"VPTESTMQ":{"_":"vptestmb:vptestmw:vptestmd:vptestmq","*":"Bitwise AND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1."},"VPTESTMD":{"_":"vptestmb:vptestmw:vptestmd:vptestmq","*":"Bitwise AND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1."},"VPTESTMW":{"_":"vptestmb:vptestmw:vptestmd:vptestmq","*":"Bitwise AND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1."},"VPTESTMB":{"_":"vptestmb:vptestmw:vptestmd:vptestmq","*":"Bitwise AND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1."},"VPTESTNMB:VPTESTNMW:VPTESTNMD:VPTESTNMQ":{"_":"vptestnmb:vptestnmw:vptestnmd:vptestnmq","*":"Performs a bitwise logical NAND operation on the byte/word/doubleword/quadword element of the first source operand (the second operand) with the corresponding element of the second source operand (the third operand) and stores the logical comparison result into each bit of the destination operand (the first operand) according to the writemask k1. Each bit of the result is set to 1 if the bitwise AND of the corresponding elements of the first and second src operands is zero; otherwise it is set to 0."},"VPTESTNMQ":{"_":"vptestnmb:vptestnmw:vptestnmd:vptestnmq","*":"Bitwise NAND of packed quadword integers in zmm2 and zmm3/m512/m64bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1."},"VPTESTNMW":{"_":"vptestnmb:vptestnmw:vptestnmd:vptestnmq","*":"Bitwise NAND of packed word integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1."},"VPTESTNMD":{"_":"vptestnmb:vptestnmw:vptestnmd:vptestnmq","*":"Bitwise NAND of packed doubleword integers in zmm2 and zmm3/m512/m32bcst and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1."},"VPTESTNMB":{"_":"vptestnmb:vptestnmw:vptestnmd:vptestnmq","*":"Bitwise NAND of packed byte integers in zmm2 and zmm3/m512 and set mask k2 to reflect the zero/non-zero status of each element of the result, under writemask k1."},"VRANGEPD":{"_":"vrangepd","*":"Calculate eight RANGE operation output value from 8 pairs of double-precision floating-point values in zmm2 and zmm3/m512/m32bcst, store the results to zmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation."},"VRANGEPS":{"_":"vrangeps","*":"Calculate 16 RANGE operation output value from 16 pairs of single-precision floating-point values in zmm2 and zmm3/m512/m32bcst, store the results to zmm1 under the writemask k1. Imm8 specifies the comparison and sign of the range operation."},"VRANGESD":{"_":"vrangesd","*":"Calculate a RANGE operation output value from 2 double-precision floating-point values in xmm2 and xmm3/m64, store the output to xmm1 under writemask. Imm8 specifies the comparison and sign of the range operation."},"VRANGESS":{"_":"vrangess","*":"Calculate a RANGE operation output value from 2 single-precision floating-point values in xmm2 and xmm3/m32, store the output to xmm1 under writemask. Imm8 specifies the comparison and sign of the range operation."},"VRCP14PD":{"_":"vrcp14pd","*":"Computes the approximate reciprocals of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the results in zmm1. Under writemask."},"VRCP14PS":{"_":"vrcp14ps","*":"Computes the approximate reciprocals of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the results in zmm1. Under writemask."},"VRCP14SD":{"_":"vrcp14sd","*":"Computes the approximate reciprocal of the scalar double-precision floating-point value in xmm3/m64 and stores the result in xmm1 using writemask k1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64]."},"VRCP14SS":{"_":"vrcp14ss","*":"Computes the approximate reciprocal of the scalar single-precision floating-point value in xmm3/m32 and stores the results in xmm1 using writemask k1. Also, upper double-precision floating-point value (bits[127:32]) from xmm2 is copied to xmm1[127:32]."},"VRCP28PD":{"_":"vrcp28pd","*":"Computes the approximate reciprocals ( < 2^-28 relative error) of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the results in zmm1. Under writemask."},"VRCP28PS":{"_":"vrcp28ps","*":"Computes the approximate reciprocals ( < 2^-28 relative error) of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the results in zmm1. Under writemask."},"VRCP28SD":{"_":"vrcp28sd","*":"Computes the approximate reciprocal ( < 2^-28 relative error) of the scalar double-precision floating-point value in xmm3/m64 and stores the results in xmm1. Under writemask. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64]."},"VRCP28SS":{"_":"vrcp28ss","*":"Computes the approximate reciprocal ( < 2^-28 relative error) of the scalar single-precision floating-point value in xmm3/m32 and stores the results in xmm1. Under writemask. Also, upper 3 single-precision floating-point values (bits[127:32]) from xmm2 is copied to xmm1[127:32]."},"VREDUCEPD":{"_":"vreducepd","*":"Perform reduction transformation on double-precision floating point values in zmm2/m512/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register under writemask k1."},"VREDUCEPS":{"_":"vreduceps","*":"Perform reduction transformation on packed single-precision floating point values in zmm2/m512/m32bcst by subtracting a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register under writemask k1."},"VREDUCESD":{"_":"vreducesd","*":"Perform a reduction transformation on a scalar double-precision floating point value in xmm3/m64 by subtracting a number of fraction bits specified by the imm8 field. Also, upper double precision floating-point value (bits[127:64]) from xmm2 are copied to xmm1[127:64]. Stores the result in xmm1 register."},"VREDUCESS":{"_":"vreducess","*":"Perform a reduction transformation on a scalar single-precision floating point value in xmm3/m32 by subtracting a number of fraction bits specified by the imm8 field. Also, upper single precision floating-point values (bits[127:32]) from xmm2 are copied to xmm1[127:32]. Stores the result in xmm1 register."},"VRNDSCALEPD":{"_":"vrndscalepd","*":"Rounds packed double-precision floating-point values in zmm2/m512/m64bcst to a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register using writemask k1."},"VRNDSCALEPS":{"_":"vrndscaleps","*":"Rounds packed single-precision floating-point values in zmm2/m512/m32bcst to a number of fraction bits specified by the imm8 field. Stores the result in zmm1 register using writemask."},"VRNDSCALESD":{"_":"vrndscalesd","*":"Rounds scalar double-precision floating-point value in xmm3/m64 to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register."},"VRNDSCALESS":{"_":"vrndscaless","*":"Rounds scalar single-precision floating-point value in xmm3/m32 to a number of fraction bits specified by the imm8 field. Stores the result in xmm1 register under writemask."},"VRSQRT14PD":{"_":"vrsqrt14pd","*":"Computes the approximate reciprocal square roots of the packed double-precision floating-point values in zmm2/m512/m64bcst and stores the results in zmm1 under writemask."},"VRSQRT14PS":{"_":"vrsqrt14ps","*":"Computes the approximate reciprocal square roots of the packed single-precision floating-point values in zmm2/m512/m32bcst and stores the results in zmm1. Under writemask."},"VRSQRT14SD":{"_":"vrsqrt14sd","*":"Computes the approximate reciprocal square root of the scalar double-precision floating-point value in xmm3/m64 and stores the result in the low quadword element of xmm1 using writemask k1. Bits[127:64] of xmm2 is copied to xmm1[127:64]."},"VRSQRT14SS":{"_":"vrsqrt14ss","*":"Computes the approximate reciprocal square root of the scalar single-precision floating-point value in xmm3/m32 and stores the result in the low doubleword element of xmm1 using writemask k1. Bits[127:32] of xmm2 is copied to xmm1[127:32]."},"VRSQRT28PD":{"_":"vrsqrt28pd","*":"Computes approximations to the Reciprocal square root (<2^-28 relative error) of the packed double-precision floating-point values from zmm2/m512/m64bcst and stores result in zmm1with writemask k1."},"VRSQRT28PS":{"_":"vrsqrt28ps","*":"Computes approximations to the Reciprocal square root (<2^-28 relative error) of the packed single-precision floating-point values from zmm2/m512/m32bcst and stores result in zmm1with writemask k1."},"VRSQRT28SD":{"_":"vrsqrt28sd","*":"Computes approximate reciprocal square root (<2^-28 relative error) of the scalar double-precision floating-point value from xmm3/m64 and stores result in xmm1with writemask k1. Also, upper double-precision floating-point value (bits[127:64]) from xmm2 is copied to xmm1[127:64]."},"VRSQRT28SS":{"_":"vrsqrt28ss","*":"Computes approximate reciprocal square root (<2^-28 relative error) of the scalar single-precision floating-point value from xmm3/m32 and stores result in xmm1with writemask k1. Also, upper 3 single-precision floating-point value (bits[127:32]) from xmm2 is copied to xmm1[127:32]."},"VSCALEFPD":{"_":"vscalefpd","*":"Scale the packed double-precision floating-point values in zmm2 using values from zmm3/m512/m64bcst. Under writemask k1."},"VSCALEFPS":{"_":"vscalefps","*":"Scale the packed single-precision floating-point values in zmm2 using floating-point values from zmm3/m512/m32bcst. Under writemask k1."},"VSCALEFSD":{"_":"vscalefsd","*":"Scale the scalar double-precision floating-point values in xmm2 using the value from xmm3/m64. Under writemask k1."},"VSCALEFSS":{"_":"vscalefss","*":"Scale the scalar single-precision floating-point value in xmm2 using floating-point value from xmm3/m32. Under writemask k1."},"VSCATTERDPS:VSCATTERDPD:VSCATTERQPS:VSCATTERQPD":{"_":"vscatterdps:vscatterdpd:vscatterqps:vscatterqpd","*":"Stores up to 16 elements (or 8 elements) in doubleword/quadword vector zmm1 to the memory locations pointed by base address BASE_ADDR and index vector VINDEX, with scale SCALE. The elements are specified via the VSIB (i.e., the index register is a vector register, holding packed indices). Elements will only be stored if their corresponding mask bit is one. The entire mask register will be set to zero by this instruction unless it triggers an exception."},"VSCATTERDPS":{"_":"vscatterdps:vscatterdpd:vscatterqps:vscatterqpd","*":"Using signed dword indices, scatter single-precision floating-point values to memory using writemask k1."},"VSCATTERDPD":{"_":"vscatterdps:vscatterdpd:vscatterqps:vscatterqpd","*":"Using signed dword indices, scatter double-precision floating-point values to memory using writemask k1."},"VSCATTERQPD":{"_":"vscatterdps:vscatterdpd:vscatterqps:vscatterqpd","*":"Using signed qword indices, scatter double-precision floating-point values to memory using writemask k1."},"VSCATTERQPS":{"_":"vscatterdps:vscatterdpd:vscatterqps:vscatterqpd","*":"Using signed qword indices, scatter single-precision floating-point values to memory using writemask k1."},"VSCATTERPF0DPS:VSCATTERPF0QPS:VSCATTERPF0DPD:VSCATTERPF0QPD":{"_":"vscatterpf0dps:vscatterpf0qps:vscatterpf0dpd:vscatterpf0qpd","*":"The instruction conditionally prefetches up to sixteen 32-bit or eight 64-bit integer byte data elements. The elements are specified via the VSIB (i.e., the index register is an zmm, holding packed indices). Elements will only be prefetched if their corresponding mask bit is one."},"VSCATTERPF0QPD":{"_":"vscatterpf0dps:vscatterpf0qps:vscatterpf0dpd:vscatterpf0qpd","*":"Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write."},"VSCATTERPF0QPS":{"_":"vscatterpf0dps:vscatterpf0qps:vscatterpf0dpd:vscatterpf0qpd","*":"Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write."},"VSCATTERPF0DPS":{"_":"vscatterpf0dps:vscatterpf0qps:vscatterpf0dpd:vscatterpf0qpd","*":"Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T0 hint with intent to write."},"VSCATTERPF0DPD":{"_":"vscatterpf0dps:vscatterpf0qps:vscatterpf0dpd:vscatterpf0qpd","*":"Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T0 hint with intent to write."},"VSCATTERPF1DPS:VSCATTERPF1QPS:VSCATTERPF1DPD:VSCATTERPF1QPD":{"_":"vscatterpf1dps:vscatterpf1qps:vscatterpf1dpd:vscatterpf1qpd","*":"The instruction conditionally prefetches up to sixteen 32-bit or eight 64-bit integer byte data elements. The elements are specified via the VSIB (i.e., the index register is an zmm, holding packed indices). Elements will only be prefetched if their corresponding mask bit is one."},"VSCATTERPF1DPS":{"_":"vscatterpf1dps:vscatterpf1qps:vscatterpf1dpd:vscatterpf1qpd","*":"Using signed dword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write."},"VSCATTERPF1DPD":{"_":"vscatterpf1dps:vscatterpf1qps:vscatterpf1dpd:vscatterpf1qpd","*":"Using signed dword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write."},"VSCATTERPF1QPS":{"_":"vscatterpf1dps:vscatterpf1qps:vscatterpf1dpd:vscatterpf1qpd","*":"Using signed qword indices, prefetch sparse byte memory locations containing single-precision data using writemask k1 and T1 hint with intent to write."},"VSCATTERPF1QPD":{"_":"vscatterpf1dps:vscatterpf1qps:vscatterpf1dpd:vscatterpf1qpd","*":"Using signed qword indices, prefetch sparse byte memory locations containing double-precision data using writemask k1 and T1 hint with intent to write."},"VSHUFF32X4:VSHUFF64X2:VSHUFI32X4:VSHUFI64X2":{"_":"vshuff32x4:vshuff64x2:vshufi32x4:vshufi64x2","*":"256-bit Version: Moves one of the two 128-bit packed single-precision floating-point values from the first source operand (second operand) into the low 128-bit of the destination operand (first operand); moves one of the two packed 128-bit floating-point values from the second source operand (third operand) into the high 128-bit of the destination operand. The selector operand (third operand) determines which values are moved to the destination operand."},"VSHUFF64X2":{"_":"vshuff32x4:vshuff64x2:vshufi32x4:vshufi64x2","*":"Shuffle 128-bit packed double-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1."},"VSHUFI64X2":{"_":"vshuff32x4:vshuff64x2:vshufi32x4:vshufi64x2","*":"Shuffle 128-bit packed quad-word values selected by imm8 from ymm2 and ymm3/m256/m64bcst and place results in ymm1 subject to writemask k1."},"VSHUFF32X4":{"_":"vshuff32x4:vshuff64x2:vshufi32x4:vshufi64x2","*":"Shuffle 128-bit packed single-precision floating-point values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1."},"VSHUFI32X4":{"_":"vshuff32x4:vshuff64x2:vshufi32x4:vshufi64x2","*":"Shuffle 128-bit packed double-word values selected by imm8 from ymm2 and ymm3/m256/m32bcst and place results in ymm1 subject to writemask k1."},"VTESTPD:VTESTPS":{"_":"vtestpd:vtestps","*":"VTESTPS performs a bitwise comparison of all the sign bits of the packed single-precision elements in the first source operation and corresponding sign bits in the second source operand. If the AND of the source sign bits with the dest sign bits produces all zeros, the ZF is set else the ZF is clear. If the AND of the source sign bits with the inverted dest sign bits produces all zeros the CF is set else the CF is clear. An attempt to execute VTESTPS with VEX.W=1 will cause #UD."},"VTESTPD":{"_":"vtestpd:vtestps","*":"Set ZF and CF depending on sign bit AND and ANDN of packed double-precision floating-point sources."},"VTESTPS":{"_":"vtestpd:vtestps","*":"Set ZF and CF depending on sign bit AND and ANDN of packed single-precision floating-point sources."},"VZEROALL":{"_":"vzeroall","*":"Zero all YMM registers."},"VZEROUPPER":{"_":"vzeroupper","*":"Zero upper 128 bits of all YMM registers."},"WAIT:FWAIT":{"_":"wait:fwait","*":"Causes the processor to check for and handle pending, unmasked, floating-point exceptions before proceeding. (FWAIT is an alternate mnemonic for WAIT.)"},"FWAIT":{"_":"wait:fwait","*":"Check pending unmasked floating-point exceptions."},"WAIT":{"_":"wait:fwait","*":"Check pending unmasked floating-point exceptions."},"WBINVD":{"_":"wbinvd","*":"Write back and flush Internal caches; initiate writing-back and flushing of external caches."},"WRFSBASE:WRGSBASE":{"_":"wrfsbase:wrgsbase","*":"Loads the FS or GS segment base address with the general-purpose register indicated by the modR/M:r/m field."},"WRFSBASE":{"_":"wrfsbase:wrgsbase","*":"Load the FS base address with the 64-bit value in the source register."},"WRGSBASE":{"_":"wrfsbase:wrgsbase","*":"Load the GS base address with the 64-bit value in the source register."},"WRMSR":{"_":"wrmsr","*":"Write the value in EDX:EAX to MSR specified by ECX."},"WRPKRU":{"_":"wrpkru","*":"Writes EAX into PKRU."},"XABORT":{"_":"xabort","*":"Causes an RTM abort if in RTM execution"},"XACQUIRE:XRELEASE":{"_":"xacquire:xrelease","*":"The XACQUIRE prefix is a hint to start lock elision on the memory address specified by the instruction and the XRELEASE prefix is a hint to end lock elision on the memory address specified by the instruction."},"XACQUIRE":{"_":"xacquire:xrelease","*":"A hint used with an “XACQUIRE-enabled“ instruction to start lock elision on the instruction memory operand address."},"XRELEASE":{"_":"xacquire:xrelease","*":"A hint used with an “XRELEASE-enabled“ instruction to end lock elision on the instruction memory operand address."},"XADD":{"_":"xadd","*":"Exchange r64 and r/m64; load sum into r/m64."},"XBEGIN":{"_":"xbegin","*":"Specifies the start of an RTM region. Provides a 32-bit relative offset to compute the address of the fallback instruction address at which execution resumes following an RTM abort."},"XCHG":{"_":"xchg","*":"Exchange quadword from r/m64 with r64."},"XEND":{"_":"xend","*":"Specifies the end of an RTM code region."},"XGETBV":{"_":"xgetbv","*":"Reads an XCR specified by ECX into EDX:EAX."},"XLAT:XLATB":{"_":"xlat:xlatb","*":"Locates a byte entry in a table in memory, using the contents of the AL register as a table index, then copies the contents of the table entry back into the AL register. The index in the AL register is treated as an unsigned integer. The XLAT and XLATB instructions get the base address of the table in memory from either the DS:EBX or the DS:BX registers (depending on the address-size attribute of the instruction, 32 or 16, respectively). (The DS segment may be overridden with a segment override prefix.)"},"XLATB":{"_":"xlat:xlatb","*":"Set AL to memory byte [RBX + unsigned AL]."},"XLAT":{"_":"xlat:xlatb","*":"Set AL to memory byte DS:[(E)BX + unsigned AL]."},"XOR":{"_":"xor","*":"r64 XOR r/m64."},"XORPD":{"_":"xorpd","*":"Return the bitwise logical XOR of packed double-precision floating-point values in xmm1 and xmm2/mem."},"VXORPD":{"_":"xorpd","*":"Return the bitwise logical XOR of packed double-precision floating-point values in zmm2 and zmm3/m512/m64bcst subject to writemask k1."},"XORPS":{"_":"xorps","*":"Return the bitwise logical XOR of packed single-precision floating-point values in xmm1 and xmm2/mem."},"VXORPS":{"_":"xorps","*":"Return the bitwise logical XOR of packed single-precision floating-point values in zmm2 and zmm3/m512/m32bcst subject to writemask k1."},"XRSTOR":{"_":"xrstor","*":"Restore state components specified by EDX:EAX from mem."},"XRSTORS":{"_":"xrstors","*":"Restore state components specified by EDX:EAX from mem."},"XSAVE":{"_":"xsave","*":"Save state components specified by EDX:EAX to mem."},"XSAVEC":{"_":"xsavec","*":"Save state components specified by EDX:EAX to mem with compaction."},"XSAVEOPT":{"_":"xsaveopt","*":"Save state components specified by EDX:EAX to mem, optimizing if possible."},"XSAVES":{"_":"xsaves","*":"Save state components specified by EDX:EAX to mem with compaction, optimizing if possible."},"XSETBV":{"_":"xsetbv","*":"Write the value in EDX:EAX to the XCR specified by ECX."},"XTEST":{"_":"xtest","*":"Test if executing in a transactional region"}}'),d=Object.keys(m),p=function(){var e=(0,n.useState)(""),t=e[0],i=e[1],a=(0,n.useState)([]),p=a[0],l=a[1],c=function(){var e;return null===(e=document.activeElement)||void 0===e?void 0:e.blur()};return(0,n.useEffect)((function(){if(t){for(var e,i=t.toUpperCase(),n=[],o=r(d);!(e=o()).done;){var a=e.value,m=(0,s.compareTwoStrings)(i,a);m>=.5&&n.push([m,a])}n.sort((function(e,t){return t[0]-e[0]})),l(n.map((function(e){return e[1]})).slice(0,25))}else l([])}),[t]),n.createElement("div",{className:"search"},n.createElement("input",{type:"text",value:t,placeholder:"Search...",onChange:function(e){return i(e.target.value)}}),n.createElement("ul",{className:0===p.length?"hidden":""},p.map((function(e){return n.createElement("li",{key:e},n.createElement(o.rU,{className:"no-underline",to:"/"+m[e]._,onClick:c},n.createElement("strong",null,e),": ",m[e]["*"]))}))))},l=function(){var e=(0,o.K2)("3832154866").site.siteMetadata;return n.createElement("nav",{id:"sidebar"},n.createElement("section",null,n.createElement("div",{id:"site-title"},n.createElement(o.rU,{to:"/"},e.title)),n.createElement("div",{id:"site-description"},n.createElement("p",null,e.description),n.createElement("p",null,"powered by"," ",n.createElement("a",{href:"https://github.com/zneak/x86doc",target:"_blank"},"zneak/x86doc")))),n.createElement("section",null,n.createElement(p,null)),n.createElement("section",null,n.createElement("ul",null,n.createElement("li",null,n.createElement("a",{href:"#"})))),n.createElement("section",null,n.createElement("footer",{id:"footer"},n.createElement("p",null,"created by"," ",n.createElement("a",{href:"https://github.com/superhawk610",target:"_blank"},e.author)," ","·"," ",n.createElement("a",{href:"https://github.com/superhawk610/x86reference"},"repo")),n.createElement("p",{className:"copyright"},"© ",(new Date).getFullYear(),", all rights reserved"))))},c=function(e){var t=e.children;return n.createElement("div",{id:"root"},n.createElement(l,null),n.createElement("main",{id:"main"},n.createElement("div",{id:"scroll-wrapper"},t)))}},1566:function(e,t,i){"use strict";i.d(t,{Z:function(){return be}});var n,o,s,r,a=i(7294),m=i(5697),d=i.n(m),p=i(6124),l=i.n(p),c=i(523),u=i.n(c),f=i(4756),h=i.n(f),g="bodyAttributes",b="htmlAttributes",v="titleAttributes",w={BASE:"base",BODY:"body",HEAD:"head",HTML:"html",LINK:"link",META:"meta",NOSCRIPT:"noscript",SCRIPT:"script",STYLE:"style",TITLE:"title"},k=(Object.keys(w).map((function(e){return w[e]})),"charset"),S="cssText",x="href",P="http-equiv",_="innerHTML",D="itemprop",y="name",V="property",T="rel",M="src",C="target",A={accesskey:"accessKey",charset:"charSet",class:"className",contenteditable:"contentEditable",contextmenu:"contextMenu","http-equiv":"httpEquiv",itemprop:"itemProp",tabindex:"tabIndex"},E="defaultTitle",z="defer",q="encodeSpecialCharacters",F="onChangeClientState",R="titleTemplate",I=Object.keys(A).reduce((function(e,t){return e[A[t]]=t,e}),{}),O=[w.NOSCRIPT,w.SCRIPT,w.STYLE],N="data-react-helmet",B="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},U=function(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")},X=function(){function e(e,t){for(var i=0;i<t.length;i++){var n=t[i];n.enumerable=n.enumerable||!1,n.configurable=!0,"value"in n&&(n.writable=!0),Object.defineProperty(e,n.key,n)}}return function(t,i,n){return i&&e(t.prototype,i),n&&e(t,n),t}}(),L=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var i=arguments[t];for(var n in i)Object.prototype.hasOwnProperty.call(i,n)&&(e[n]=i[n])}return e},Q=function(e,t){var i={};for(var n in e)t.indexOf(n)>=0||Object.prototype.hasOwnProperty.call(e,n)&&(i[n]=e[n]);return i},W=function(e,t){if(!e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return!t||"object"!=typeof t&&"function"!=typeof t?e:t},H=function(e){var t=!(arguments.length>1&&void 0!==arguments[1])||arguments[1];return!1===t?String(e):String(e).replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;").replace(/"/g,"&quot;").replace(/'/g,"&#x27;")},G=function(e){var t=Y(e,w.TITLE),i=Y(e,R);if(i&&t)return i.replace(/%s/g,(function(){return Array.isArray(t)?t.join(""):t}));var n=Y(e,E);return t||n||void 0},j=function(e){return Y(e,F)||function(){}},K=function(e,t){return t.filter((function(t){return void 0!==t[e]})).map((function(t){return t[e]})).reduce((function(e,t){return L({},e,t)}),{})},Z=function(e,t){return t.filter((function(e){return void 0!==e[w.BASE]})).map((function(e){return e[w.BASE]})).reverse().reduce((function(t,i){if(!t.length)for(var n=Object.keys(i),o=0;o<n.length;o++){var s=n[o].toLowerCase();if(-1!==e.indexOf(s)&&i[s])return t.concat(i)}return t}),[])},J=function(e,t,i){var n={};return i.filter((function(t){return!!Array.isArray(t[e])||(void 0!==t[e]&&ne("Helmet: "+e+' should be of type "Array". Instead found type "'+B(t[e])+'"'),!1)})).map((function(t){return t[e]})).reverse().reduce((function(e,i){var o={};i.filter((function(e){for(var i=void 0,s=Object.keys(e),r=0;r<s.length;r++){var a=s[r],m=a.toLowerCase();-1===t.indexOf(m)||i===T&&"canonical"===e[i].toLowerCase()||m===T&&"stylesheet"===e[m].toLowerCase()||(i=m),-1===t.indexOf(a)||a!==_&&a!==S&&a!==D||(i=a)}if(!i||!e[i])return!1;var d=e[i].toLowerCase();return n[i]||(n[i]={}),o[i]||(o[i]={}),!n[i][d]&&(o[i][d]=!0,!0)})).reverse().forEach((function(t){return e.push(t)}));for(var s=Object.keys(o),r=0;r<s.length;r++){var a=s[r],m=h()({},n[a],o[a]);n[a]=m}return e}),[]).reverse()},Y=function(e,t){for(var i=e.length-1;i>=0;i--){var n=e[i];if(n.hasOwnProperty(t))return n[t]}return null},$=(n=Date.now(),function(e){var t=Date.now();t-n>16?(n=t,e(t)):setTimeout((function(){$(e)}),0)}),ee=function(e){return clearTimeout(e)},te="undefined"!=typeof window?window.requestAnimationFrame&&window.requestAnimationFrame.bind(window)||window.webkitRequestAnimationFrame||window.mozRequestAnimationFrame||$:i.g.requestAnimationFrame||$,ie="undefined"!=typeof window?window.cancelAnimationFrame||window.webkitCancelAnimationFrame||window.mozCancelAnimationFrame||ee:i.g.cancelAnimationFrame||ee,ne=function(e){return console&&"function"==typeof console.warn&&console.warn(e)},oe=null,se=function(e,t){var i=e.baseTag,n=e.bodyAttributes,o=e.htmlAttributes,s=e.linkTags,r=e.metaTags,a=e.noscriptTags,m=e.onChangeClientState,d=e.scriptTags,p=e.styleTags,l=e.title,c=e.titleAttributes;me(w.BODY,n),me(w.HTML,o),ae(l,c);var u={baseTag:de(w.BASE,i),linkTags:de(w.LINK,s),metaTags:de(w.META,r),noscriptTags:de(w.NOSCRIPT,a),scriptTags:de(w.SCRIPT,d),styleTags:de(w.STYLE,p)},f={},h={};Object.keys(u).forEach((function(e){var t=u[e],i=t.newTags,n=t.oldTags;i.length&&(f[e]=i),n.length&&(h[e]=u[e].oldTags)})),t&&t(),m(e,f,h)},re=function(e){return Array.isArray(e)?e.join(""):e},ae=function(e,t){void 0!==e&&document.title!==e&&(document.title=re(e)),me(w.TITLE,t)},me=function(e,t){var i=document.getElementsByTagName(e)[0];if(i){for(var n=i.getAttribute(N),o=n?n.split(","):[],s=[].concat(o),r=Object.keys(t),a=0;a<r.length;a++){var m=r[a],d=t[m]||"";i.getAttribute(m)!==d&&i.setAttribute(m,d),-1===o.indexOf(m)&&o.push(m);var p=s.indexOf(m);-1!==p&&s.splice(p,1)}for(var l=s.length-1;l>=0;l--)i.removeAttribute(s[l]);o.length===s.length?i.removeAttribute(N):i.getAttribute(N)!==r.join(",")&&i.setAttribute(N,r.join(","))}},de=function(e,t){var i=document.head||document.querySelector(w.HEAD),n=i.querySelectorAll(e+"["+"data-react-helmet]"),o=Array.prototype.slice.call(n),s=[],r=void 0;return t&&t.length&&t.forEach((function(t){var i=document.createElement(e);for(var n in t)if(t.hasOwnProperty(n))if(n===_)i.innerHTML=t.innerHTML;else if(n===S)i.styleSheet?i.styleSheet.cssText=t.cssText:i.appendChild(document.createTextNode(t.cssText));else{var a=void 0===t[n]?"":t[n];i.setAttribute(n,a)}i.setAttribute(N,"true"),o.some((function(e,t){return r=t,i.isEqualNode(e)}))?o.splice(r,1):s.push(i)})),o.forEach((function(e){return e.parentNode.removeChild(e)})),s.forEach((function(e){return i.appendChild(e)})),{oldTags:o,newTags:s}},pe=function(e){return Object.keys(e).reduce((function(t,i){var n=void 0!==e[i]?i+'="'+e[i]+'"':""+i;return t?t+" "+n:n}),"")},le=function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return Object.keys(e).reduce((function(t,i){return t[A[i]||i]=e[i],t}),t)},ce=function(e,t,i){switch(e){case w.TITLE:return{toComponent:function(){return e=t.title,i=t.titleAttributes,(n={key:e})[N]=!0,o=le(i,n),[a.createElement(w.TITLE,o,e)];var e,i,n,o},toString:function(){return function(e,t,i,n){var o=pe(i),s=re(t);return o?"<"+e+' data-react-helmet="true" '+o+">"+H(s,n)+"</"+e+">":"<"+e+' data-react-helmet="true">'+H(s,n)+"</"+e+">"}(e,t.title,t.titleAttributes,i)}};case g:case b:return{toComponent:function(){return le(t)},toString:function(){return pe(t)}};default:return{toComponent:function(){return function(e,t){return t.map((function(t,i){var n,o=((n={key:i})[N]=!0,n);return Object.keys(t).forEach((function(e){var i=A[e]||e;if(i===_||i===S){var n=t.innerHTML||t.cssText;o.dangerouslySetInnerHTML={__html:n}}else o[i]=t[e]})),a.createElement(e,o)}))}(e,t)},toString:function(){return function(e,t,i){return t.reduce((function(t,n){var o=Object.keys(n).filter((function(e){return!(e===_||e===S)})).reduce((function(e,t){var o=void 0===n[t]?t:t+'="'+H(n[t],i)+'"';return e?e+" "+o:o}),""),s=n.innerHTML||n.cssText||"",r=-1===O.indexOf(e);return t+"<"+e+' data-react-helmet="true" '+o+(r?"/>":">"+s+"</"+e+">")}),"")}(e,t,i)}}}},ue=function(e){var t=e.baseTag,i=e.bodyAttributes,n=e.encode,o=e.htmlAttributes,s=e.linkTags,r=e.metaTags,a=e.noscriptTags,m=e.scriptTags,d=e.styleTags,p=e.title,l=void 0===p?"":p,c=e.titleAttributes;return{base:ce(w.BASE,t,n),bodyAttributes:ce(g,i,n),htmlAttributes:ce(b,o,n),link:ce(w.LINK,s,n),meta:ce(w.META,r,n),noscript:ce(w.NOSCRIPT,a,n),script:ce(w.SCRIPT,m,n),style:ce(w.STYLE,d,n),title:ce(w.TITLE,{title:l,titleAttributes:c},n)}},fe=l()((function(e){return{baseTag:Z([x,C],e),bodyAttributes:K(g,e),defer:Y(e,z),encode:Y(e,q),htmlAttributes:K(b,e),linkTags:J(w.LINK,[T,x],e),metaTags:J(w.META,[y,k,P,V,D],e),noscriptTags:J(w.NOSCRIPT,[_],e),onChangeClientState:j(e),scriptTags:J(w.SCRIPT,[M,_],e),styleTags:J(w.STYLE,[S],e),title:G(e),titleAttributes:K(v,e)}}),(function(e){oe&&ie(oe),e.defer?oe=te((function(){se(e,(function(){oe=null}))})):(se(e),oe=null)}),ue)((function(){return null})),he=(o=fe,r=s=function(e){function t(){return U(this,t),W(this,e.apply(this,arguments))}return function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function, not "+typeof t);e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,enumerable:!1,writable:!0,configurable:!0}}),t&&(Object.setPrototypeOf?Object.setPrototypeOf(e,t):e.__proto__=t)}(t,e),t.prototype.shouldComponentUpdate=function(e){return!u()(this.props,e)},t.prototype.mapNestedChildrenToProps=function(e,t){if(!t)return null;switch(e.type){case w.SCRIPT:case w.NOSCRIPT:return{innerHTML:t};case w.STYLE:return{cssText:t}}throw new Error("<"+e.type+" /> elements are self-closing and can not contain children. Refer to our API for more information.")},t.prototype.flattenArrayTypeChildren=function(e){var t,i=e.child,n=e.arrayTypeChildren,o=e.newChildProps,s=e.nestedChildren;return L({},n,((t={})[i.type]=[].concat(n[i.type]||[],[L({},o,this.mapNestedChildrenToProps(i,s))]),t))},t.prototype.mapObjectTypeChildren=function(e){var t,i,n=e.child,o=e.newProps,s=e.newChildProps,r=e.nestedChildren;switch(n.type){case w.TITLE:return L({},o,((t={})[n.type]=r,t.titleAttributes=L({},s),t));case w.BODY:return L({},o,{bodyAttributes:L({},s)});case w.HTML:return L({},o,{htmlAttributes:L({},s)})}return L({},o,((i={})[n.type]=L({},s),i))},t.prototype.mapArrayTypeChildrenToProps=function(e,t){var i=L({},t);return Object.keys(e).forEach((function(t){var n;i=L({},i,((n={})[t]=e[t],n))})),i},t.prototype.warnOnInvalidChildren=function(e,t){return!0},t.prototype.mapChildrenToProps=function(e,t){var i=this,n={};return a.Children.forEach(e,(function(e){if(e&&e.props){var o=e.props,s=o.children,r=function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return Object.keys(e).reduce((function(t,i){return t[I[i]||i]=e[i],t}),t)}(Q(o,["children"]));switch(i.warnOnInvalidChildren(e,s),e.type){case w.LINK:case w.META:case w.NOSCRIPT:case w.SCRIPT:case w.STYLE:n=i.flattenArrayTypeChildren({child:e,arrayTypeChildren:n,newChildProps:r,nestedChildren:s});break;default:t=i.mapObjectTypeChildren({child:e,newProps:t,newChildProps:r,nestedChildren:s})}}})),t=this.mapArrayTypeChildrenToProps(n,t)},t.prototype.render=function(){var e=this.props,t=e.children,i=Q(e,["children"]),n=L({},i);return t&&(n=this.mapChildrenToProps(t,n)),a.createElement(o,n)},X(t,null,[{key:"canUseDOM",set:function(e){o.canUseDOM=e}}]),t}(a.Component),s.propTypes={base:d().object,bodyAttributes:d().object,children:d().oneOfType([d().arrayOf(d().node),d().node]),defaultTitle:d().string,defer:d().bool,encodeSpecialCharacters:d().bool,htmlAttributes:d().object,link:d().arrayOf(d().object),meta:d().arrayOf(d().object),noscript:d().arrayOf(d().object),onChangeClientState:d().func,script:d().arrayOf(d().object),style:d().arrayOf(d().object),title:d().string,titleAttributes:d().object,titleTemplate:d().string},s.defaultProps={defer:!0,encodeSpecialCharacters:!0},s.peek=o.peek,s.rewind=function(){var e=o.rewind();return e||(e=ue({baseTag:[],bodyAttributes:{},encodeSpecialCharacters:!0,htmlAttributes:{},linkTags:[],metaTags:[],noscriptTags:[],scriptTags:[],styleTags:[],title:"",titleAttributes:{}})),e},r);he.renderStatic=he.rewind;var ge=i(5444),be=function(e){var t,i,n=e.description,o=void 0===n?"":n,s=e.lang,r=void 0===s?"en":s,m=e.meta,d=void 0===m?[]:m,p=e.title,l=(0,ge.K2)("63159454").site,c=o||l.siteMetadata.description,u=null===(t=l.siteMetadata)||void 0===t?void 0:t.title;return a.createElement(he,{htmlAttributes:{lang:r},title:p,titleTemplate:u?"%s | "+u:void 0,meta:[{name:"description",content:c},{property:"og:title",content:p},{property:"og:description",content:c},{property:"og:type",content:"website"},{name:"twitter:card",content:"summary"},{name:"twitter:creator",content:(null===(i=l.siteMetadata)||void 0===i?void 0:i.author)||""},{name:"twitter:title",content:p},{name:"twitter:description",content:c}].concat(d)})}}}]);
//# sourceMappingURL=commons-ab44047feb64603a3644.js.map